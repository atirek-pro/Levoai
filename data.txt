---
sidebar_position: 6
---

# Install Code Analysis Tools

## Prerequisites
- Docker is installed on your machine.
- Ensure that you are able to launch and use Docker containers, and network connectivity works.
- `api.levo.ai` is reachable from the host machine

## Instructions to setup code-scanning

- [Install Levo CLI][install-cli], which contains the commands to scan code
- Once the CLI is installed, you can
    - [Scan your code and identify REST API endpoints.](#scan-code-and-identify-rest-api-endpoints)
    - [Scan the project directory to look for existing OpenAPI/Swagger specs.](#scan-project-directory-to-fetch-and-import-openapiswagger-specs)


### Scan Code and identify REST API Endpoints

- Login to Levo CLI
    ```
    levo login
    ```
- Enter the CLI authorization key and select the organization.
- Once logged in, go to the project directory where you want to run code-scanning
    ```
    cd <your_project_directory>
    ```
- Inside the project directory, run the below CLI command
    ```
    levo scan code \
        --dir <relative path to directory you wish to scan> \
        --app-name <name of the app you wish to see on Dashboard> \
        --env-name <the environment to which your app should belong> \
        --language <programmming language used in repository, default is java>
    ```
- In the `--dir` option, you can specify the relative subdirectory path (`./path/to/sub-directory`) if you want to scan only a part of the project, or simply DOT (`.`) for the current directory.
- Use the `--help` option to know the list of available options
- If there are REST endpoints in the code, they will be imported to the Levo Dashboard, under the given app-name.


### Scan project directory to fetch and import OpenAPI/Swagger specs

- Login to Levo CLI
    ```
    levo login
    ```
- Enter the CLI authorization key and select the organization.
- Once logged in, go to the project directory where you want to scan for openAPI specs.
    ```
    cd <your_project_directory>
    ```
- Inside the project directory, run the below CLI command
    ```
    levo scan schema \
        --dir <relative path to directory you want to scan>  \
        --env-name <the environment to which your app should belong>
    ```
- In the `--dir` option, you can specify the relative subdirectory path (`./path/to/sub-directory`) if you want to scan only a part of the project, or simply DOT (`.`) for the current directory.
- Use the `--help` option to know the list of available options
- If there are OpenAPI/Swagger specs in the project directory, they will be imported to Levo Dashboard.
- The App Name will be the same as the title of the OpenAPI/Swagger spec.


### Github Action

#### Prerequisites
- An account on Levo.ai
- An application code repository on GitHub (Currently Java and Python is supported)

#### Action Configuration
The pre-built action for executing `Scan Code` requires the following configuration settings:

- `authorization-key` : Specify your CLI authorization key here. Refer to [Generating CLI Authorization Keys](/integrations/common-tasks.md#generating-cli-authorization-keys) for instructions on fetching your key

- `organization-id` : Specify your *Organization ID* here. Refer to [Accessing Organization IDs](/integrations/common-tasks.md#accessing-organization-ids) for instructions on fetching your ID
 
- `saas-url` : The URL of the Levo SaaS instance. Default value is `https://api.levo.ai`. For India, use `https://api.india-1.levo.ai`.

- `app-name` : The name of the application you want to see on the Levo Dashboard

- `env-name` : This is an **OPTIONAL** setting. The environment to which your app should belong. Default value is `staging`.

Here is a sample *Scan Code Action* with its configuration:

```YAML
- name: Levo Scan Repo
  uses: levoai/actions/scan@v2.3.0
  with:
    # Authorization key required to execute the Levo CLI. Please refer to https://app.levo.ai/settings/keys to get your authorization key.
    authorization-key: <'Specify your CLI authorization key here'>

    # The ID of your organization in Levo dashboard. Please refer to https://app.levo.ai/settings/organization to get your organization id.
    organization-id: <'Specify your organization ID here'>

    # [OPTIONAL] The environment to which your app should belong. Default: staging.
    saas-url: "https://api.dev.levo.ai"

    # The name of the application you want to see on the Levo Dashboard.
    app-name: <'Application Name here'>

    # [OPTIONAL] The environment to which your app should belong. Default: staging.
    env-name: <'Environment Name here'>
```

#### Job Outputs
This pre-built *Action* produces the below [Outputs](https://docs.github.com/en/actions/using-jobs/defining-outputs-for-jobs), which can be referenced by downstream Actions/Jobs.

```YAML
outputs:
  scan-success: <'true/false'>
```


[install-cli]: /security-testing/test-laptop


---
sidebar_position: 5
---

# Install Log Parsing Sensors

## Access Logs Based Instrumentation

### i. Pre-requisites
- Satellite has been successfully installed.
- You have noted down the Satellite's `hostname:port` or `ip-address:port` information.
- The Satellite is reachable (via HTTP/s) from the location where you are going to install the log-parser.

## ii. Pick an `Application Name`
Auto discovered API endpoints and their OpenAPI specifications are shown in the [API Catalog](/guides/security-testing/concepts/api-catalog), grouped under an application name. The application name helps segregate and group API endpoints from different environments, similar to how file folders work in an operating system.

Pick a descriptive name which will be used in the subsequent step below. For example: `my-test-app`.

## iii. Follow instructions for your platform
Follow instructions for your specific platform/method below:
- [Install on Linux host via Docker](#install-on-linux-host-via-docker)

-----------------------------------------------------------------------

## Install on Linux host via Docker

### Prerequisites
- Docker Engine version `18.03.0` and above

### 1. Install Log Parser

> If you are installing the Satellite and Log Parser on the ***same*** Linux host, please do ***NOT*** use `localhost` as the hostname below. Use the Linux host's `IP address`, or `domain name` instead. This is required as the Log Parser runs inside a Docker container, and `localhost` resolves to the Log Parser container's IP address, instead of the Linux host.

```bash
# Replace '<SATELLITE_URL>' with the values you noted down from the Satellite install
#
# Specify below the 'APP_NAME'. Do not quote the 'APP_NAME'.
# Environment Name is optional. If not specified, it defaults to 'staging'
# 
docker run --rm -d --name=log-parser \
  -v ./logs:/mnt/levo/logs \
  -e LEVO_SATELLITE_URL=<LEVO_SATELLITE_URL> \
  -e LEVOAI_ORG_ID=<LEVOAI_ORG_ID> \
  -e APP_NAME=<APP_NAME> \
  -e ENV_NAME=<ENV_NAME> \
  levoai/log-parser 
```

#### NOTE:
- The default address for the satellite in Docker-based Log Parser installations is `https://satellite.levo.ai`.
- In case of levo hosted satellite, it is necessary that you must also specify an organization ID (`LEVOAI_ORG_ID`).
- If you wish, you may also host the Satellite yourself and specify the address of the satellite to direct the Log Parser's data to it.

### 2. Verify connectivity with Satellite
Execute the following command to check for connectivity health:

```bash
# Please specify the actual container name for log-parser below
docker logs log-parser | grep "starting fluentd"
```
If connectivity is healthy, you should see output similar to below.

```bash
2024-02-22 01:27:06 +0000 [info]: starting fluentd-1.16.3 pid=7 ruby="3.2.2"
2024-02-22 01:27:06 +0000 [info]: #0 starting fluentd worker pid=16 ppid=7 worker=0
2024-02-22 01:27:06.831947051 +0000 fluent.info: {"pid":16,"ppid":7,"worker":0,"message":"starting fluentd worker pid=16 ppid=7 worker=0"}
```

Please proceed to the next step, if there are no errors.



---
description: Continuous API Security Assurance. Observe, detect, protect, early!
sidebar_position: 1
slug: /
---

# Welcome to Levo!

Levo comprises of two components, a Sensor which runs alongside your application workloads, and a Satellite.
The Sensor captures live traffic from your environment and sends it to the Satellite for processing.

Levo can host the Satellite for you (reach out to [`support@levo.ai`](mailto:support@levo.ai)), or you can host it yourself.

- [Signup with your enterprise email](https://app.levo.ai/signup)
- [OS Platform Compatibility Check](/guides/general/os-compat-check)
- [Install Satellite](/install-satellite)
- [Install Traffic Capture Sensors](/install-traffic-capture-sensors)


---
sidebar_position: 3
keywords: [Security, Privacy, Data Processing, Data Storage]
---

# Data Processing & Storage FAQs

## Is my data accessible by anyone outside my organization?
Your data belongs ONLY to you, and is ONLY accessible by members of your organization.

Employee's of Levo DO NOT have access to your data.

## What kind of customer data does Levo process and store?

There are two distinct workflows where customer data is processed and stored.

Levo does not process or store PII or PSI data of any kind. Any exceptions will be specifically called out in the workflow descriptions below.

### 1. API Catalog & Schema
Levo's API Catalog can be populated either via auto discovery or via manual import of OpenAPI Schemas. 

In either case no actual customer data, including PII/PSI data is ingested or stored. Only API metadata is ingested and stored.

The below diagram describes the two methods of populating the API Catalog.

![](../assets/api-catalog-population.svg)

#### Manually Imported APIs
In this case OpenAPI specifications are imported by the customer and stored in Levo's API Catalog.

This data is ONLY accessible by members of your organization.

As a best practice, please ensure that your OpenAPI specifications do not contain secrets, tokens, or PSI/PII data.

#### Auto Discovered APIs
Levo can auto discover all your APIs and their schema in your live environments (using an eBPF Sensor).

Even though the eBPF Sensor captures real API traffic (that could potentially have PII/PSI data), the Satellite anonymises all the API traces, and only sends API metadata to Levo SaaS.

The below diagram shows how PII/PSI data from the raw API trace is anonymized and sent to Levo SaaS as API metadata.

![](../assets/trace-anonymization.svg)

### 2. API Security Testing
![](../assets/testing-workflow-data-handling.svg)

This workflow has 4 distinct phases.

- The Test Runner (CLI) pulls Test Plans from Levo SaaS. Test Plans have NO real customer data, and only have information on API endpoints (metadata specified in the API catalog).

- Any user credentials or tokens required to test API endpoints stays within the customer premises, and are supplied locally to the CLI. This information is NEVER transmitted to Levo SaaS.

- The CLI executes the test plan against your API endpoints (similar to integration tests), and sends the results to Levo SaaS. 

    Any authentication/authorization tokens are stripped from the test results before transmission to Levo SaaS.
    Test results may contain the detailed HTTP request/response of the API endpoint being tested. 

    Even though test results are ONLY accessible by members of your organization, it is good practice to ensure, the API endpoints being tested DO NOT return `real` PII/PSI data.

- Test results are viewed from Levo SaaS. Test results do not contain any authentication/authorization tokens, and are ONLY accessible by members of your organization.

    Employee's of Levo, cannot access your test results or other data.

## Does Levo store authentication tokens or secrets?
Levo does not ingest or store authentication credentials, tokens or other secrets. All of this remains within your premises. Please see section above for more details.

## Is TLS used for all data transmissions?
Yes, TLS is used wherever there is data in motion.

## Does Levo SaaS require inbound network connectivity to my datacenter/VPC?
NO. Levo's CLI runs within your datacenter/VPC, and makes outbound network connections to Levo SaaS.

---
sidebar_position: 0
---

# FAQs

## [General](general.md)

## [Data Processing & Storage](data-processing-storage.md)

## [Satellite-Sensor FAQs](satellite-sensor-faqs.md)

## [Sample Applications](sample-apps.md)

---
sidebar_position: 1
---

# General FAQs

#### Why do you need Levo?
Automated security testing of microservices, which uncovers sophisticated [business logic][biz-logic-flaws] and access control-based attacks, is a significant gap today. Continuous Security Assurance from Levo.ai provides fully automated and effortless (runtime) security testing for Microservices in CI/CD.

#### How is Levo different from other Application Security Testing tools?

Modern attacks target [business logic flaws][biz-logic-flaws] that arise from sub-optimal authentication and authorization across API endpoints.

AST tools like [SCA][sca] & [SAST][sast] statically analyze source code for security defects, but are unaware of authentication & authorization flaws.

[DAST][dast] tools focus on the runtime but lack adoption due to the significant manual heavy lifting required. Moreover, they are [“business logic blind”][biz-logic-flaws-tests] as they are unable to uncover sophisticated business logic and access control violation attacks.

[IAST][iast] tools require comprehensive unit test coverage written by developers, and are also “business logic blind”.

Levo is the only purpose-built security solution for APIs & microservices that provides comprehensive detection of both business logic, and OWASP Top 10 vulnerabilities.

#### What CI/CD environments are supported?
Levo supports all popular CI/CD environments. Please refer to [Integrations](/integrations/integrations.md) for more information.


[biz-logic-flaws]: https://www.hackerone.com/company-news/rise-idor
[biz-logic-flaws-tests]: https://engineeringblog.yelp.com/2020/01/automated-idor-discovery-through-stateful-swagger-fuzzing.html
[sca]: https://www.synopsys.com/glossary/what-is-software-composition-analysis.html
[sast]: https://www.microfocus.com/en-us/what-is/sast
[dast]: https://www.microfocus.com/en-us/what-is/dast
[iast]: https://snyk.io/learn/application-security/iast-interactive-application-security-testing/



---
sidebar_position: 4
---

# Sample Applications FAQs

## crAPI

#### Why are several test cases in the onboarding test plan for crAPI disabled?
The objective of onboarding is to let new users experience Levo's security testing capabilities in a quick and stress free manner. To keep the test plan execution time for onboarding under 5 minutes, we disable some tests.

We ensure that there is at least one test case enabled, for each vulnerability type that we test for.

---
sidebar_position: 2
---

# Satellite-Sensor FAQs
![FAQs](../assets/FAQs.svg)

## Table of Contents

- [Getting Help](satellite-sensor-faqs.md#getting-help)
- [Sensor](satellite-sensor-faqs.md#sensor)
- [Satellite](satellite-sensor-faqs.md#satellite)
- [API Catalog](satellite-sensor-faqs.md#api-catalog)

------------------------------------------------------------------------------

## Getting Help
Please email `support@levo.ai` for assistance with installation, product questions, roadmap, etc.

Please provide as much details as possible in your support request.

------------------------------------------------------------------------------

## Sensor

### What OS platforms are supported?
Please see [OS Platforms](/guides/general/supported-platforms.md#what-os-platforms-are-supported).

### What Kubernetes platforms are supported?
Please see [K8s Platforms](/guides/general/supported-platforms.md#what-kubernetes-platforms-are-supported).

### Is Docker Desktop or minikube on Mac OSX, supported?
Support for Docker Desktop, Docker Desktop based Kubernetes, and minikube on MacOS is on the roadmap.

Developers can evaluate `API Observability` on their macOS Laptops, via a proxy based Sensor. Please refer to [Quickstart for macOS/Windows](/quickstart/quickstart-mitm.md).

### Is Windows OS supported?
Microsoft is currently building support for [eBPF in Windows](https://github.com/microsoft/ebpf-for-windows). Windows support will be added subsequent to the completion of that effort.

Developers can evaluate `API Observability` on their Windows Laptops, via a proxy based Sensor. Please refer to [Quickstart for macOS/Windows](/quickstart/quickstart-mitm.md).

### Is there a script that can assess if my OS platform is compatible?
Yes. Please see [install guide](/guides/install-guide).

### How do I install the Sensor?
Please see [install guide](/guides/install-guide).

### What kind of API traffic is discovered?
Currently REST APIs only. Support for gRPC, and GraphQL are on the roadmap.

### What is an API Trace?
An API Trace is the representation of an API invocation, generated from captured traffic. It contains the full HTTP request & response, including the request URL, request headers, request body, response code, response headers, and response body.

### Can APIs running over TLS (HTTPs) be discovered?
Yes, for applications that use [OpenSSL](https://www.openssl.org/). Support for [Java TLS](https://www.ateam-oracle.com/post/transport-level-security-tls-and-java), and [Boring SSL](https://boringssl.googlesource.com/boringssl/) are on the roadmap.

### Are REST APIs over [HTTP/2](https://en.wikipedia.org/wiki/HTTP/2) supported?
Currently only REST APIs over HTTP/1.x are supported. Vast majority of REST APIs still use HTTP/1.x. Support for HTTP/2 is on the roadmap.

### Does the sensor need special privileges?
Yes, like all other vendor solutions in the market that use eBPF. The sensor requires root privileges to capture all API traffic and associated metadata.

### Will the sensor impact my application workloads?
The sensor is passive and *not* inline with your application. It uses [eBPF probes](https://epbf.io) to make passive copies of API traffic (HTTP), similar to [network traffic mirroring](https://docs.aws.amazon.com/vpc/latest/mirroring/what-is-traffic-mirroring.html). The Sensor will not impact your application's function or performance unlike other inline solutions (sidecar proxies, in-app agents, and SDKs).

### What is the CPU impact of the sensor?
Less than 5%, as the sensor can sample API traffic.

### Can API traffic be sampled?
Yes. API traffic can be sampled in high traffic environments to optimize CPU consumption of the Sensor. Unlike vendors building API security solutions that are anomaly based (where every single API call has to be captured), Levo can aggressively sample API traffic. Sampled API traffic is used to discover API endpoints and their underlying schema.

### Can API traffic be filtered?
Yes. Please see [Filtering API Traffic](/install-traffic-capture-sensors/common-tasks/filter-traffic.md).

### Can I consume captured API Traces from the sensor?
Yes. The Sensor exports captured API Traces in industry standard [OpenTelemetry](https://opentelemetry.io/docs/concepts/what-is-opentelemetry/) format. These traces can be visualized using tools like [Jaeger](https://www.jaegertracing.io/), etc.

### What is BPF Type Format Info (BTF)?
Levo's eBPF sensor uses [probes](https://ebpf.io/what-is-ebpf/#hook-overview) to copy API data from socket system calls. [BTF](https://www.kernel.org/doc/html/latest/bpf/btf.html) provides syscall function symbol information, that is used by the Sensor to attach probes.

### Do Linux distributions ship with pre-built BTF info?
Most modern Linux distributions contain pre-built BTF info. If BTF is missing for your specific version of Linux, Levo Support can build a Sensor that contains a custom BTF for your version of Linux.

------------------------------------------------------------------------------

## Satellite

### I don't care about data privacy in pre-production. Can Levo host the Satellite for me?
Yes, Levo certainly can host the Satellite for you. Please contact `support@levo.ai` for assistance.

### Can multiple Sensors send API Traces to the same Satellite?
Yes. Multiple sensors from different hosts/clusters can be configured to send API Traces to the same Satellite.

### Can the Satellite be deployed in a different host/cluster?
Yes. Please see [Install Satellite](/install-satellite).

### How does the Satellite detect sensitive data in API Traffic?
The Satellite has a pre-trained ML model that is used to detect sensitive data such as PII, PSI, etc.

### Can the Satellite be upgraded?
Levo provides updated Docker images for the Satellite. You can upgrade the Satellite at your own convenience, to take advantage of new features, and/or bug fixes.

### What is the resource consumption of the Satellite?
It depends on your traffic patterns. This is usually not a concern, as the Satellite can be run on a dedicated host/cluster and will not contend with your production workloads.

------------------------------------------------------------------------------

## API Catalog

### What OpenAPI Specification version for the auto discovered APIs?
Version 3.0.x

---
sidebar_position: 1
---

# Frictionless API Observability
![API Observability](../assets/api-observability.svg)

Levo’s frictionless & privacy-preserving API observability solution, auto discovers and auto documents all your APIs.

[Here](https://levo.ai/frictionless-api-observability/) is a blog that describes the high level benefits.

#### Get Started

- [Key Concepts](/guides/key-concepts)
- [Supported Platforms](/guides/general/supported-platforms.md)
- [Quickstart](/quickstart)
- [Demo Application](demo-application.md)



---
sidebar_position: 3
---

# Demo Application
*crAPI* is an API driven sample application, that can be used to evaluate API Observability.

You can read more about *crAPI* [here](https://github.com/levoai/demo-apps/blob/main/crAPI/README.md).

1. First follow instructions in the [Install Guide](/guides/install-guide) to install the Satellite, and Sensor components successfully.

2. Now install the crAPI demo application by following instructions [here](https://github.com/levoai/demo-apps/blob/main/crAPI/docs/quick-start.md).

3. Generate traffic for crAPI by browsing its web UI for at least five minutes.

4. Go to the API Catalog in the Levo web console to see auto discovered OpenAPI specifications for crAPI. The specifications will be grouped under the `Application Name` you specified when installing the Sensor.

Congratulations! You are done.

---
sidebar_position: 0
keywords: [API Security, eBPF, API Observability, Security Testing]
---

# Guides

This section contains guides to help you get started with LevoAI's API Observability and Security Testing.

- [Key Concepts](/guides/key-concepts)
- [API Observability](/guides/api-observability)
- [Security Testing](/guides/security-testing)
- [General](/guides/general)
- [Install Guide](/guides/install-guide)
- [Demo Application](/guides/demo-application)



---
sidebar_position: 0
keywords: [API Security, eBPF, API Observability]
---

# Key Concepts
![API Observability](../assets/api-obs-catalog.svg)

API Observability involves three components - a) Sensor, b) Satellite, and c) API Catalog.

## eBPF Sensor
The sensor is a userspace process, that uses [Extended Berkeley Packet Filters (eBPF)](https://ebpf.io) to passively capture API traffic (full HTTP payloads) from Linux workloads. The sensor works on bare metal, virtual machine, and container formats.

eBPF is used by all the modern observability & security vendors, including [DATADOG](https://www.datadoghq.com/product/network-monitoring/network-performance-monitoring/), [new relic](https://newrelic.com/platform/kubernetes-pixie), [paloalto networks](https://www.paloaltonetworks.com/prisma/cloud), [aqua](https://www.aquasec.com/products/tracee/), [sysdig](https://sysdig.com/), [Cilium](https://cilium.io/), etc.

Similar to [network traffic mirroring](https://docs.aws.amazon.com/vpc/latest/mirroring/what-is-traffic-mirroring.html) the sensor works at the Linux host level.

The sensor does not require any modifications to your application workloads. Absolutely no SDKs, no code changes, no configuration changes, no sidecars, and no runtime agents.

The sensor is not *inline* with the application workloads and ***will not*** impact the workload. API traffic can be aggressively sampled in high traffic environments, to limit CPU consumption by the sensor. 

The sensor can be run in both production and pre-production environments. Captured API Traces (HTTP traffic) is sent to the Satellite component, for data anonymization, schema generation, and sensitive data detection/annotation.

## Satellite
The Satellite runs within the customer premises or VPC, and can be run alongside application workloads, or in a separate host.

It uses sampled API traffic (API Traces) from the Sensor to:
    
1. Auto discover API endpoints
2. Derive (OpenAPI) schema for the discovered API endpoints
3. Detect sensitive data (PII, PSI, etc.) present in API data
4. Annotate the derived schema with sensitive data types
5. Send the API schema to Levo SaaS for API Catalog building

### Your Data Stays with You!
![Privacy Preserving](../assets/api-trace-anonymization.svg)

Privacy preserving technology ensures your API data stays with you.

Typical API observability solutions, will ingest all your API data into their SaaS, and put the burden of redacting sensitive customer data on you.

Levo’s privacy preserving technology, does not ingest any of your API data into SaaS. Levo discovers and documents your APIs using only data type inferences performed in the Satellite.

## API Catalog
Levo SaaS aggregates data received from the Satellite to create an [API Catalog](/guides/security-testing/concepts/api-catalog/api-catalog.md).

The API Catalog is the source of truth to answer the following questions:

- What APIs do I have in my environment?
- Which APIs are exposed externally?
- What is the schema for my APIs?
- Which APIs process sensitive data (PII, PSI, etc.)?
- Which users, via which roles/scopes are accessing, which API endpoints?
- Are my API schema's drifting?

The API Catalog also serves as the primary input for Levo's API [security](https://docs.levo.ai/test-your-app/test-app-security/choices) & [contract](https://docs.levo.ai/test-your-app/test-app-schema-conformance) testing features.


---
sidebar_position: 1
---

This section describes tasks that are common when using Levo.

- [OS-Compatibility-Check](/guides/general/os-compat-check)
- [Private Registry](/guides/general/private-registry)
- [Supported Platforms](/guides/general/supported-platforms)



---
sidebar_position: 2
---

# Use a Private Docker Registry for Kubernetes Installations

To use private images while installing Levo's services in your environment, you need to follow 3 steps:
1. Copy Levo's public Docker images into your registry.
1. Create a secret in your Kubernetes cluster with the credentials to access your private registry.
1. Specify a values file to the Levo Helm chart to use your private registry.

## Copy Levo's public Docker images into your registry

An example bash script to do this for AWS ECR has been provided below. Please modify this script to suit your needs.

```bash
#!/usr/bin/env bash

# Dependencies: yq, helm, awscli, docker

set -e
trap "exit" INT

region="us-west-2"
registry="your.registry"

helm repo add levoai https://charts.levo.ai || true
helm repo update
images=($(helm template levoai/levoai-satellite | yq -N '..|.image? | select(.)' | sort -u))
images+=($(helm template levoai/levoai-ebpf-sensor | yq -N '..|.image? | select(.)' | sort -u))

for image in "${images[@]}"; do
  src_image=${image#"docker.io/"}
  dest_image="$registry/$src_image"
  repo_name=${src_image%:*}
  aws ecr describe-repositories --repository-names $repo_name --region $region || aws ecr create-repository --repository-name $repo_name --region $region
  echo "Copying $src_image to $dest_image"
  docker buildx imagetools create --tag $dest_image $src_image
done
```

## Create a secret in your Kubernetes cluster with the credentials to access your private registry

Adapt the following command for your private registry:

```shell
kubectl create secret docker-registry ecr-auth --docker-server=your.registry --docker-username=AWS --docker-password=$(aws ecr get-login-password --region us-west-2)
```

## Specify a values file to the Levo Helm chart to use your private registry

### eBPF Sensor

```yaml
sensor:
  imageRepo: your.registry/levoai/ebpf_sensor
```

### Satellite

```yaml
global:
  levoai_config_override:
    onprem-api:
      org-id: <id>
      refresh-token: <token>
  imageRegistry: your.registry
  imagePullSecrets:
    - name: ecr-auth
```


---
sidebar_position: 5
---

# Supported Platforms

## What OS platforms are supported?

- x86-64 Processors only.
- Linux running on bare metal, virtual machine, and container formats.
- Linux Kernel versions 4.14 and above.
- Debian, Fedora, OpenSUSE, and Amazon Linux based distributions

> macOS & Windows Laptops are supported via a proxy based Sensor. Please refer to [Quickstart for macOS/Windows](/quickstart/quickstart-mitm.md).

## What Kubernetes platforms are supported?
- [minikube on Linux](https://minikube.sigs.k8s.io/docs/)
- [AKS](https://azure.microsoft.com/en-us/services/kubernetes-service/#overview)
- [GKE (Debian Nodes Only. No Container-Optimized OS)](https://cloud.google.com/kubernetes-engine)
- [EKS](https://aws.amazon.com/eks/)

Support for Docker Desktop, Docker Desktop based Kubernetes, and minikube on MacOS is on the roadmap.

## What is the minimum Kubernetes version supported?
- Minimum Kubernetes version: `1.18.0`.
- Kubernetes Node's Linux Kernel version >= `4.14`.



---
sidebar_position: 0
---

# Install Guide

This guide provides *comprehensive instructions* for installing the Satellite, and Sensor on a supported platform of your choice (Kubernetes, Docker, or Linux Virtual Machine).

Platform specific instructions are described in the steps below.

Your estimated completion time is *10 minutes*.

![Install Steps](../../assets/api-observability-install.svg)

- [Signup with your enterprise email](https://app.levo.ai/signup)
- [OS Platform Compatibility Check](/guides/general/os-compat-check.mdx)
- [Install Satellite](/install-satellite)
- [Install Sensor](/install-traffic-capture-sensors)


---
sidebar_position: 4
---

# Direct API Integrations

Direct API integrations with Levo is enabled via a [GraphQL](https://graphql.org/) API endpoint. All operations present in the levo UI & CLI are also accessible via the GraphQL API.

Please contact `support@levo.ai` for full GraphQL schema details with respective to the operations.


---
sidebar_position: 2
---

# JUnit Format Test Results

[JUnit XML format](https://www.ibm.com/docs/en/developer-for-zos/14.1.0?topic=formats-junit-xml-format) is a really popular industry format that is used for test result reporting.

Levo CLI can produce JUnit/XUnit format output for all test results (security/schema conformance). Please refer to the [CLI Command Reference](/security-testing/test-laptop/levo-cli-command-reference.md) for more details on command line switches (`--export-junit-xml`) that activate this output.

There are many tools in the industry that consume this format, and produce HTML, and PDF reports of test results. A few examples are [Jenkins JUnit Plugin](https://plugins.jenkins.io/junit/), [Jenkins XUnit Plugin](https://plugins.jenkins.io/xunit/), [junit2html](https://gitlab.com/inorton/junit2html), [Ant JUnitReport](https://ant.apache.org/manual/Tasks/junitreport.html), [xunit-viewer](https://github.com/lukejpreston/xunit-viewer), etc.

Below are some examples of JUnit format test results rendered in Jenkins via the [JUnit plugin](https://plugins.jenkins.io/junit/).

![JUnit Build Summary](../../assets/junit/jenkins-build-junit-format-summary.png)
![JUnit Build Results](../../assets/junit/jenkins-build-junit-format-results.png)
![JUnit Build Detail-1](../../assets/junit/jenkins-build-junit-format-detail-1.png)
![JUnit Build Detail-2](../../assets/junit/jenkins-build-junit-format-detail-2.png)




---
sidebar_position: 4
---

# Levo CLI in CI/CD

![Embed Levo in CI/CD Quality Gates](../../assets/levo-quality-gates.svg)

You can embed Levo’s contract & security tests in various stages of your software delivery pipeline via CI/CD [Quality Gates](https://docs.microsoft.com/en-us/azure/devops/pipelines/release/approvals/gates?view=azure-devops).

While Levo can be embedded in any CI/CD product (via the CLI), below are first class integrations.

- [GitHub Actions](/security-testing/github-action)
- [Jenkins](/security-testing/jenkins-plugin)

-----------------------------------

## Others

Need support for a CI/CD vendor that is not listed above?

Levo's autogenerated tests can be embedded in any CI/CD product by simply wrapping the Levo CLI in a shell script that is invoked by your CI/CD vendor's job hooks.

Contact `support@levo.ai` for more information.

<br/>

-----------------------------------

---
sidebar_position: 0
---

# Security Testing

- [Concepts](/guides/security-testing/concepts)
- [Sample Application](/guides/security-testing/test-sample-app)
- [Testing your Own Apps](/guides/security-testing/test-your-app/testing-your-own-apps)
- [Levo CLI in CI/CD](/guides/security-testing/levocli-cicd)
- [Common Tasks](/guides/security-testing/common-tasks)

---
sidebar_position: 1
---

# Common Tasks
This section describes tasks that are common when using Levo.

### [Providing Authentication / Authorization for Tests](/guides/security-testing/common-tasks/authn-authz)

### [Providing RBAC Information for APIs](/guides/security-testing/common-tasks/api-rbac)

### [Running Test Plans](/guides/security-testing/common-tasks/running-test-plans/running-test-plans.md)

---
sidebar_position: 1
---

# Associating RBAC Information with APIs

APIs specified in the API Catalog can be associated with `RBAC` information using the `metadata.yml` file.
The association is made by importing a properly constructed `metadata.yml` into the specific API Catalog (Application or Service).

Please refer to the API Catalog screens in the UI to import a `metadata.yml` file.

## What is the structure of the `metadata.yml` file?

Consider a scenario where you have the API endpoints mentioned below, and have implemented role based access controls (RBAC) for your APIs.

*`GET /`* <br></br>
*`GET /identity/api/v1/admin/users/find`* <br></br>
*`GET /identity/api/v2/vehicle/{vehicleId}/location`* <br></br>
*`GET /workshop/api/shop/orders/{order_id}`* <br></br>

Say, that there are two roles: `ROLE_USER` and `ROLE_ADMIN` associated with your API endpoints. These roles provide certain entitlements (capability to access specific API operations after authentication) to regular users and administrators.

The table below represents the RBAC entitlements:

| API Endpoint                                      | Roles Allowed to Access Endpoint | Comments                         |
| ------------------------------------------------- | -------------------------------- | -------------------------------- |
| GET /                                             | ROLE_USER, ROLE_ADMIN            | Available to all roles           |
| GET /identity/api/v1/admin/users/find             | ROLE_ADMIN                       | Endpoint has elevated privileges |
| GET /identity/api/v2/vehicle/{vehicleId}/location | ROLE_USER                        | N/A for Admins                   |
| GET /workshop/api/shop/orders/{order_id}          | ROLE_USER                        | N/A for Admins                   |

For the above scenario, YAML file (shown below), provides a mapping between the API endpoints and their associated roles.

```YAML
# This is an example metadata.yml file
#
roles:
  # This section captures the set of roles that are available to be associated with your API endpoints
  - role: ROLE_USER
    description: USER role that provides certain entitlements for regular users
  - role: ROLE_ADMIN
    description: ADMIN role that provides elevated privileges/entitlements for administrator
#
#
api:
  # This section defines actual associations between API endpoints and roles at the global level
  # This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  #
  #
  endpoints:
    # This section defines API endpoint specific overrides
    #
    - endpoint: GET /identity/api/v1/admin/users/find
      roles:
        - ROLE_ADMIN # `admin/users/find` should only be accessed by ROLE_ADMIN
      default_role: ROLE_ADMIN # override the default role for this endpoint
    #
    - endpoint: GET /identity/api/v2/vehicle/{vehicleId}/location
      roles:
        - ROLE_USER # `/vehicle/{vehicleId}/location` should only be accessed by ROLE_USER
        # No need to override the default_role here, as it is already ROLE_USER
    #
    - endpoint: GET /workshop/api/shop/orders/{order_id}
      roles:
        - ROLE_USER # `/shop/orders/{order_id}` should only be accessed by ROLE_USER
        # No need to override the default_role here, as it is already ROLE_USER 
```

If you have many API endpoints and have complex requirements for associating RBAC information, the next section will help simplify the association, via the usage of pattern matching [glob][GLOB], etc.


[GLOB]: https://github.com/begin/globbing#what-is-globbing

---
sidebar_position: 2
---

# Associating RBAC Information Using Pattern Matching (Glob)

## What problem does this solve?
Some applications contain a numerous API endpoints and associated RBAC roles/scopes.

This feature supports rapid, and efficient mapping of roles/scopes with numerous API endpoints at scale.

The feature uses a technique called Globbing, which is described below.

## What is Globbing?
The term "globbing", also referred to as "glob matching" or "URL path expansion", is a programming concept that describes the process of using wildcards, referred to as "glob patterns" or "globs", for URL paths or other similar sets of strings.

You can read more about it [here][GLOB].

## What are some use cases?

Consider a scenario where your application has numerous API endpoints, and three roles (shown below) for RBAC.

| RBAC Role Name | Role Description                 |
| -------------- | -------------------------------- |
| ROLE_USER      | A consumer of the application    |
| ROLE_MECHANIC  | Skilled at working with machines |
| ROLE_ADMIN     | Administrator. Oversees everything |

Below are example use cases, and the corresponding `metadata.yml` file structure.

### 1. Allow `ROLE_USER` access to all POST endpoints   

```YAML
roles:
# This section captures the set of roles that are available to be associated with your API endpoints
  - role: ROLE_USER
    description: "A consumer of the application."
  - role: ROLE_MECHANIC
    description: "Skilled at working with machines."
  - role: ROLE_ADMIN
    description: "Administrator. Oversees everything."

api:
# This section defines actual associations between API endpoints and roles at the global level
# This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_MECHANIC
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  #
  endpoint_groups:
  # This section allows Method and URL path based mapping between endpoints and roles
  #
  # This specifies that ROLE_USER should have access to all POST endpoints
    - methods:
        - "POST"
      roles:
        - ROLE_USER
```

### 2. Allow `ROLE_MECHANIC` & `ROLE_ADMIN` access to GET endpoints beginning with `/workshop/`

For example the API endpoints under consideration could be:
- GET /workshop/shop
- GET /workshop/shop/products
- GET /workshop/mechanic
- GET /workshop/mechanic/service_requests

```YAML
roles:
# This section captures the set of roles that are available to be associated with your API endpoints
  - role: ROLE_USER
    description: "A consumer of the application."
  - role: ROLE_MECHANIC
    description: "Skilled at working with machines."
  - role: ROLE_ADMIN
    description: "Administrator. Oversees everything."

api:
# This section defines actual associations between API endpoints and roles at the global level
# This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_MECHANIC
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  #
  endpoint_groups:
  # This section allows Method and URL path based mapping between endpoints and roles
  #
  # This specifies that ROLE_MECHANIC & ROLE_ADMIN should have access to all GET endpoints beginning with /workshop/
    - methods:
        - "GET"
      patterns:
      # This describes the URI path to match as a glob string. This can be a list of URI paths.
        - "/workshop/**"
      roles:
        - ROLE_MECHANIC
        - ROLE_ADMIN
```

### 3. Allow `ROLE_MECHANIC` & `ROLE_ADMIN` access to GET endpoints with URI pattern `/workshop/<URI path segment>`

For example the API endpoints under consideration could be:
- GET /workshop/shop
- GET /workshop/mechanic

However the below API is not under consideration as it has more than one path segments:
- GET /workshop/mechanic/service_requests

```YAML
roles:
# This section captures the set of roles that are available to be associated with your API endpoints
  - role: ROLE_USER
    description: "A consumer of the application."
  - role: ROLE_MECHANIC
    description: "Skilled at working with machines."
  - role: ROLE_ADMIN
    description: "Administrator. Oversees everything."

api:
# This section defines actual associations between API endpoints and roles at the global level
# This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_MECHANIC
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  #
  endpoint_groups:
  # This section allows Method and URL path based mapping between endpoints and roles
  #
  # This specifies that ROLE_MECHANIC & ROLE_ADMIN should have access to all GET endpoints with URI pattern `/workshop/<path segment>`
    - methods:
        - "GET"
      patterns:
      # This describes the URI path to match as a glob string. This can be a list of URI paths.
        - "/workshop/*"
      roles:
        - ROLE_MECHANIC
        - ROLE_ADMIN
```

## FAQs

### What happens when an endpoint is part of a group and also is listed explicitly under the endpoints section?
In such case the explicit listing will take precedence over the group pattern matching. Please see example below.

```YAML
roles:
# This section captures the set of roles that are available to be associated with your API endpoints
  - role: ROLE_USER
    description: "A consumer of the application."
  - role: ROLE_MECHANIC
    description: "Skilled at working with machines."
  - role: ROLE_ADMIN
    description: "Administrator. Oversees everything."

api:
# This section defines actual associations between API endpoints and roles at the global level
# This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_MECHANIC
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  #
  endpoint_groups:
  # This section allows Method and URL path based mapping between endpoints and roles
  #
  # This specifies that ROLE_MECHANIC & ROLE_ADMIN should have access to all GET endpoints with URI pattern `/workshop/<path segment>`
    - methods:
        - "GET"
      patterns:
      # This describes the URI path to match as a glob string. This can be a list of URI paths.
        - "/workshop/*"
      roles:
        - ROLE_MECHANIC
        - ROLE_ADMIN
#
endpoints:
    # This section defines API endpoint specific overrides
    #
    - endpoint: GET /workshop/list
      roles:
      # This overrides the mapping specified in the `endpoint_groups` section above
        - ROLE_ADMIN # `/workshop/list` should only be accessed by ROLE_ADMIN
      default_role: ROLE_ADMIN # override the default role for this endpoint
    #
```

### What methods are supported in the `endpoint_groups`?
All RESTful Methods are supported. In case no method is specified, the glob string will be matched against all RESTful methods.

### What happens when the `patterns` list is absent?
In case the `patterns` list is absent, all endpoints matching the specified `methods` will be matched.

### What matching operators are allowed for the `patterns` glob string?

#### Segments and Separators (/)
The separator is always the `/` character. A segment is everything that comes between the two separators. This includes path parameters.

Example:

`/workshop/api`

Here `workshop` and `api` are the segments and `/` is the separator.

#### Single Asterisk (*)
Single Asterisk (*) matches zero or more characters within one segment. It is used for globbing the URI path within one URI path segment.

Example:

The glob `/workshop/api/shop/*` will match endpoints such as:

`/workshop/api/shop/return_qr_code` 

but not endpoints like:

`/workshop/api/shop/orders/all` or `/workshop/api/shop/orders/{order_id}`

#### Double Asterisk (**)
Double Asterisk (**) matches zero or more characters across multiple URI path segments.

Example:

The glob `/workshop/api/shop/**` will match the endpoints such as:

`/workshop/api/shop/return_qr_code`
`/workshop/api/shop/orders/all`
`/workshop/api/shop/orders/{order_id}`

#### Question Mark(?)
Question mark(?) matches a single character within one URI path segment. When some URIs differ just one character, you can use the `?`.

Example:

Glob string `/community/api/v?/coupon/*` will match:

`/community/api/v2/coupon/new-coupon`
`/community/api/v2/coupon/validate-coupon`
`/community/api/v1/coupon/validate-coupon`




[GLOB]: https://github.com/begin/globbing#what-is-globbing






---
sidebar_position: 0
---

# Providing RBAC Information for APIs

### [Associating RBAC Information with APIs](api-rbac-apis.md)

### [Associating RBAC Information Using Pattern Matching (Glob)](api-rbac-glob.md)






---
sidebar_position: 0
---

# Providing Authentication / Authorization for Tests

Most API endpoints require some form of user/client authentication, and authorization. Effective security testing requires providing valid authentication credentials to Levo's autogenerated Test Plans.

Below sections cover the provisioning of authentication and authorization information for test plans.

### [Providing Authentication Information](/guides/security-testing/common-tasks/authn-authz/authn)
### [Supported Authentication Methods](/guides/security-testing/common-tasks/authn-authz/supported-auth-methods)
### [Providing Authorization Information for Authorization Abuse Tests](/guides/security-testing/common-tasks/authn-authz/authz)




---
sidebar_position: 1
---

# Providing Authentication for Tests

Most API endpoints require some form of user/client authentication. Effective security testing requires providing valid authentication credentials to Levo's autogenerated Test Plans.

This information can be provided in a secure, and structured manner via an `environment.yml` file.

## How do I use `environment.yml` file?

The `environment.yml` file is autogenerated per `Test Plan`, and needs to be completed with appropriate authentication information, prior to the execution of the Test Plan.

The completed file is provided as an argument to the CLI. The CLI uses the credentials to access the target APIs and evaluate their security posture.

## Are my `secrets` sent to Levo SaaS?

The `environment.yml` file contains `secrets` and is **never** sent to, or stored in Levo SaaS. This file is solely consumed by the CLI, and Levo SaaS does not have access to your secrets.

Please treat this file securely, and take all precautions necessary for handling secrets.

## What is the structure of this autogenerated file?
This section covers authentication for standard security tests. For test plans that involve [`Horizontal Authorization Abuse`][horizontal-priv-abuse], and [`Vertical Authorization Abuse`][vertical-priv-abuse] test cases, please refer to the [`Providing Authorization Info`](authz.md) section.

If the API endpoints you are testing have no role/scope information (used for granular authorization), and/or not susceptible to [`Horizontal Authorization Abuse`][horizontal-priv-abuse], then autogenerated file will have the below structure.

```YAML
# Environment file that contains users, roles and their Authentication
# mechanisms that will be used by the API endpoints.
iam:
  users:
  - name: user_1
    default: true # This user's credentials will be used to access all API endpoints requiring AuthN
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
```
The default authentication mechanism used by Levo is [Bearer Authentication][bearer-auth]. You are required to provide
valid `bearer tokens` for the user above (`user_1`).

The `default: true` for `user_1` specifies that this user's credentials will be used to access all API endpoints that require authentication.

### Does Levo support other authentication methods?
The next section describes support for various standard and custom authentication methods.



[horizontal-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Horizontal
[vertical-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Vertical
[bearer-auth]: https://swagger.io/docs/specification/authentication/bearer-authentication/



---
sidebar_position: 3
---

# Providing Authorization Information for Authorization Abuse Tests

Levo's autogenerated Test Plans, evaluate API vulnerabilities related to [`Horizontal Authorization Abuse`][horizontal-priv-abuse], and [`Vertical Authorization Abuse`][vertical-priv-abuse].

In order to effectively access and test APIs for these vulnerabilities, Levo may require authentication credentials for additional users, and their associated `role` information.

### [Provision Horizontal AuthZ Abuse Test Plans](horizontal-authz.md)

### [Provision Vertical AuthZ Abuse Test Plans](vertical-authz.md)

### [Provision Horizontal/Vertical AuthZ Abuse Test Plans](horizontal-n-vertical-authz.md)



[horizontal-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Horizontal
[vertical-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Vertical


---
sidebar_position: 4
---

# Providing Authorization Information for `Horizontal Authorization Abuse` Test Cases
Testing for [`Horizontal Authorization Abuse`][horizontal-priv-abuse], requires credentials for additional users.

Since horizontal authorization abuse ([BOLA][bola]) is about violating resource ownership constraints among users, these tests operate with a notion of users owning specific RESTful resources.

The tests first access the API's RESTful resource via the user who owns the resource, and then attempt to do the same with an additional user, who does not have resource ownership.

The autogenerated `environment.yml` file will have the below structure (assuming the default Bearer AuthN mechanism is being used).

```YAML
# Environment file that contains users, roles and their Authentication
# mechanisms that will be used by the API endpoints.
iam:
  users:
  - name: user_1
    default: true # This user should own RESTful resources subject to horizontal abuse testing
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
  - name: user_2
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
```
You are required to provide valid `bearer tokens` for two users above (`user_1` and `user_2`).

If you are wondering why bearer tokens for two users are required, `user_1` is the `default` user, that is used in most of the API testing.

`user_2` specifies credentials for another user (at the same role level as `user_1`), and is used in [`horizontal privilege escalation`][bola] tests.

If using an authentication mechanism other than Bearer AuthN, please modify the auto generated YAML appropriately.


[horizontal-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Horizontal
[bola]: /vulnerabilities/v1/OWASP-API-10/A1-BOLA


---
sidebar_position: 6
---

# Providing Authorization Information for Test Plans - `Horizontal & Vertical Authorization Abuse` Test Cases

Often you will want to test APIs for both [`Horizontal Authorization Abuse`][horizontal-priv-abuse], and [`Vertical Authorization Abuse`][vertical-priv-abuse], in a single test plan.

This requires credentials for additional users, and their associated role information.

User `role` information for API endpoints is provided in the API catalog via the [metadata.yml file](/guides/security-testing/concepts/api-catalog/metadata-yml.md). The metadata file specifies the various roles used by the API, and specific roles that apply to specific API endpoints.

While the metadata file is used to specify `role` information, the `environment.yml` file requires the provisioning of one or more users per role (as specified in the metadata file), and their respective authentication credentials.

For example if the metadata file has specified two roles (`ROLE_USER`, and `ROLE_ADMIN`), the autogenerated `environment.yml` file will have the below structure (assuming the default Bearer AuthN mechanism is being used).

```YAML
# Environment file that contains users, roles and their Authentication
# mechanisms that will be used by the API endpoints.
iam:
  users:
  - name: user_1
    # Default user for `ROLE_USER` that is used in general, unless overridden by a specific test case.
    # This user is the primary user (victim) in horizontal authZ abuse test cases involving `ROLE_USER`.
    default: true
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
    roles:
        - ROLE_USER
  - name: user_2
  # This additional user at role `ROLE_USER` is used in horizontal authZ abuse test cases.
  # This user is the secondary user (attacker) in horizontal authZ abuse test cases.
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
      roles:
        - ROLE_USER
  - name: user_3
    # Default user for `ROLE_ADMIN` that is used in general, unless overridden by a specific test case.
    # This user is the primary user (victim) in horizontal authZ abuse test cases involving `ROLE_ADMIN`.
    default: true 
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
    roles:
        - ROLE_ADMIN
  - name: user_4
    # This additional user at role `ROLE_ADMIN` is used in horizontal authZ abuse test cases.
    # This user is the secondary user (attacker) in horizontal authZ abuse test cases involving `ROLE_ADMIN`.
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
    roles:
        - ROLE_ADMIN
```
Since the test plan has test cases for both horizontal and vertical authZ abuse, we have to provide credentials for 4 users. Two users for `ROLE_USER`, two users for `ROLE_ADMIN`. The two users at each role level will be used for the horizontal authorization abuse test cases (Victim user and Attacker user).

If using an authentication mechanism other than Bearer AuthN, please modify the auto generated YAML appropriately.


[horizontal-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Horizontal
[vertical-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Vertical



---
sidebar_position: 2
---

# Supported Authentication Methods

The default authentication mechanism is [Bearer Authentication][bearer-auth], and the `environment.yml` file is auto-generated to use this method.

You can customize the authentication method to suit your needs.

Below are various authentication methods supported by levo, and the corresponding structure of the `environment.yml` file, to properly activate the authentication method.

Please customize the auto generated `environment.yml` file accordingly.

## Bearer Tokens
The default authentication mechanism is [Bearer Authentication][bearer-auth]. You are required to provide
valid `bearer tokens` for `user_1` in the example below.

```YAML
iam:
  users:
  - name: user_1
    default: true # This user's credentials will be used for all authn-authz
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
```

## Login API / form based login (aka http_call)
If you use an API (or HTTP JSON forms) to acquire a authentication token (bearer token) in exchange for user credentials, you can use the `http_call` method.

This method requires you to provide the following:
- The login URL
- The HTTP method to use when fetching the URL. Only `POST` & `GET` supported. If unspecified will use `POST`.
- The key names for both the username and password values that are sent in the login request's POST (JSON) body.
- The location in the login URL's JSON response, where the authentication token is present.
- The username and base64 encoded password values for the `user_1` used in security tests.

Below is the syntax to enable `http_call` based login.

```YAML
iam:
  #
  #
  # This section specifies how to extract an authn-authz token
  authenticators:
    - name:  <your friendly name for this authenticator. E.g. my_authenticator>
      type: http_call # Makes a HTTP request using the specified method
      method: <POST | GET> # Defaults to POST if unspecified
      login_url: <Enter URL value. E.g. /identity/api/auth/login> # URL for HTTP request
      username_key: <JSON key for username> # Key in HTTP request's JSON body that specifies the user value
      password_key: <JSON key for password> # Key in HTTP request's JSON body that specifies the password value
      #
      #
      # This section specifies how to extract a token in the HTTP response
      session_credential_extractors:
        - name: access_token
          type: bearer_token
          location: <header | body> # Specifies the location to extract the token. Header or Body.
          path: <JSON path expression> # In case the location is `body`, a JSON path expression to the token in the response body
  #
  #
  # This section specifies actual user information the test plan will use
  users:
    - name: user_1
      default: true # This user's credentials will be used to access all API endpoints requiring AuthN
      username: <user_id>
      password_base64: <base64 password> # Passwords need to be base64 encoded
      authenticator: <friendly name of the authenticator specified above. E.g. my_authenticator>
```

## Basic Authentication
Below are format examples for `Basic Authentication` with and without `role` information.

### Basic Authentication (no roles)
```YAML
iam:
  authenticators:
    - name: <your friendly name for this authenticator>
      type: basic_auth # Use Basic Authentication for API calls
  users:
    # This section defines users and their respective credentials
    # The credentials will be used in the Basic Authentication scheme
    - name: user_1
      username: <username for an actual user in your API's backend>
      password_base64: <password for the specified user> # Passwords need to be base64 encoded
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
```

### Basic Authentication (with roles)
```YAML
iam:
  authenticators:
    - name: <your friendly name for this authenticator>
      type: basic_auth # Use Basic Authentication for API calls
  users:
    # This section defines users and their respective credentials
    # The credentials will be used in the Basic Authentication scheme
    #
    # `user_1` with role ROLE_USER
    - name: user_1
      default: true # Default user for `ROLE_USER`
      username: <username for an actual user in your API's backend>
      password_base64: <password for the specified user> # Passwords need to be base64 encoded
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
      roles:
        - ROLE_USER
    #
    # `user_2` with role ROLE_USER
    - name: user_2
      username: <username for an actual user in your API's backend>
      password_base64: <password for the specified user> # Passwords need to be base64 encoded
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
      roles:
        - ROLE_USER
    #
    # `admin_1` with role ROLE_ADMIN
    - name: admin_1
      default: true # Default user for `ROLE_ADMIN`
      username: <username for an actual user in your API's backend>
      password_base64: <password for the specified user> # Passwords need to be base64 encoded
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
      roles:
        - ROLE_ADMIN
    #
    # `admin_2` with role ROLE_ADMIN
    - name: admin_2
      username: <username for an actual user in your API's backend>
      password_base64: <password for the specified user> # Passwords need to be base64 encoded
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
      roles:
        - ROLE_ADMIN
```

## API key based authentication
The OpenAPI specification file (in the API catalog), specifies if the API uses API keys for authentication, and the exact location of the API key (query parameter, header, etc).

The environment.yml file provides specific values for the API key and can be specific for each user. Below is the format when using API keys.

```YAML
iam:
  authenticators:
    - name: <your friendly name for this authenticator>
      type: api_key # Use API key authn-authz for API calls
  users:
    # This section defines users and their respective API keys
    - name: user_1
      api_keys:
      - name: <friendly name for your API key for user_1>
        value: <your api key value>
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above>
```
If you using roles, the format is similar to the Basic Authentication example. You just need to use API key instead of username and password.

## Cookie based authentication
Below examples are applicable, when cookies are being used for user authentication.

### Use existing cookie values
Below example is applicable, when the cookie values are known *a priori*.

```YAML
iam:
  users:
  - name: user_1
    default: true # This user's credentials will be used for all authn-authz
    cookies:
    - name: <Enter exact cookie name. E.g. JSESSIONID> # Cookie is case sensitive
      value: <Enter the cookie value>
```

### Extract cookie via API call (aka http_call)
If you use an API (or HTTP JSON forms) to acquire a authentication cookie in exchange for user credentials, you can use the `http_call` method.

This method requires you to provide the following:
- The HTTP URL of the API endpoint that returns the authentication cookie.
- The HTTP method to use when fetching the URL. Only `POST` & `GET` supported. If unspecified will use `POST`.
- The name/location of the username field that is sent in the login request's (JSON) body. This needs to be a JSON path expression.
- The name/location of the password field that is sent in the login request's (JSON) body. This needs to be a JSON path expression.
- The name of the cookie header in the JSON response, where the cookie is present.
- The username and base64 encoded password values for the `user_1` used in security tests.

Below is the syntax to extract cookies using a `http_call`.
```YAML
iam:
  authenticators:
    - name: <your friendly name for this authenticator. E.g. my_auth_cookie_extractor>
      type: http_call
      method: <POST | GET> # Defaults to POST if unspecified
      login_url: <Enter URL value. E.g. /login> # URL for HTTP request
      request_params:
        - name: username
          value: <JSON path expression. E.g. $$.user.username> #JSON path of username field.
        - name: password
          value: <JSON path expression. E.g. $$.user.password> #JSON path of password field
      #
      # JSON path expressions in the example shown above is representative of the
      # below JSON
      # {
      #   "user": {
      #             "username":"<value>",
      #             "password":"<value>"
      #           }
      # }
      #
      #
      # This section specifies how to extract the cookie from the HTTP response
      session_credential_extractors:
        - name: <your friendly name for this cookie extractor. E.g. my-cookies>
          type: cookies # Use cookie based authn-authz 
          location: headers # Location of the cookie is in the response headers
          header_name: Set-Cookie # Case sensitive name of the header. All cookies in the Set-Cookie header are extracted
  #
  #
  # This section specifies actual user information the test plan will use
  users:
    - name: user_1
      default: true # This user's credentials will be used to access all API endpoints requiring AuthN
      username: <user_id> # Specify the actual user id
      password_base64: <base64 password> # Specify the user's base64 encoded password.
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above. E.g. my_auth_cookie_extractor>
```

### Use existing cookie values (usage with roles)
Below example is applicable when you are running tests that involve multiple users belonging to different roles. 

There are two roles and three users in the below example, that require cookie values to be specified.

```YAML
iam:
  users:
  # This section defines users and their respective cookie based credentials
  #
  # `admin_1` with role ROLE_ADMIN
  - name: admin_1
    default: true # Default user for `ROLE_ADMIN`
    roles:
    - ROLE_ADMIN
    # Use the below cookie header for authn-authz
    cookies:
    - name: <Enter exact cookie name. E.g. JSESSIONID> # Cookie is case sensitive
      value: <Enter the cookie value>
  #
  # `user_1` with role ROLE_USER
  - name: user_1
    default: true # Default user for `ROLE_USER`
    roles:
    - ROLE_USER
    cookies:
    - name: <Enter exact cookie name. E.g. JSESSIONID> # Cookie is case sensitive
      value: <Enter the cookie value>
  #
  # `user_2` with role ROLE_USER
  - name: user_2
    roles:
    - ROLE_USER
    cookies:
    - name: <Enter exact cookie name. E.g. JSESSIONID> # Cookie is case sensitive
      value: <Enter the cookie value>
```

### Extract cookie via API call (usage with roles)
Below example is applicable when you are running tests that involve multiple users belonging to different roles, and you want to extract authentication cookies for them

There are two roles and three users in the below example, that require cookie values to be extracted using the http_call.

```YAML
iam:
  authenticators:
    - name: <your friendly name for this authenticator. E.g. my_auth_cookie_extractor>
      type: http_call
      method: <POST | GET> # Defaults to POST if unspecified
      login_url: <Enter URL value. E.g. /login> # URL for HTTP request
      request_params:
        - name: username
          value: <JSON path expression. E.g. $$.user.username> #JSON path of username field.
        - name: password
          value: <JSON path expression. E.g. $$.user.password> #JSON path of password field
      #
      # This section specifies how to extract the cookie from the HTTP response
      session_credential_extractors:
        - name: <your friendly name for this cookie extractor. E.g. my-cookies>
          type: cookies # Use cookie based authn-authz 
          location: headers # Location of the cookie is in the response headers
          header_name: Set-Cookie # Case sensitive name of the header. All cookies in the Set-Cookie header are extracted.
  #
  #
  # This section specifies actual user information the test plan will use
  users:
    # `admin_1` with role ROLE_ADMIN
    - name: admin_1
      default: true # Default user for `ROLE_ADMIN`
      username: <user_id> # Specify the actual user id
      password_base64: <base64 password> # Specify the user's base64 encoded password.
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above. E.g. my_auth_cookie_extractor>
    #
    # `user_1` with role ROLE_USER
    - name: user_1
      default: true # Default user for `ROLE_USER`
      username: <user_id> # Specify the actual user id
      password_base64: <base64 password> # Specify the user's base64 encoded password.
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above. E.g. my_auth_cookie_extractor>
    #
    # `user_2` with role ROLE_USER
    - name: user_2
      username: <user_id> # Specify the actual user id
      password_base64: <base64 password> # Specify the user's base64 encoded password.
      # Below defines which authn-authz mechanism to use
      authenticator: <friendly name of the authenticator specified above. E.g. my_auth_cookie_extractor>
```

## OAuth
Below methods describe how [access tokens](https://www.oauth.com/oauth2-servers/access-tokens/) can be extracted using the OAuth protocol.

### Password Grant
The [Password grant](https://www.oauth.com/oauth2-servers/access-tokens/password-grant/) enables Levo's Test Plans to exchange the user’s username and password for an access token.

This method requires you to provide the following:
- The URL of the token generation API endpoint
- The URL of the refresh token generation API endpoint (optional)
- The *username* of the user, for whom the token is being generated
- The base64 encoded *password* of the user, for whom the token is being generated
- A list of *scopes* for the user (optional)
- The *Client ID*, if it is required by your OAuth server (optional)
- The *Client Secret*, if it is required by your OAuth server (optional)

Below is the syntax to enable *Password Grant*.

```YAML
iam:
  authenticators:
    - name: <Friendly name for this authenticator. E.g. oauth_2>
      type: oauth2 # Use OAuth protocol
      grant_type: password
      token_url: <Enter the URL for the token generation endpoint. E.g. https://my-oauth/oauth/access_token>
      method: POST
      client_id: <Enter your client ID. E.g. 23lkjlekfjlskd90> # Optional field
      client_secret: <Enter your client secret. E.g. UYT9239FRE> # Optional field
      #
      # This section specifies how to extract the access token from the HTTP response
      session_credential_extractors:
        - name: access-token
          type: bearer_token
          location: body
          path: $$.access_token # JSON path expression to the location of the access token in the response. Do not modify unless different from OAuth defaults
  #
  #
  # This section specifies actual user information the test plan will use
  users:
    - name: user_1
      default: true # This user's credentials will be used for all authn-authz
      username: <Enter the username for whom you want to extract the access token>
      password_base64: <base64 password> # Passwords need to be base64 encoded
      scopes: # Optional field with a list of scopes
      #  E.g. - api.read
      #  E.g. - api.write
      authenticator: <friendly name of the authenticator specified above. E.g. oauth_2>
```

If using roles, please follow the [cookie extractor with roles](#extract-cookie-via-api-call-usage-with-roles) example above, and modify appropriately.

### Client Credentials Grant
The [Client Credentials Grant](https://www.oauth.com/oauth2-servers/access-tokens/client-credentials/) is used for service-to-service API authentication. Use this method when testing internal APIs that do not require end-user authentication, but require service-to-service authentication.

This method requires you to provide the following:
- The URL of the token generation API endpoint
- The URL of the refresh token generation API endpoint (optional)
- The *Client ID*, if it is required by your OAuth server
- The *Client Secret*, if it is required by your OAuth server
- A list of *scopes* for the user (optional)

Below is the syntax to enable *Client Credentials Grant*.

```YAML
iam:
  authenticators:
    - name: <Friendly name for this authenticator. E.g. oauth_2>
      type: oauth2 # Use OAuth protocol
      token_url: <Enter the URL for the token generation endpoint. E.g. https://my-oauth/oauth/access_token>
      grant_type: client_credential
      method: POST
      client_id: <Enter your client ID. E.g. 23lkjlekfjlskd90>
      client_secret: <Enter your client secret. E.g. UYT9239FRE>
      #
      # This section specifies how to extract the access token from the HTTP response
      session_credential_extractors:
        - name: access-token
          type: bearer_token
          location: body
          path: $$.access_token # JSON path expression to the location of the access token in the response. Do not modify unless different from OAuth defaults
  #
  #
  # This section specifies actual user information the test plan will use
  users:
    - name: user_1
      default: true # This user's credentials will be used for all authn-authz
      scopes: # Optional field with a list of scopes
      #  E.g. - api.read
      #  E.g. - api.write
      authenticator: <friendly name of the authenticator specified above. E.g. oauth_2>
```

If using roles, please follow the [cookie extractor with roles](#extract-cookie-via-api-call-usage-with-roles) example above, and modify appropriately.



[bearer-auth]: https://swagger.io/docs/specification/authentication/bearer-authentication/



---
sidebar_position: 5
---

# Providing Authorization Information for `Vertical Authorization Abuse` Test Cases
Testing for [`Vertical Authorization Abuse`][vertical-priv-abuse], requires credentials for additional users, and their associated role information.

User `role` information for API endpoints is provided in the API catalog via the [metadata.yml file](/guides/security-testing/concepts/api-catalog/metadata-yml.md). The metadata file specifies the various roles used by the API, and specific roles that apply to specific API endpoints.

While the metadata file is used to specify `role` information, the `environment.yml` file requires the provisioning of one or more users per role (as specified in the metadata file), and their respective authentication credentials.

For example if the metadata file has specified two roles (`ROLE_USER`, and `ROLE_ADMIN`), the autogenerated `environment.yml` file will have the below structure (assuming the default Bearer AuthN mechanism is being used).

```YAML
# Environment file that contains users, roles and their Authentication
# mechanisms that will be used by the API endpoints.
iam:
  users:
  # List all the users, their roles, username and password,
  # if required, in this section.
  # The default flag should be true if this user should be used
  # as the default user for that role. If there are no roles,
  # only one user should have default: True.
  - name: user_1
    default: true # Default user for `ROLE_USER`
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
    roles:
        - ROLE_USER
  - name: user_2
    bearer_tokens:
    - name: bearerAuth
      value: <Enter the bearer token>
    roles:
        - ROLE_ADMIN
```

If using an authentication mechanism other than Bearer AuthN, please modify the auto generated YAML appropriately.


[vertical-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Vertical



---
sidebar_position: 3
---

# How do I run a Data Driven Test Plan?
![](../../../../assets/data-driven-test-plan.svg)

Below are the high level steps for running a previously generated Data Driven Test Plan.

![](../../../../assets/task-run-data-driven-test-plan.svg)

### 1. Check Test Plan State

- If your Test Plan is in the `Config Complete` state, goto step 3 below.

- If your Test Plan is in the `Config in Progress` state, goto step 2 below.

- If your Test Plan is not in either of the above states, please contact Levo Support (support@levo.ai).

### 2. Configure Test Fixtures

Data Driven Test Plans may require some parameter data to be configured for the API endpoints, prior to execution.

Please follow detailed steps outlined [here](/guides/security-testing/test-your-app/test-app-security/data-driven/configure-plan-fixtures.md), to configure parameters via `Test Fixtures`.

Your test plan's `Runnable` status, and `number of test cases runnable` will auto update as you configure required parameters.

The Test Plan will be `Runnable` if at least one Test Case is runnable.

You can always continue to step 3, even if you have not completed configuring parameters for all Test Suites, and Test Cases. This is OK as long as the Test Plan is in the `Runnable` state.

Test Cases that are not runnable, will be skipped during execution of the Test Plan.

### 3. Download & Configure `environment.yml`
    
Your test plan `may` have an auto generated `environment.yml` associated with it.
    
If it was auto generated follow the steps outlined [here](/guides/security-testing/test-your-app/test-app-security/data-driven/configure-env-yml.md), to download and configure it appropriately.

### 2. Execute Test Plan via CLI

Follow instructions [here](/guides/security-testing/test-your-app/test-app-security/data-driven/execute-test-plan.md) to execute the Test Plan via the CLI (Test Runner).

### 3. View Test Results

In the Levo SaaS console side panel, click on `Test Runs` and navigate to your most recent test run results.

---
sidebar_position: 2
---

# How do I run a Zero Configuration Test Plan?
![](../../../../assets/zero-conf-test-plan.svg)

Below are the high level steps for running a previously generated Zero Configuration Test Plan.

![](../../../../assets/task-run-zero-conf-test-plan.svg)

### 1. Download & Configure `environment.yml`
    
Your test plan `may` have an auto generated `environment.yml` associated with it.
    
If it was auto generated follow the steps outlined [here](/guides/security-testing/test-your-app/test-app-security/zero-conf/configure-env-yml.md), to download and configure it appropriately.

### 2. Execute Test Plan via CLI

Follow instructions [here](/guides/security-testing/test-your-app/test-app-security/zero-conf/execute-test-plan.md) to execute the Test Plan via the CLI (Test Runner).

### 3. View Test Results

In the Levo SaaS console side panel, click on `Test Runs` and navigate to your most recent test run results.

---
sidebar_position: 1
---

# Running Test Plans via Levo CLI

### [How do I run a Zero Configuration Test Plan?](run-zero-conf-test-plan.md)
![](../../../../assets/zero-conf-test-plan.svg)


### [How do I run a Data Driven Test Plan?](run-data-driven-test-plan.md)
![](../../../../assets/data-driven-test-plan.svg)



---
sidebar_position: 1
---

# Concepts
Levo is purpose built for modern development teams, and developers.

Below are a few key concepts that should be pretty intuitive for developers and AppSec teams building API based applications.

### [API Catalog](api-catalog/api-catalog.md)

### [Test Plans](test-plans/test-plans.md)

### [Test Runner](test-runner.md)

### [Test Runs & Reports](test-run-reports.md)



---
sidebar_position: 7
---

# Test Run Reports
![](../../../assets/test-run-reports.svg)

The execution results of the Test Plans are reported to Levo SaaS by the CLI.

The CLI also provides a summary of execution results in the console. This summary is also available in the CI/CD logs (when integrated with CI/CD).





---
sidebar_position: 6
---

# CLI - Test Runner
![](../../../assets/cli-test-runner.svg)

The CLI is the component that executes the autogenerated Test Plans.

The CLI is is packaged as a Docker container, and can be run on a developer's laptop or integrated into CI/CD environments.

Levo provides pre-packaged runner/actions integrations for several popular CI/CD products.



---
sidebar_position: 1
keywords: [API Catalog, OpenAPI Specifications]
---

# API Catalog
Levo autogenerates security and resilience tests for APIs based on schema definitions for API endpoints.

These schemas can either be auto discovered (by observing runtime traffic) or imported into Levo.

The API Catalog is a store and directory for the aforementioned schemas. 

![](../../../../assets/api-catalog-structure-1.svg)
![](../../../../assets/api-catalog-structure-2.svg)

The catalog is comprised of `Applications`, and `Services`. An `Application` is a logical grouping of a set of API endpoints.

An `Application` can contain one or more `Services`, where a `Service` is another logical grouping of a set of API endpoints.

This type of organization is very common in [Microservices Architecture (MSA)][msa].

[msa]: https://aws.amazon.com/microservices/



---
sidebar_position: 2
keywords: [API Authorization, Roles, Scopes]
---

# Metadata.yml file

## What is it?

Often API endpoints enforce granular authorization controls on users/clients using role based access control (RBAC) mechanisms. Effective security testing involves evaluating the proper configuration and functioning of these RBAC controls.

Currently there is no industry standard way to express RBAC information in OpenAPI specifications.

The `metadata.yml` allows associating RBAC information with API endpoints present in Levo's API Catalog.

Associating RBAC information with API endpoints in the API catalog is completely optional. However, if testing authorization controls is desired, then providing RBAC information via the `metadata.yml` file is mandatory.

## Are there other uses for this file?
RESTful APIs operate on resources, and provide `CRUD` operations on those resources. Effective security also requires evaluating the proper functioning of state transitions that happen across these `CRUD` operations.

The `metadata.yml` also allows grouping API endpoints for specific resources, so that Levo can auto generate tests that evaluate the consistency of state changing `CRUD` operation sequences.

## How do I provide RBAC information for my API endpoints?
You can get detailed information [here](/guides/security-testing/common-tasks/api-rbac)

---
sidebar_position: 3
---

# Creating a Test Plan

Click on `New Test Plan` to start creating a test plan.

Choose from `Zero-configuration` or `Data-Driven` testing.

Select the application you want to create the Test Plan for from the list of your applications.

Fill in the necessary details and choose the endpoints you want to run your tests against.

Click on Next and select the categories of test you want to run from and choose from a wide variety of Tests like BOLA, SQLI, CORS, Fuzzing, etc.

Click on `Generate Test Plan` to finish creating the test plan.

> Note: In case of Data-Driven Testing, configure the environment.yaml file (you can read more aout it in the next section).

---
sidebar_position: 3
---

# Environment.yml file

Most API endpoints require some form of user/client authentication. In addition, API endpoints may also enforce granular authorization controls on users/clients using role based access control (RBAC) mechanisms.

Effective security testing requires providing valid users and their respective authentication credentials to Levo's autogenerated Test Plans.

This information can be provided in a secure, and structured manner via an `environment.yml` file.

## How do I use `environment.yml` file?

The `environment.yml` file is autogenerated per `Test Plan`, and needs to be completed with appropriate user/authentication information, prior to the execution of the Test Plan.

The completed file is provided as an argument to the CLI. The CLI uses the credentials to access the target APIs and evaluate their security posture.

## Are my `secrets` sent to Levo SaaS?

The `environment.yml` file contains `secrets` and is **never** sent to, or stored in Levo SaaS. This file is solely consumed by the CLI, and Levo SaaS does not have access to your secrets.

Please treat this file securely, and take all precautions necessary for handling secrets.

## Tell me more
You can find more information on providing authentication/authorization information for tests [here](/guides/security-testing/common-tasks/authn-authz)


---
sidebar_position: 2
---

# Test Plan Types
At a high level test plans come in two flavors:

1. Zero Configuration (zero conf)
2. Data Driven 

![](../../../../assets/test-plan-types.svg)



## Zero Configuration vs. Data Driven

|                                                              | Zero Configuration | Data Driven                                                |
| :----------------------------------------------------------- | :-------------------- | :------------------------------------------------------------ |
| **Time to Value**                                         | Instant              | Requires One Time Configuration                              |
| **Test Category Coverage**                                 | Reduced              | Comprehensive                                                |
| **Efficacy of Test Results**                               | Moderate             | Superior                                                     |
| **Horizontal Authorization Abuse Coverage (BOLA / IDOR)**  | No                   | Yes                                                          |
| **Vertical Authorization Abuse Coverage (Privilege Escalation)** | Yes                  | Yes                                                          |
| **Coverage for API Methods (GET, POST, etc.)**             | All Methods          | <ul><li>All Methods.</li> <li>PUT, POST, PATCH, & DELETE require additional configuration to support stateful operations on resources.</li></ul> |
| **Primary Use Case**                                       | Rapid Assessments    | Deep / Comprehensive Assessments                             |

## Zero Configuration

Zero Configuration test plans are instantly runnable, and only require specifying user authentication information.

These test plans use type information specified in the API schema to autogenerate data for various parameters required by the API.

For example is a string field in a POST body is of format type `email`, the test plan will autogenerate syntactically valid email addresses.

However there is no guarantee that the generated values are truly valid for the API endpoint being tested (the values may not exist in the backend database, etc.). Since parameter data is autogenerated, these test plans provide less security test coverage, and lower efficacy that Data Driven test plans.

For example, APIs often return `404 Not Found` in lieu of `401 Unauthorized` or `403 Forbidden` during authentication/authorization failures. This is prevent hackers from enumerating resources.

Zero Configuration test plans cannot truly distinguish between an authentication/authorization failure and the absence of the requested resource in the API's backend database.

This results in lower efficacy and reduced test coverage (results might have false negatives).

## Data Driven
As the name suggests, parameter data for APIs is end user supplied via [fixtures](fixtures/test-fixtures.md).

By configuring parameter data, end users have complete control of what data is send when making API calls. 

This dramatically increases efficacy of test results and test coverage, as the test plans can clearly distinguish between, authentication/authorization failures and the absence of the requested resource.



---
sidebar_position: 1
keywords: [API Security Testing, API Security Test Plan]
---

# Test Plans
Autogenerated `Test Plans` are tailor-made for each API (and it's associated endpoints).

![API Security Test Plan](../../../../assets/test-plans.svg)

Test Plans can be generated for APIs present in either the `Application` or `Service` (API Catalog) groupings.

A Test Plan is structured as show below.
![](../../../../assets/test-plan-structure-1.svg)

A Test plan is comprised of `Test Suites`. A Test Suite is focussed on a single API endpoint, and comprises of a set of `Test Cases`.

A `Test Case` has a singular objective, and tests the specific API endpoint for a specific vulnerability. For example, test the API endpoint for a [SSRF][SSRF-lnk] vulnerability, or an authorization bypass vulnerability.


[SSRF-lnk]: /vulnerabilities/v1/OWASP-WEB-10/A10-SSRF

---
sidebar_position: 2
---

# Configuring Test Fixtures

## Test Case Level Fixtures
![](../../../../../assets/test-case-unbound-api-param.png)

Above is an example of a test case for the endpoint `GET /identity/api/v2/vehicle/{vehicleId}/location`.

This endpoint requires a valid value for path parameter `{vehicleId}` for successful invocation. This requirement
is shown in the *`Parameters`* table in the test case. `Not Bound` indicates that a valid value is required to execute
this test case.

Levo autogenerates fixtures for these required API parameters. These autogenerated fixtures are located in the `parameters.py` code block of the test case (see below).

![](../../../../../assets/test-case-api-param-fixture.png)

Here is a zoom in view of the autogenerated (commented-out) fixture for `vehicleId`:
```python
#@levo.fixture(name="vehicleId", location="path")
#def vehicleid():
#    return "Enter Your Value Here."
#
```

### Steps to Configure Fixture

1. Block select the fixture code in the editor, and use `CMD + /` to uncomment the fixture code.

```python
@levo.fixture(name="vehicleId", location="path")
def vehicleid():
    return "Enter Your Value Here."

```

2. Now enter a value for the `vehicleId` that is valid for your live API endpoint that you want to test.

```python
@levo.fixture(name="vehicleId", location="path")
def vehicleid():
    return "649acfac-10ea-43b3-907f-752e86eff2b6"
```

In the above example `649acfac-10ea-43b3-907f-752e86eff2b6` is the value that will be used for `vehicleId`,
when executing this test case against a live API target.

3. Remember to save the changes you made.

#### You are done!

---
sidebar_position: 1
---

# Test Fixtures for API Parameters

## What are test fixtures?

[Software test fixtures][fixtures] initialize test functions. They provide a fixed baseline so that tests execute reliably and produce consistent, repeatable, results.

[JUnit Fixtures][junit], and [PyTest Fixtures][pytest] are pretty commonly used by modern development teams.

Initialization may setup services, state, or provide seed values to (mandatory & optional) API input parameters, so that the API invocation succeeds.

For example, effective testing of the API endpoint `GET /ride_receipts/{receipt_id}`, might require a 
known and valid value for the `{receipt_id}` parameter, which is present in the receipts database.

Without this known seed value, the test that exercises this API endpoint might not get a proper response from the API endpoint. Fixtures allow providing this seed value for the `{receipt_id}` parameter.

## Levo's Test Fixtures
Levo provides fixtures for configuring seed values for various API endpoint parameters. These fixtures are available at the `Test Case` level, `Test Suite` level, and `Test Plan` level as shown below.

Fixtures at the `Test Suite` level will automatically apply to all `Test Cases` within that `Test Suite`. Fixtures ate the `Test Plan` level will apply to all `Test Suites`.

![](../../../../../assets/fixtures.svg)

## Test Fixture Format

![](../../../../../assets/get-vehicle-id-ep.png)

Above is an example of an API endpoint that has `{vehicleId}` as a path parameter. This endpoint checks if the vehicle specified by the `{vehicleId}` is present in it's database.

If the specified vehicle is present, it returns `200 OK` and the vehicle details. If not present it returns `404 Not Found` and an appropriate error message.

In order to effectively test this endpoint for various security vulnerabilities, we need to know the ID of at least one legitimate vehicle present in the API server's database. Using random values for `{vehicleId}` will not exercise all code paths within the endpoint's implementation, largely resulting in 404 responses.

Below is an example of a test fixture that allows specifying a legitimate `{vehicleId}` value to be used when testing the endpoint.

```python
@levo.fixture(name="vehicleId", location="path")
def vehicleid():
    return "649acfac-10ea-43b3-907f-752e86eff2b6"
```

While the example above returns a hardcoded value, the fixture could be coded to perform a database lookup, or make an API call to get the appropriate value.

## Auto Generation of Fixtures
Levo auto generates test fixtures for various mandatory API parameters, and configures them with example values provided in the OpenAPI schema. Skeleton fixtures are generated in cases where example values are not available.

You can always modify and customize the auto generated fixtures to suit specific needs.


[fixtures]: https://en.wikipedia.org/wiki/Test_fixture#Software
[junit]: https://github.com/junit-team/junit4/wiki/Test-fixtures
[pytest]: https://docs.pytest.org/en/6.2.x/fixture.html

---
sidebar_position: 1 
---

# Sample Applications For Evaluating Levo

![](../../../assets/sample-apps.svg)

Levo provides sample applications that help you evaluate security and resilience testing capabilities.

You can download these applications and follow instructions to test them with Levo.

- [Completely Ridiculous API (crAPI)](crapi/crapi.md) for security testing
- [MalSchema](https://github.com/levoai/demo-apps/blob/main/MalSchema/README.rst) for schema conformance testing



---
sidebar_position: 2
---

# CrAPI Sample App - Part 1

## 1. Install crAPI
1. Install the crAPI demo application by following instructions [here][install-crapi].

2. [Download][crapi-openapi-spec] and save crAPIs OpenAPI specification (OAS).

3. Verify crAPI is running by logging in, using one of the user credentials provided [here][crapi-credentials].

## 2. Import crAPI APIs into Levo SaaS
1. Login into the Levo SaaS portal.

2. Click on `API Catalog` in the side panel and proceed to import crAPIs OAS (saved in step above).

3. In the import dialog name this API catalog as `My crAPI`, and complete the import.

## 3. Upload a metadata.yml file to enable authorization bypass (RBAC) tests
crAPI's APIs have role based access controls (RBAC). If want to validate the proper configuration and functioning of the said controls, you will need to construct a metadata.yml file and upload it to the catalog created in the previous step.

You can read more about authorization bypass tests and the metadata.yml file [here](/guides/security-testing/concepts/api-catalog/metadata-yml.md).

For your convenience, the appropriate metadata.yml for crAPI is shown below. Please upload this to catalog via the `Metadata` tab in the catalog UI.

```YAML
# metadata.yml file for crAPI that describes RBAC for API endpoints
#
roles:
# This section captures the set of roles that are available to be associated with the API endpoints
  - role: ROLE_USER
    description: This role provides specific entitlements for regular users
  - role: ROLE_MECHANIC
    description: This role provides specific entitlements for mechanics
  - role: ROLE_ADMIN
    description: This role provides specific entitlements for administrators
#
api:
# This section defines actual associations between API endpoints and roles at the global level
# This can be overridden at the individual API endpoint level
  roles:
    - ROLE_USER
    - ROLE_MECHANIC
    - ROLE_ADMIN
  # The default role (and an associated user) that should be used to access all endpoints
  # This can be overridden at the individual API endpoint level
  default_role: ROLE_USER
  endpoints:
    # This section defines API endpoint specific overrides
    #
    - endpoint: GET /identity/api/v1/admin/users/find
      roles:
        - ROLE_ADMIN
      default_role: ROLE_ADMIN
    - endpoint: GET /identity/api/v2/vehicle/{vehicleId}/location
      roles:
        - ROLE_ADMIN
        - ROLE_USER
      default_role: ROLE_USER
    - endpoint: GET /workshop/api/mechanic/mechanic_report
      roles:
        - ROLE_ADMIN
        - ROLE_USER
      default_role: ROLE_USER
    - endpoint: GET /workshop/api/merchant/contact_mechanic
      roles:
        - ROLE_ADMIN
        - ROLE_USER
      default_role: ROLE_USER
    - endpoint: GET /workshop/api/shop/orders/{order_id}
      roles:
        - ROLE_USER
```

## 4. Generate a security test plan for crAPI's APIs
1. Click on `Test Plans` in the side panel and proceed to create a test plan by clicking `New Test Plan`.

2. Pick `Data Driven` as the type of test plan to generate.

3. In the `New Test Plan` dialog name the plan as `My crAPI Test Plan`. Pick `My crAPI` as the API asset for this test plan.

4. Check the check box named **`Auto-populate API parameters for this test plan`**.

    > This uses examples in the OpenAPI specification file to auto populate [test fixtures/API parameters][fixtures] that are required in the generated test plan.
    The example values are used in making API requests during test execution.

5. Proceed to generate the test plan.

6. You will now have a test plan called `My crAPI Test Plan` in the `Config Complete` state.

7. **Copy** the LRN (Levo Resource Name) of `My crAPI Test Plan` to the clipboard.

8. Open the test plan `My crAPI Test Plan`, navigate to the `environment.yml` section, 
and download this file to your desktop. You can read more about the purpose of the file [here][env-file].

[install-crapi]: https://github.com/levoai/demo-apps/blob/main/crAPI/docs/quick-start.md
[crapi-openapi-spec]: https://raw.githubusercontent.com/levoai/demo-apps/main/crAPI/api-specs/demo%20scenarios/onboarding-scenarios.json
[crapi-credentials]: https://github.com/levoai/demo-apps/blob/main/crAPI/docs/user-asset-info.md#user-info
[fixtures]: /guides/security-testing/concepts/test-plans/fixtures/test-fixtures.md
[env-file]: /guides/security-testing/concepts/test-plans/env-yml.md


---
sidebar_position: 3
---

# CrAPI Sample App - Part 2

The test plan created was auto configured as you selected `Auto-populate API parameters for this test plan` in the previous step.

Just like developers run tests using JUnit, & PyTest `fixtures`, Levo's test plans use [fixtures][fixtures] to drive tests. The fixtures provide seed values for API parameters required for the proper execution of the tests.

Levo used examples in the OpenAPI specification to auto populate these fixtures.

## 5. Install Levo CLI & Login
Levo CLI is the test runner that will execute the test plan against your running instance of crAPI.

Follow the instructions [here][levo-cli] to install Levo CLI and authenticate it with Levo SaaS.

Skip this step if you have already completed it.

## 6. Execute the test plan against crAPI

Now we will use the Levo CLI to execute the test plan.

### Prerequisites
- Ensure you copied the `LRN (Levo Resource Name)` to the clipboard in the previous step.
- Ensure you downloaded the `environment.yml` file from the test plan to your desktop.
- Ensure the `environment.yml` file is in the same directory from which you launch Levo CLI. You may need to copy the file to the directory from where you launch the CLI.

Execute the following in the shell where you installed Levo CLI:

```
# Use `host.docker.internal` instead of `localhost` or `127.0.0.1` if crAPI is running on your local machine.
# Modify the --target-url value below if crAPI is running elsewhere.

export TEST_PLAN_LRN="<LRN value copied to your clipboard in previous steps>"

# Execute security tests against crAPI 
levo test --test-plan $TEST_PLAN_LRN --target-url http://host.docker.internal:8888 --env-file environment.yml
```

## View the test results in the `Test Runs` page
1. In the Levo SaaS console side panel, click on `Test Runs` and navigate to your most recent test run results
2. You will notice that Levo has found failed test cases and an [Broken Object Level Authorization][BOLA] vulnerability. Navigate to the BOLA test case status, and review the summary and the logs.

## Verify results using crAPI's Hackpad (Optional)
Inside `crAPI`, use the top level menu to navigate to `Hackpad`. Follow instructions in the `Hackpad` to verify if the IDOR finding reported by Levo is a true positive.

## Congratulations! You are done.


[fixtures]: /guides/security-testing/concepts/test-plans/fixtures/test-fixtures.md
[levo-cli]: /security-testing/test-laptop
[BOLA]: /vulnerabilities/v1/OWASP-API-10/A1-BOLA

---
sidebar_position: 1
---

# Evaluate Levo using the sample application `crAPI`

You can read more about crAPI [here](https://github.com/levoai/demo-apps/blob/main/crAPI/README.md). Below are high level steps to launch and security test crAPI's APIs.

### [crAPI - Part I](crapi-part-1.md)
Part I covers:
- Installing crAPI.
- Importing crAPI's OpenAPI specifications.
- Generating a tailored security test plan for crAPI.

### [crAPI - Part II](crapi-part-1.md)
Part II covers:
- Running the test plan.
- Viewing the test results.

---
sidebar_position: 2
---

# Using your own app to evaluate Levo's schema conformance testing

Ensure your target application is running and note down its URL.

Use `host.docker.internal` instead of `localhost` or `127.0.0.1` for targets on your local machine.

## I use a live URL for my OpenAPI v3 specifications
Execute the following in the shell where you installed Levo CLI:

```
export SCHEMA_URL="<your live schema's URL>"
export TARGET_URL="<your live target's URL>"

# Run all schema conformance tests for all my API operations
levo test-conformance --schema $SCHEMA_URL --target-url $TARGET_URL

# Provide custom headers (e.g. Authorization if required)
levo test-conformance --schema $SCHEMA_URL --target-url $TARGET_URL -H "Authorization: Bearer <token>"

```
Now you can view the test results in the https://levo.ai SaaS console's `Test Runs` page.

## I use a local JSON or YAML file my OpenAPI v3 specifications
Levo CLI can accept schemas (OASv3, Swagger, etc.) as a file rather than a live URL. The Levo CLI container, mounts the user's HOME directory (on the host), as readonly directory inside the container.

Execute the following in the shell where you installed Levo CLI:

```
export SCHEMA_FILE="<your schema file's absolute path from the $HOME directory>"
export TARGET_URL="<your live target's URL>"

# Run all schema conformance tests for all my API operations
levo test-conformance --schema $SCHEMA_FILE --target-url $TARGET_URL

# Provide custom headers (e.g. Authorization if required)
levo test-conformance --schema $SCHEMA_FILE --target-url $TARGET_URL -H "Authorization: Bearer <token>"

```
Now you can view the test results in the https://levo.ai SaaS console's `Test Runs` page.


---
sidebar_position: 1
---

# How do I use Levo with my own applications?

![](../../../assets/api.svg)


First review the [Concepts][concepts] section. Then follow these steps:

#### Setup Levo CLI & sign up on Levo.ai
* [Levo CLI for Mac OS][mac]
* [Levo CLI for Linux][linux]
* [Levo CLI for Windows][windows]

#### Pick your use case & follow instructions

* [Automatically test APIs for security vulnerabilities][use-my-app-for-security-tests]

* [Automatically test APIs for schema conformance][use-my-app-for-schema-tests]



[concepts]: /guides/security-testing/concepts
[mac]: /security-testing/test-laptop/test-mac-os.md
[linux]: /security-testing/test-laptop/test-linux.md
[windows]: /security-testing/test-laptop/test-windows.md

[use-my-app-for-schema-tests]: test-app-schema-conformance.md
[use-my-app-for-security-tests]: test-app-security/choices.md



---
sidebar_position: 1
---

# Automatically test APIs for security vulnerabilities

## [I want effortless and instant testing](zero-conf/zero-conf.md)
![](../../../../assets/zero-conf-test-plan.svg)

    Does not require data provisioning or parameter configuration
   
    Runs instantly 

    Reduced security test coverage

    Reduced efficacy of test results

## [I want comprehensive test coverage and better efficacy](data-driven/data-driven.md)
![](../../../../assets/data-driven-test-plan.svg)


    Best security test coverage

    Best efficacy of test results

    Requires data/parameter configuration for API endpoints

    May require associating API endpoints with RBAC info via a metadata.yml file

---
sidebar_position: 5
---

# Configure `environment.yml`
![](../../../../../assets/data-driven-test-plan.svg)

![](../../../../../assets/data-driven-flow-4.svg)

***Note: If your test plan does not have a `environment.yml` file associated with it you can skip this step, and proceed to the next.***

Each auto generated test plan *may* have a `environment.yml` file associated with it, which provides critical authentication/authorization information for your APIs.

You can read more about this file [here][env-file]. 

*You will need to configure this file with appropriate authentication/authorization information prior to executing the test plan.*

## 1. Download the `environment.yml` file
In your test plan, navigate to the `environment.yml` section, and download this file to your desktop.

## 2. Configure the `environment.yml` file
Follow the instructions [here][configure-authn] to configure appropriate user credentials/roles required to effectively test your live API endpoints.


[env-file]: /guides/security-testing/concepts/test-plans/env-yml.md
[configure-authn]: /guides/security-testing/common-tasks/authn-authz


---
sidebar_position: 4
---

# Configure Test Plan Fixtures
![](../../../../../assets/data-driven-test-plan.svg)

![](../../../../../assets/data-driven-flow-3.svg)


## 1. Configure your `Config in Progress` test plan
Levo uses [test fixtures][fixtures] to provide proper values to API parameters prior to sending test traffic to the live API endpoints.

This test plan requires configuration of these test fixtures prior to execution. Proper configuration of the test plan will make it runnable.

1. Open the test plan and navigate to the test cases that require configuration (test cases are under test suites). Check the test case documentation for specific parameters that need configuration. Uncomment the auto-generated fixtures and follow this [example][fixture-example], to configure values that are appropriate for your live API target.

2. Continue this process until either the test plan's state changes to `Config Complete`, or you have enough test cases/suites that are runnable.

3. Remember to `save` your changes to the test plan.


[example-values]: https://swagger.io/docs/specification/adding-examples/
[fixtures]: /guides/security-testing/concepts/test-plans/fixtures/test-fixtures.md
[fixture-example]: /guides/security-testing/concepts/test-plans/fixtures/configure-fixtures.md


---
sidebar_position: 1
---


# Data Driven Security Tests
![](../../../../../assets/data-driven-test-plan.svg)

The below figure describes the high level workflow for the generation and execution of [Data Driven](/guides/security-testing/concepts/test-plans/test-plan-types.md) security tests.

![](../../../../../assets/data-driven-flow.svg)

Just follow the steps in this guide, to generate and execute security tests against your APIs.


---
sidebar_position: 6
---

# Execute Test Plan
![](../../../../../assets/data-driven-test-plan.svg)

![](../../../../../assets/data-driven-flow-5.svg)

## 1. Copy the test plan's Levo Resource Name (LRN)
From the test plans screen **copy** the LRN (Levo Resource Name) of your test plan to the clipboard.

## 2. Install Levo CLI & Login
Skip this step if you have already completed it.

Levo CLI is the test runner that will execute the test plan against your running instance of crAPI.

Follow the instructions [here][levo-cli] to install Levo CLI and authenticate it with Levo SaaS.

## 3. Execute the test plan against you live API endpoints

Now we will use the Levo CLI to execute the test plan.

### Prerequisites
- Ensure you copied the `LRN (Levo Resource Name)` to the clipboard in the previous step.
- Ensure you downloaded the `environment.yml` file (***if present***) from the test plan to your desktop.
- Ensure the `environment.yml` file (***if present***) is in the same directory from which you launch Levo CLI. You may need to copy the file to the directory from where you launch the CLI.

Execute the following in the shell where you installed Levo CLI:

```
# Use `host.docker.internal` instead of `localhost` or `127.0.0.1` if your API is running on your local machine.

levo test --test-plan <LRN value copied to clipboard > --target-url <your live API's base URL> --env-file environment.yml
```
**Note**: If your test plan does not have an `environment.yml` file associated with it, please do not specify the `--env-file` option above.

## 4. View the test results in the `Test Runs` page
In the Levo SaaS console side panel, click on `Test Runs` and navigate to your most recent test run results

## Congratulations! You are done.


[levo-cli]: /security-testing/test-laptop



---
sidebar_position: 3
---


# Auto Generate Test Plan
![](../../../../../assets/data-driven-test-plan.svg)

![](../../../../../assets/data-driven-flow-2.svg)

## 1. Generate a security test plan for your APIs

1. Click on `Test Plans` in the side panel and proceed to create a test plan by clicking `New Test Plan`.

2. Pick `Data Driven` as the type of test plan to generate.

3. In the `New Test Plan` dialog pick a suitable name for the plan. 

4. Pick the previously imported API catalog as the API asset for this test plan.

5. If your API specification has [example values][example-values], and these example values will work with your live API endpoints, then check the check box named **`Auto-populate API parameters for this test plan`**.

    > This uses examples in the OpenAPI specification file to auto populate [test fixtures/API parameters][fixtures] that are required in the generated test plan.
    The example values are used in making API requests during test execution.

6. Proceed to generate the test plan. The generated test plan will have coverage for several security vulnerabilities.

7. Depending on if you used `Auto-populate API parameters for this test plan`, in the previous step, and how comprehensive the provided examples are, your newly generated test plan with either be in the `Config Complete` or `Config in Progress` states.

8. If your test plan is in the `Config Complete` state, it is immediately runnable, and you can proceed to [**Configure environment.yml**][download-env-step].

9. If your test plan is in the `Config in Progress` state, you will need to configure values for API parameters using [test fixtures][fixtures].
The next section describes the processing of configuring API parameter values via fixtures.


[example-values]: https://swagger.io/docs/specification/adding-examples/
[fixtures]: /guides/security-testing/concepts/test-plans/fixtures/test-fixtures.md
[download-env-step]: configure-env-yml.md


---
sidebar_position: 2
---


# Import API Specifications
![](../../../../../assets/data-driven-test-plan.svg)

![](../../../../../assets/data-driven-flow-1.svg)

Levo requires OpenAPI specifications for security test generation. If you already have OpenAPI specifications, you can simply import them into the API Catalog.

Otherwise OpenAPI specifications can be generated via one of the following methods:
- Auto-generate OpenAPI from live traffic via Levo's [API Observability](/guides/api-observability.md) solution
- If you have Postman Collections, use [postman-to-openapi](https://github.com/levoai/postman-to-openapi) to generate OpenAPI from your collections
- If you have HAR files, you can contact `support@levo.ai` to have them converted to OpenAPI specifications

## 1. Import your APIs into Levo SaaS

If you are using an auto-generated `API Catalog`, pick your `Application` from the catalog and go to the next step.

1. Login into the Levo SaaS portal.

2. Click on `API Catalog` in the side panel and proceed to import you App's API specifications.

3. Select the catalog type as `Application`, and pick a suitable name for this catalog.

4. Complete the import, and verify if the API endpoints are visible in the catalog.

## 2. Upload a metadata.yml file to enable authorization bypass (RBAC) tests
If you are trying Levo for the first time, we recommend you skip this step and proceed to the next step.

If you have role based access controls (RBAC) for your APIs, and you wish to validate the proper configuration and functioning of the said controls, you will need to construct a metadata.yml file and upload it to the catalog created in the previous step.

You can read more about authorization bypass tests and the metadata.yml file [here](/guides/security-testing/concepts/api-catalog/metadata-yml.md).

Please construct an appropriate metadata.yml for your API endpoints and upload it via the `Metadata` tab for your API catalog in the Levo SaaS UI.



---
sidebar_position: 4
---

# Configure `environment.yml`
![](../../../../../assets/zero-conf-test-plan.svg)

![](../../../../../assets/zero-conf-flow-3.svg)

***Note: If your test plan does not have a `environment.yml` file associated with it you can skip this step.***

Each auto generated test plan *may* have a `environment.yml` file associated with it, which provides critical authentication/authorization information for your APIs.

You can read more about this file [here][env-file]. 

You will need to configure this file with appropriate authentication/authorization information prior to executing the test plan.

## 1. Download the `environment.yml` file
Open your test plan, navigate to the `environment.yml` section, and download this file to your desktop.

## 2. Configure the `environment.yml` file
Follow the instructions [here][configure-authn] to configure appropriate user credentials/roles required to effectively test your live API endpoints.


[env-file]: /guides/security-testing/concepts/test-plans/env-yml.md
[configure-authn]: /guides/security-testing/common-tasks/authn-authz


---
sidebar_position: 5
---

# Execute Test Plan
![](../../../../../assets/zero-conf-test-plan.svg)

![](../../../../../assets/zero-conf-flow-4.svg)

## 1. Copy the test plan's Levo Resource Name (LRN)
From the test plans screen **copy** the LRN (Levo Resource Name) of your test plan to the clipboard.

## 2. Install Levo CLI & Login
Skip this step if you have already completed it.

Levo CLI is the test runner that will execute the test plan against your running instance of crAPI.

Follow the instructions [here][levo-cli] to install Levo CLI and authenticate it with Levo SaaS.

## 3. Execute the test plan against you live API endpoints

Now we will use the Levo CLI to execute the test plan.

### Prerequisites
- Ensure you copied the `LRN (Levo Resource Name)` to the clipboard in the previous step.
- Ensure you downloaded the `environment.yml` file (***if present***) from the test plan to your desktop.
- Ensure the `environment.yml` file (***if present***) is in the same directory from which you launch Levo CLI. You may need to copy the file to the directory from where you launch the CLI.

Execute the following in the shell where you installed Levo CLI:

```
# Use `host.docker.internal` instead of `localhost` or `127.0.0.1` if your API is running on your local machine.

levo test --test-plan <LRN value copied to clipboard> --target-url <your live API's base URL> --env-file environment.yml
```

**Note**: If your test plan does not have an `environment.yml` file associated with it, please do not specify the `--env-file` option above.

## 4. View the test results in the `Test Runs` page
In the Levo SaaS console side panel, click on `Test Runs` and navigate to your most recent test run results

## Congratulations! You are done.



[levo-cli]: /security-testing/test-laptop


---
sidebar_position: 3
---


# Auto Generate Test Plan
![](../../../../../assets/zero-conf-test-plan.svg)

![](../../../../../assets/zero-conf-flow-2.svg)


## 1. Generate a security test plan for your APIs

1. Click on `Test Plans` in the side panel and proceed to create a test plan by clicking `New Test Plan`.

2. Pick `Zero Config` as the type of test plan to generate 

3. In the `New Test Plan` dialog pick a suitable name for the plan. 

4. Pick the previously imported API catalog as the API asset for this test plan.

5. Proceed to generate the test plan. The generated test plan will have coverage for several security vulnerabilities.
    > Zero Config Test Plans do not support horizontal authorization bypass ([BOLA][bola]) tests. If you skipped providing RBAC association info via the metadata.yml file, no tests for vertical authorization bypass ([BFLA][bfla]) will be generated.

6. Your new test plan will be in the `Config Complete` state, and is immediately runnable. Please proceed to the next step.


[bola]: /vulnerabilities/v1/OWASP-API-10/A1-BOLA
[bfla]: /vulnerabilities/v1/OWASP-API-10/A5-BFLA





---
sidebar_position: 2
---


# Import API Specifications
![](../../../../../assets/zero-conf-test-plan.svg)

![](../../../../../assets/zero-conf-flow-1.svg)

Levo requires OpenAPI specifications for security test generation. If you already have OpenAPI specifications, you can simply import them into the API Catalog.

Otherwise OpenAPI specifications can be generated via one of the following methods:
- Auto-generate OpenAPI from live traffic via Levo's [API Observability](/guides/api-observability.md) solution
- If you have Postman Collections, use [postman-to-openapi](https://github.com/levoai/postman-to-openapi) to generate OpenAPI from your collections
- If you have HAR files, you can contact `support@levo.ai` to have them converted to OpenAPI specifications

## 1. Import your APIs into Levo SaaS

If you are using an auto-generated `API Catalog`, pick your `Application` from the catalog and go to the next step.

1. Login into the Levo SaaS portal.

2. Click on `API Catalog` in the side panel and proceed to import you App's API specifications.

3. Select the catalog type as `Application`, and pick a suitable name for this catalog.

4. Complete the import, and verify if the API endpoints are visible in the catalog.

## 2. Upload a metadata.yml file to enable authorization bypass (RBAC) tests
If you are trying Levo for the first time, we recommend you skip this step and proceed to the next step.

If you have role based access controls (RBAC) for your APIs, and you wish to validate the proper configuration and functioning of the said controls, you will need to construct a metadata.yml file and upload it to the catalog created in the previous step.

You can read more about authorization bypass tests and the metadata.yml file [here](/guides/security-testing/concepts/api-catalog/metadata-yml.md).

Please construct an appropriate metadata.yml for your API endpoints and upload it via the `Metadata` tab for your API catalog in the Levo SaaS UI.



---
sidebar_position: 1
---


# Zero Conf Security Tests
![](../../../../../assets/zero-conf-test-plan.svg)

The below figure describes the high level workflow for the generation and execution of [Zero Configuration](/guides/security-testing/concepts/test-plans/test-plan-types.md) security tests.

![](../../../../../assets/zero-conf-flow.svg)

Just follow the steps in this guide, to generate and execute security tests against your APIs.


---
sidebar_position: 0
---

# Install Satellite

## 1. Prerequisites
- You have an account on [Levo.ai](https://app.levo.ai/login)
:::info
Depending on the region you are installing in, you may need to use [Levo.ai India-1](https://app.india-1.levo.ai/login) to create account.
:::
- [OS Compatibility script](/guides/general/os-compat-check.mdx) indicates the Linux host (that you want to instrument with the Sensor) is compatible.
- At least 4 CPUs
- At least 8 GB RAM
- The Satellite URL should be reachable from the Sensor.
  - The Collector listens for spans from the eBPF Sensor on port 4317 using HTTP/2 (gRPC), and port 4318 using HTTP/1.1. 
  - The Satellite listens for spans from the PCAP Sensor on port 9999 using HTTP/1.1.

## 2. Copy `Authorization Key` from Levo.ai

The Satellite uses an authorization key to access Levo.ai.

- [Login](https://app.levo.ai/login) to Levo.ai.
- Click on your user profile.
- Click on `User Settings`
- Click on `Keys` on the left navigation panel
- Click on `Get Satellite Authorization Key`

Copy your authorization key. This key is required in subsequent steps below.


## 3. Follow instructions for your platform
- [Install on Kubernetes](satellite-kubernetes.md)
- [Install on Linux host via Docker Compose](satellite-docker.mdx)
- [Install in AWS EC2 using Levo Satellite AMI](satellite-ami-aws-ec2.mdx)
- [Install in AWS EKS](satellite-aws-eks.md)
  - [Install in AWS EKS using EC2](satellite-aws-ecs.mdx)
  - [Install in AWS EKS using Fargate](satellite-aws-eks-fargate.md)
- [Install in AWS ECS](satellite-aws-ecs.mdx)



---
sidebar_position: 5
---

# Satellite on AWS EKS using Fargate

Fargate allows us to have containers without the overhead of managing and scaling servers and clusters. AWS handles the maintenance, as well as security and health of the instances for us, which is something we would not want to spend time into.

### 1. Setup environment variables

```bash
export CLUSTER_NAME='Cluster Name'
export REGION='AWS Region'
export ACCOUNT_ID='AWS Account ID'
```

### 2. Cluster creation

To create a cluster using Fargate, run

```bash
eksctl create cluster --name ${CLUSTER_NAME} --region ${REGION} --fargate 
```

`--fargate` specifies that the cluster needs to run on fargate, and initially assigns 2 fargate nodes to us


It can be checked by running `kubectl get nodes` . The output would be something like this:
```bash
fargate-ip-192.168.1.1.<aws-region>.compute.internal   Ready    <none>   1m   v1.25
fargate-ip-192-168-1.1.<aws-region>.compute.internal   Ready    <none>   1m   v1.25
```


### 3. Connecting to the cluster

AWS EKS grants cluster admin permissions to the account from which the cluster is created. If you don't need access to the cluster for other AWS Users, you can skip this section.

Access to other AWS users in the same account can be granted via 2 ways.
- [Adding individual access to user accounts](#adding-individuals-to-the-cluster)
- [Giving the permissions to a user group](#giving-access-to-an-iam-user-group)

#### Adding individuals to the cluster

This command can be run to add an inidividual user account to the cluster's aws-auth configmap

```bash
eksctl create iamidentitymapping \
    --cluster ${CLUSTER_NAME} \
    --region ${REGION} \
    --arn <AWS ACCOUNT ARN FOR THE USER> \
    --group system:masters \
    --no-duplicate-arns \
    --username <AWS USERNAME FOR THE USER>
```

#### Giving access to an IAM User Group

We create a role developer.assume-access.role and attach two policies to it. The first one is `EKSFullAccess` so that it has access to all the EKS resources. The second one is `developer.assume-eks-access-role.policy` that allows assuming the role.

A detailed guide on defining the roles and policies can be found [here](https://eng.grip.security/enabling-aws-iam-group-access-to-an-eks-cluster-using-rbac).

Once you have followed the above guide to create the roles and attach the specific policies, you can add the role to the cluster's aws-auth config map to let the developers group access the cluster
```bash
eksctl create iamidentitymapping \
    --cluster ${CLUSTER_NAME} \
    --region ${REGION} \
    --arn arn:aws:iam::${ACCOUND_ID}:role/developer.assume-access.role \
    --group system:masters \
```

This needs to be run in order to grant access to the cluster.

One can Connect to the cluster by running just a single command

```bash
aws eks update-kubeconfig --name ${CLUSTER_NAME} --region ${REGION}> --role-arn arn:aws:iam::${ACCOUNT_ID}:role/developer.assume-access.role
```

This commands updates the kubeconfig and adds the context for the cluster and sets the current context to it.
The `--role` argument sets the correct role and policies so that seemless access to the cluster is granted instantly.


### 4. Install the satellite
Please follow the instructions in the [Install on Kubernetes](satellite-kubernetes.md) section to install the Satellite.

Please ensure that you note down the address of the collector.



---
sidebar_position: 4
---

# Satellite on AWS EKS

AWS EKS supports two compute types for its nodes, EC2 and Fargate. Depending on your usecase, you can follow the installation steps given below.
- [Install using EC2](satellite-aws-ecs.mdx)
- [Install using Fargate](satellite-aws-eks-fargate.md)

### Prerequisites
- [eksctl](https://eksctl.io/) version >= `v0.152.0`
- [Helm v3](https://helm.sh/docs/intro/install/) installed and working on your local machine.
- An AWS account with EKS permissions.

## Install in AWS EKS using EC2

### 1. Setup environment variables

```bash
export CLUSTER_NAME='Cluster Name'
export REGION='AWS Region'
export ACCOUNT_ID='AWS Account ID'
```


### 2. Cluster Creation
```bash
read -r -d '' EKS_CLUSTER <<EOF
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: ${CLUSTER_NAME}
  region: ${REGION}

vpc:
  subnets:
    private:
      # MENTION THE SUBNETS YOU WANT TO USE FOR YOUR SATELLITE
      # FOR EXAMPLE:
      # us-west-2a: { id: subnet-0d09e999a579234ea }
      # us-west-2b: { id: subnet-0d09e999a579234eb }

nodeGroups:
  - name: ng-e2e
    instanceType: t2.xlarge
    desiredCapacity: 1
    volumeSize: 40
    privateNetworking: true
EOF

echo "${EKS_CLUSTER}" > eks-cluster.yaml

eksctl create cluster -f ./configuration/eks-cluster.yaml
```


### 3. Connecting to the cluster

AWS EKS grants cluster admin permissions to the account from which the cluster is created. If you don't need access to the cluster for other AWS Users, you can skip this section.

Access to other AWS users in the same account can be granted via 2 ways.
- [Adding individual access to user accounts](#adding-individuals-to-the-cluster)
- [Giving the permissions to a user group](#giving-access-to-an-iam-user-group)

#### Adding individuals to the cluster

This command can be run to add an inidividual user account to the cluster's aws-auth configmap

```bash
eksctl create iamidentitymapping \
    --cluster ${CLUSTER_NAME} \
    --region ${REGION} \
    --arn <AWS ACCOUNT ARN FOR THE USER> \
    --group system:masters \
    --no-duplicate-arns \
    --username <AWS USERNAME FOR THE USER>
```

#### Giving access to an IAM User Group

We create a role developer.assume-access.role and attach two policies to it. The first one is `EKSFullAccess` so that it has access to all the EKS resources. The second one is `developer.assume-eks-access-role.policy` that allows assuming the role.

A detailed guide on defining the roles and policies can be found [here](https://eng.grip.security/enabling-aws-iam-group-access-to-an-eks-cluster-using-rbac).

Once you have followed the above guide to create the roles and attach the specific policies, you can add the role to the cluster's aws-auth config map to let the developers group access the cluster
```bash
eksctl create iamidentitymapping \
    --cluster ${CLUSTER_NAME} \
    --region ${REGION} \
    --arn arn:aws:iam::${ACCOUND_ID}:role/developer.assume-access.role \
    --group system:masters \
```

This needs to be run in order to grant access to the cluster.

One can Connect to the cluster by running just a single command

```bash
aws eks update-kubeconfig --name ${CLUSTER_NAME} --region ${REGION}> --role-arn arn:aws:iam::${ACCOUNT_ID}:role/developer.assume-access.role
```

This commands updates the kubeconfig and adds the context for the cluster and sets the current context to it.
The `--role` argument sets the correct role and policies so that seemless access to the cluster is granted instantly.


### 4. Setting the cluster up

#### Creating an OIDC provider

Run these two commands:
```bash
oidc_id=$(aws eks describe-cluster --name ${CLUSTER_NAME} --region ${REGION} --query "cluster.identity.oidc.issuer" --output text | cut -d '/' -f 5)
```

```bash
aws iam list-open-id-connect-providers | grep $oidc_id | cut -d "/" -f4 | cut -d "\"" -f1
```

If this returns a value, that is the OIDC ID that we need. If the statement returns nothing, run this command:
```bash
eksctl utils associate-iam-oidc-provider --cluster ${CLUSTER_NAME} --region ${REGION} --approve
```

This creates an OIDC Identity Provider.

Next, to create a role in AWS for the EBS CSI Driver add-on ([Amazon Elastic Block Store CSI Driver](https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html) manages persistent volumes in EKS) we need to run these:

```bash
OIDC=$(aws iam list-open-id-connect-providers | grep $oidc_id | cut -d "/" -f4 | cut -d "\"" -f1)

read -r -d '' EBS_DRIVER_POLICY <<EOF
{
"Version": "2012-10-17",
"Statement": [
    {
    "Sid": "",
    "Effect": "Allow",
    "Principal": {
        "Federated": "arn:aws:iam::${ACCOUNT_ID}:oidc-provider/oidc.eks.${REGION}.amazonaws.com/id/${OIDC}"
    },
    "Action": "sts:AssumeRoleWithWebIdentity",
    "Condition": {
        "StringEquals": {
        "oidc.eks.${REGION}.amazonaws.com/id/${OIDC}:aud": "sts.amazonaws.com",
        "oidc.eks.${REGION}.amazonaws.com/id/${OIDC}:sub": "system:serviceaccount:kube-system:ebs-csi-controller-sa"
        }
    }
    }
]
}
EOF
echo "${EBS_DRIVER_POLICY}" > aws-ebs-csi-driver-trust-policy.json

aws iam create-role \
  --role-name AmazonEKS_EBS_CSI_DriverRole \
  --assume-role-policy-document file://aws-ebs-csi-driver-trust-policy.json

aws iam attach-role-policy \
  --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \
  --role-name AmazonEKS_EBS_CSI_DriverRole

eksctl create addon --name aws-ebs-csi-driver --cluster ${CLUSTER_NAME} --region ${REGION} --service-account-role-arn arn:aws:iam::${ACCOUNT_ID}:role/AmazonEKS_EBS_CSI_DriverRole —force
```

### 5. Install the satellite

Please follow the instructions in the [Install on Kubernetes](satellite-kubernetes.md) section to install the Satellite.

Please ensure that you note down the address of the collector.



---
sidebar_position: 1
---


# Satellite on Kubernetes

### Prerequisites
- Kubernetes version >= `v1.18.0`
- [Helm v3](https://helm.sh/docs/intro/install/) installed and working.
- The Kubernetes cluster API endpoint should be reachable from the machine you are running Helm.
- `kubectl` access to the cluster, with `cluster-admin` permissions.
- At least 4 CPUs
- At least 8 GB RAM

### 1. Setup environment variables

```bash
export LEVOAI_AUTH_KEY=<'Authorization Key'>
```

### 2. Install levoai Helm repo
```bash
helm repo add levoai https://charts.levo.ai && helm repo update
```

### 3. Create `levoai` namespace & install Satellite

#### If locating Satellite on the same cluster alongside Sensor
```bash
helm upgrade --install -n levoai --create-namespace \
  --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
  levoai-satellite levoai/levoai-satellite
```

:::info

Depending on the region you are installing in, you may need to set a different Levo base URL for the satellite.

For example, if the satellite will be used with `app.india-1.levo.ai`, the installation command will be:

```bash
helm upgrade --install -n levoai --create-namespace \
  --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
  --set global.levoai_config_override.onprem-api.url="https://api.india-1.levo.ai" \
  levoai-satellite levoai/levoai-satellite
```

:::

#### If locating Satellite on a dedicated cluster
You will need to expose the Satellite via either a `LoadBalancer` or `NodePort`, such that is is reachable by Sensors running in other clusters. Please modify the below command appropriately.

```bash
# Please modify this command template and choose either 'LoadBalancer' or 'NodePort', prior to execution
helm upgrade --install -n levoai --create-namespace \
    --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
    --set levoai-collector.service.type=<LoadBalancer | NodePort> \
    # --set global.levoai_config_override.onprem-api.url="https://api.india-1.levo.ai" \
    levoai-satellite levoai/levoai-satellite
```

### 4. Verify connectivity with Levo.ai

#### a. Check Satellite health

The Satellite is comprised of five sub components 1) levoai-collector, 2) levoai-ion, 3) levoai-rabbitmq, 4)levoai-satellite, and 5) levoai-tagger.

Wait couple of minutes after the install, and check the health of the components by executing the following:

```bash
kubectl -n levoai get pods
```
If the Satellite is healthy, you should see output similar to below.

```bash
NAME                                READY   STATUS    RESTARTS   AGE
levoai-collector-5b54df8dd6-55hq9   1/1     Running   0          5m0s
levoai-ion-669c9c4fbc-vsmmr         1/1     Running   0          5m0s
levoai-rabbitmq-0                   1/1     Running   0          5m0s
levoai-satellite-8688b67c65-xppbn   1/1     Running   0          5m0s
levoai-tagger-7bbf565b47-b572w      1/1     Running   0          5m0s
```


#### b. Check connectivity
Execute the following to check for connectivity health:

```bash
# Please specify the actual pod name for levoai-tagger below
kubectl -n levoai logs <levoai-tagger pod name> | grep "Ready to process; waiting for messages."
```
If connectivity is healthy, you will see output similar to below.

```bash
{"level": "info", "time": "2022-06-07 08:07:22,439", "line": "rabbitmq_client.py:155", "version": "fc628b50354bf94e544eef46751d44945a2c55bc", "module": "/opt/levoai/e7s/src/python/levoai_e7s/satellite/rabbitmq_client.py", "message": "Ready to process; waiting for messages."}
```

**Please contact `support@levo.ai` if you notice health/connectivity related errors.**

### 5. Note down `Host:Port` information

#### If locating Satellite on the same cluster alongside Sensor
The Collector can now be reached by the Sensors running in the same cluster at `levoai-collector.levoai:4317`. Please note this, as it will be required to configure the Sensor.

#### If locating Satellite on a dedicated cluster
Run the below command and note the `external` address/port of the the Collector service. This will be required to configure the Sensor.

```bash
kubectl get service levoai-collector -n levoai
```
Please proceed to [install Traffic Capture Sensors](/install-traffic-capture-sensors).

---------------------------------------------------------

## Satellite Lifecycle Management

### Upgrade Satellite
```bash
# Setup environment variables
export LEVOAI_AUTH_KEY=<'Authorization Key' from the original installation> 

# Update helm repo and upgrade installation
helm repo update

helm upgrade -n levoai \
  --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
  levoai-satellite levoai/levoai-satellite
```


### Uninstall Satellite
```shell
helm uninstall levoai-satellite -n levoai
```

After running the above command, wait until all Satellite pods have been terminated, and then run the following command to delete the rabbitmq PersistentVolumeClaim. Deleting the PVC also deletes the corresponding PersistentVolume.

```shell
kubectl delete pvc data-levoai-rabbitmq-0 -n levoai
```

In case the `kubectl delete pvc` command gets stuck, run the following command before deleting the PVC again:

```shell
kubectl patch pvc data-levoai-rabbitmq-0 -p '{"metadata":{"finalizers":null}}' -n levoai
```

### Change the `Authorization Key` used to communicate with Levo.ai
- Uninstall the Satellite.
- Reinstall the Satellite with the new `Authorization Key`.


### Change the `minimum number of URLs` that the satellite needs to observe to detect an API endpoint.
To detect an API endpoint, Satellite waits for at least '10' URLs to match that endpoint URL pattern.
This number may cause delays in detecting API endpoints when there is not enough load.

If you want to change this number to suit your environment:
- Export an environment variable `LEVOAI_MIN_URLS_PER_PATTERN`, and
- Restart the Satellite with 'min_urls_required_per_pattern' helm config override option

For example, to set this to 3:
```bash
# Setup environment variables
export LEVOAI_AUTH_KEY=<'Authorization Key' from the original installation>
export LEVOAI_MIN_URLS_PER_PATTERN=3

# Update helm repo and upgrade installation
helm repo update

helm upgrade -n levoai \
  --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
  --set global.levoai_config_override.min_urls_required_per_pattern=$LEVOAI_MIN_URLS_PER_PATTERN \
  levoai-satellite levoai/levoai-satellite
```

### List Satellite's pods
```bash
kubectl -n levoai get pods | grep -E '^levoai-collector|^levoai-rabbitmq|^levoai-satellite|^levoai-tagger'
```

### Tail logs of a specific pod
```bash
kubectl -n levoai logs -f <pod name>
```

------------------------------------------------------

### Troubleshooting

### Tagger Errors

The `Tagger` component sends API endpoint metadata information to Levo.ai. API Observability will not function if the Tagger is in an errored state.

Please see sample output below from `kubectl get pods`, that shows the Tagger in an errored state.

```bash                              
NAME                                READY   STATUS    RESTARTS      AGE
levoai-collector-848fb4fff9-gv8g9   1/1     Running   0             64s
levoai-rabbitmq-0                   0/1     Running   0             64s
levoai-satellite-54956ccb89-5s4h2   1/1     Running   0             64s
levoai-tagger-799db4d9cc-89jm8      0/1     Error     1 (14s ago)   64s
```

Below are common error scenarios:

### Authentication Errors
The `Tagger` component authenticates with Levo.ai using the `Authorization Key`. If Tagger is unable to authenticate, it will error out.

Check for authentication errors in the `Tagger` logs:
```bash

kubectl -n levoai logs <levoai-tagger-pod-id> | grep "Exception: Failed to refresh access token"
```

If there are exception messages, you have an incorrect or stale `Authorization Key`. Please contact support@levo.ai for further assistance.

### Connectivity Errors

Check for connectivity errors in the `Tagger` logs:
```bash

kubectl -n levoai logs <levoai-tagger-pod-id> | grep "ConnectionRefusedError: [Errno 111] Connection refused"
```

If there are exception messages, Tagger is unable to connect to dependent services. It generally establishes connection after 3/4 retries. Please contact support@levo.ai for further assistance.

<br></br>



---
sidebar_position: 6
---

# AWS API Gateway

## Logs-based Instrumentation

### Tailing Logs with CloudWatch

You may use CloudWatch Logs to instrument your AWS API Gateway endpoints.

The following script has been provided as an example to help you configure logging for your API Gateway endpoints.

[Levo's Log Parser](/install-log-parsing-sensors) can be configured to parse the logs and send them to Levo.

```bash
#!/usr/bin/env bash

log_group_name=levo/api-gateway-logs

aws logs create-log-group --log-group-name $log_group_name
aws logs put-retention-policy --log-group-name $log_group_name --retention-in-days 7

log_group_arn=$(aws logs describe-log-groups --log-group-name-prefix $log_group_name --query 'logGroups[0].arn' --output text)

aws apigatewayv2 update-stage --api-id 'your-apigateway-api-id' --stage-name '$default' --access-log-settings "DestinationArn=$log_group_arn,"'Format="{\"host\":\"$context.domainName\",\"method\":\"$context.httpMethod\",\"path\":\"$context.path\",\"agent\":\"$context.identity.userAgent\",\"code\":\"$context.status\",\"requestId\":\"$context.requestId\",\"ip\":\"$context.identity.sourceIp\",\"requestTime\":\"$context.requestTime\",\"routeKey\":\"$context.routeKey\",\"protocol\":\"$context.protocol\",\"responseLength\":\"$context.responseLength\"}"'

aws logs tail --follow $log_group_name
```

### Streaming Logs with CloudWatch and Amazon Data Firehose

You may also use Amazon Data Firehose to stream live access logs to Levo's satellite.

1. Configure a CloudWatch log group for APIs in API Gateway (using the above example script)
1. Create a Firehose stream to send incoming events to a publicly accessible satellite endpoint
1. Connect the CloudWatch log group to the Firehose stream

Please contact `support@levo.ai` if you are interested in this setup.

## CloudFront Lambda@Edge Instrumentation

You may configure AWS CloudFront with your API Gateway endpoints as the origin, and use Lambda@Edge functions to intercept and capture traffic.

Please visit the following links for more information

- [Setting up API Gateway with a CloudFront distribution](https://repost.aws/knowledge-center/api-gateway-cloudfront-distribution)
- [Setting up Levo's CloudFront Lambda@Edge Functions](/install-traffic-capture-sensors/aws-cloudfront)


---
sidebar_position: 5
---

# AWS CloudFront

Lambda@Edge functions to ingest traffic from AWS CloudFront distributions.

## Installation

### Pre-requisites
- Install the AWS CLI (version 2) by following the [AWS docs](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).
- You have sufficient permissions on AWS to create and deploy Lambda@Edge functions.
- The Satellite has been successfully set up and is reachable (via HTTPS) from the worker.

### Creating the Lambda Functions using the AWS CLI

- Obtain your organization's ID from https://app.levo.ai/settings/organizations or by
clicking on your profile picture in Levo's dashboard, and navigating to `User Settings -> Organizations`.
- Run the `install.sh` script in the repository.

```shell
git clone https://github.com/levoai/aws-cloudfront-lambda
cd aws-cloudfront-lambda
LEVO_ORG_ID=<value> ./install.sh
```

### Associating the Lambdas with a CloudFront Distribution
1. Go to the [AWS CloudFront Console](https://us-east-1.console.aws.amazon.com/cloudfront/v4/home#/distributions) and select your distribution.
1. Click on the "Behaviors" tab, then click on the "Create Behaviour" button.
1. Configure the behaviour and ensure that the following properties are set:
   - Path pattern: Use `*` to send all JSON payloads to Levo, or use a more specific API pattern
   - Origin and origin groups: The origin for which the traffic should be sent
   - Allowed HTTP methods: GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE
   - Cache policy: Set this to any policy as per your requirements
   - *Function Associations*
      - `Origin request`:
         - Function type: `Lambda@Edge`
         - Function ARN: Paste the "Request Handler ARN" value printed by the `install.sh` script
         - Include body: `Yes`
      - `Origin response`:
         - Function type: `Lambda@Edge`
         - Function ARN: Paste the "Response Handler ARN" value printed by the `install.sh` script
1. Click on the "Create behaviour" button to save the configuration.

That's all!
Within a few minutes, you should start seeing API catalogs in your Levo dashboard.


---
sidebar_position: 5
---

# AWS Traffic Mirroring

### i. Prerequisites
- Satellite has been successfully installed with traffic mirroring listener.
- You have noted down the Satellite's Elastic Network Interface (target ENI) id.
- You have noted down the Source Elastic Network Interface (source ENI) id, usually the Load Balancer ENI.
- The Satellite is reachable from the source where you are mirroring traffic from.

[Setup Levo CLI with AWS credentials](/security-testing/test-laptop)

### ii. Creating mirroring session using Levo CLI

In order to create the traffic mirroring in aws you have to run:

```bash
levo mirror create
```

The CLI will ask for some inputs. First it will ask for the Elastic Network Interface resource id of the source instance from which you want to mirror the traffic.

```bash
? What is the source Network Interface resource id? [your-source-eni-for-traffic-mirroring]
Getting source mirroring details...
```

Then CLI will as for the Elastic Network Interface resource id of the target satellite instance you want to mirror the traffic to.

```bash
? What is the target Network Interface resource id? [eni-for-satellite-running-traffic-listener]
Getting source mirroring details...
Initializing traffic mirroring... creating traffic mirroring filter if necessary.
Looking for an existing traffic mirror target...
Looking for eni-*********** in us-west-2
```

Then it will ask you to name the traffic mirroring session so you can identify it.

```bash
? How do you want to name the mirroring session? [your-mirroring-session-name]
Creating traffic mirroring session...
```

Done. Now traffic should be mirrored from your source network interface into the Levo satellite.

### ii. Listing mirroring session using Levo CLI

```bash
foo@bar:~$ levo mirror list
my-mirroring-session-1
my-mirroring-session-2
my-mirroring-session-3
```

### iii. Delete a mirroring session using Levo CLI

```bash
foo@bar:~$ levo delete my-mirroring-session-1
Sesion successfully deleted!
```

---
sidebar_position: 7
---

# Azure API Management

## Policy-based Instrumentation

### Pre-requisites
- You have sufficient permissions on Azure to configure API Management policies.
- The Satellite has been successfully set up and is reachable (via HTTPS) from the resource group.

### Installation
To instrument your Azure API Management endpoints, the following steps are required:
1. Configuring named values
2. Adding the instrumentation policy

#### Configuring Named Values

Follow the steps in the official Azure docs to [add named values to your API Management instance](https://learn.microsoft.com/en-us/azure/api-management/api-management-howto-properties?tabs=azure-portal#add-a-plain-or-secret-value-to-api-management).

The following named values must be configured:

| Name | Description |
| ---- | ----------- |
| `LevoOrgId` | Your organization's ID. <br/> Obtain your organization's ID from https://app.levo.ai/settings/organizations or by clicking on your profile picture in Levo's dashboard, and navigating to `User Settings -> Organizations`. |
| `LevoTracesEndpoint` | The URL to which traces should be sent, e.g. `https://collector.levo.ai`. |
| `LevoEnv` | The environment in which the apps will show up in Levo's dashboard, e.g. `production` or `staging`. |

#### Adding the Policy

Follow the steps in the official Azure docs to [add a policy to your API Management instance](https://learn.microsoft.com/en-us/azure/api-management/api-management-howto-properties?tabs=azure-portal#add-a-plain-or-secret-value-to-api-management).

Copy the contents of the `policy.xml` file in the [levoai/azure-apim-policy](https://github.com/levoai/azure-apim-policy) repository on GitHub and paste it into the policy editor.

Ensure that the policy is added at the [API Scope](https://learn.microsoft.com/en-us/azure/api-management/set-edit-policies?tabs=editor#api-scope).

## Logs-based Instrumentation

You may also use Azure API Management Logs to instrument your APIs.
Visit the [Log Parser](/install-log-parsing-sensors) page for more details.


---
sidebar_position: 4
---

# Cloudflare Worker

## Prerequisites
- You are using Cloudflare for DNS, and you have [proxying](https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/) enabled.
- You have sufficient permissions on Cloudflare to create workers and configure worker routes for your website.
- The Satellite has been successfully set up and is reachable (via HTTPS) from the worker.

## Deploying the Worker

### Using the CLI

Follow the steps below to deploy the worker to your account.  
You can obtain your organization's ID from https://app.levo.ai/settings/organizations or by
clicking on your profile picture in Levo's dashboard, and navigating to `User Settings -> Organizations`.

```shell
# Clone the worker repository
git clone https://github.com/levoai/cf-worker.git
# cd into the repository
cd cf-worker
# Install all dependencies
yarn
# Authenticate with Cloudflare
npx wrangler login
# Deploy the worker
npx wrangler deploy
# Add your organization ID as a secret
echo <VALUE> | npx wrangler secret put LEVO_ORG_ID
```

That's it! The worker has been added to your Cloudflare account.

:::info
You must also add `LEVO_SATELLITE_URL` as an environment variable for the worker if you are hosting the Satellite yourself.

Check the [repository's README](https://github.com/levoai/cf-worker/blob/main/README.md) for a list of all supported variables.
:::

## Configuring Websites to use the Worker

Follow the instructions in the [Cloudflare Docs](https://developers.cloudflare.com/workers/configuration/routing/routes/#set-up-a-route).

:::caution
When adding a worker route, ensure that the failure mode is set to "Fail open" to allow requests to bypass the worker in case of unexpected errors
or if the [daily request limit](https://developers.cloudflare.com/workers/platform/limits/#daily-request) runs out.
:::

<img
  src={require('../assets/cf-worker-route.png').default}
  alt="Adding a Cloudflare Worker route"
  style={{ display: 'block', margin: 'auto', paddingTop: '24px'}}
/>


---
sidebar_position: 0
---

# Install Traffic Capture Sensors

Depending on your environment, you may choose to install a different Levo sensor to suit your needs.

## eBPF Sensor (Recommended)
You should install the [eBPF sensor](/guides/key-concepts#ebpf-sensor) if:

- You have access to the node / VM / machine where your application workloads are running
- In addition to your publicly exposed services, you want to instrument internal applications which do not have public API endpoints

[**Click here for the installation instructions**](/install-traffic-capture-sensors/ebpf-sensor).

## PCAP Sensor
You should install the pcap sensor if:

- Your application workloads are deployed on a Serverless compute architecture (like AWS Fargate)

[**Click here for the installation instructions**](/install-traffic-capture-sensors/pcap-sensor).

## AWS Traffic Mirroring
Use this if you want to use traffic mirroring to instrument your application workloads.

[**Click here for the installation instructions**](/install-traffic-capture-sensors/aws-traffic-mirroring).

## Cloudflare Worker
You may install Levo's Cloudflare Worker if:

- You are using Cloudflare for DNS, and you have [proxying](https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/) enabled.

[**Click here for the installation instructions**](/install-traffic-capture-sensors/cloudflare-worker).

## AWS CloudFront Lambda@Edge
You may install Levo's CloudFront Lambda@Edge functions if:

- You are using CloudFront as a CDN for your API endpoints.

Note that CloudFront does not provide access to the API endpoint response bodies.

[**Click here for the installation instructions**](/install-traffic-capture-sensors/aws-cloudfront).

## AWS API Gateway

You may instrument your AWS API Gateway endpoints with CloudWatch Logs.

However, CloudWatch only provides endpoints access logs and API endpoint request and response bodies will not be available.

[**Click here for the installation instructions**](/install-traffic-capture-sensors/aws-api-gateway).

## Azure API Management Policy
You should install Levo's Azure API Management policy if:

- Your API endpoints are managed by Azure API Management.

[**Click here for the installation instructions**](/install-traffic-capture-sensors/azure-api-management).

---

## Quickstart

If you want a quick glimpse of Levo's API Observability without a full installation, check out the [Quickstart page](/quickstart).


---
sidebar_position: 3
---

# Sensor on MacOS

This guide provides comprehensive instructions for installing the Levo Satellite, Sensor and Log Parser components together as a single container on a MacOS host.

Follow instructions for your specific platform/method below:
- [Install on Linux host via Docker](#install-via-docker)

<br></br>

-----------------------------------------------------------------------

## Install via Docker

### Prerequisites
- Docker Engine version `18.03.0` and above

### 1. Install Levo-all (Sensor, Satellite and Log Parser)


This section provides information on the
optional environment variables that can be set to customize the properties of the
sensor-satellite configuration.

The Sensor-Satellite setup can be run with the following docker command -

```bash
docker run -e LEVOAI_AUTH_KEY=<your-auth-key> \
  -e LEVOAI_ORG_ID=<your-org-id> \
  --net=host \
  -v ./logs:/mnt/levo/logs
  levoai/levo-all
```

## Required Environment Variables

- **LEVOAI_AUTH_KEY**
    - *Description:* The Satellite CLI authorization key from app.levo.ai
    - *Default:* ""

- **LEVOAI_ORG_ID**
    - *Description:* Organization ID for your specific organization in your app.
    - *Default:* ""

## Optional Environment Variables

The following environment variables can be configured to modify the behavior of the Sensor-Satellite setup:

- **LEVO_FILTER**
    - *Description:* Set a filter for specific data.
    - *Default:* ""

- **LEVO_TRACE_EXPORT_INTERVAL**
    - *Description:* Interval for exporting traces.
    - *Default:* 0.0

- **LEVO_RATE_LIMIT_NUMBER**
    - *Description:* Set the rate limit number.
    - *Default:* 0.0

- **LEVO_HOST_ALLOW_RE**
    - *Description:* Regular expression for allowed hosts.
    - *Default:* ""

- **LEVO_PATH_ALLOW_RE**
    - *Description:* Regular expression for allowed paths.
    - *Default:* ""

- **LEVO_HOST_EXCLUSIONS_RE**
    - *Description:* Regular expression for excluded hosts.
    - *Default:* ""

- **LEVO_PATH_EXCLUSIONS_RE**
    - *Description:* Regular expression for excluded paths.
    - *Default:* ""

- **LEVO_ORG_ID**
    - *Description:* Set the organization ID.
    - *Default:* ""

- **LEVO_APP_ENVIRONMENT**
    - *Description:* Set the application environment.
    - *Default:* "staging"

- **LEVOAI_SATELLITE_PORT**
    - *Description:* Set the port for the LevoAI satellite.
    - *Default:* 9999

- **LEVOAI_MODE**
    - *Description:* Set the mode of the LevoAI system (e.g., "single-node").
    - *Default:* "single-node"

- **LEVOAI_DEBUG_ENABLED**
    - *Description:* Enable or disable debug mode.
    - *Default:* false

- **LEVOAI_DEBUG_PORT**
    - *Description:* Set the port for debugging.
    - *Default:* 12345

- **LEVOAI_DEBUG_SERVER_HOST**
    - *Description:* Set the host for the debug server.
    - *Default:* "host.docker.internal"

- **LEVOAI_LOG_LEVEL**
    - *Description:* Set the log level (e.g., "INFO").
    - *Default:* "INFO"

- **ENABLE_LOG_PARSER**
    - *Description:* Enable or disable the log parser.
    - *Default:* true

- **LEVOAI_BASE_URL**
    - *Description:* Set the base URL for the Levo.ai Platform API.
    - *Default:* "https://api.levo.ai"

- **APP_NAME**
    - *Description:* Set the application name.
    - *Default:* "app-logs-DATE-TIME"

- **ENV_NAME**
    - *Description:* Set the environment name.
    - *Default:* "staging"

### Note

Setting these environment variables is optional and can be set according to your specific requirements
before deploying the Sensor-Satellite setup.


## Log Parser

### List of supported log parsers
- Nginx
- Apache
- Azure API Gateway

### Note
- Make sure logs directories are structured as per the supported log parsers.
- The logs directory should be mounted to the `/mnt/levo/logs` directory in the container.
  - Nginx logs should be mounted to `/mnt/levo/logs/nginx`.
  - Apache logs should be mounted to `/mnt/levo/logs/apache`.
  - Azure API Gateway logs should be mounted to `/mnt/levo/logs/azure`.


---
sidebar_position: 3
---

# API Traffic Capture Filters

The Sensor allows capturing API (HTTP) traffic based on filter (include/exclude) criteria. These filters are specified in a configuration file. Please refer to [Sensor Configuration](sensor-configuration.mdx) for high level structure of the file.

The sensor's fundamental unit at which filtering criteria are applied is a `Linux Process`.

The sensor can filter traffic based on Linux Process names, Linux Process IDs, IP address tuples associated with a Linux Process's TCP/UDP traffic, Kubernetes Pod metadata associated with the Linux Process (when running on Kubernetes), and HTTP URL/header information in traffic being processed by the Linux Process.

Below diagram shows the outcomes and precedence, when the various filtering criteria mentioned above are combined together.

![API Filter Precedence](../../assets/Sensor-API-Traffic-Filters-Precedence.svg)

Below are details on the supported filtering criteria.

- [**Default Excluded Ports**](#default-excluded-ports)
- [**Configure IP Filters**](#configure-ip-filters)
  - [**IP Filter Examples**](#ip-filter-examples)
      - [Exclude All Traffic](#exclude-all-traffic)
      - [Exclude Specific Ports/Port Ranges](#exclude-specific-portsport-ranges)
      - [Include Specific Ports/Port Ranges](#include-specific-portsport-ranges)
      - [Exclude Specific IP Addresses](#exclude-specific-ip-addresses)
      - [Include Specific IP Addresses](#include-specific-ip-addresses)
      - [Exclude IP Subnets](#exclude-ip-subnets)
      - [Include IP Subnets](#include-ip-subnets)
      - [Capture Traffic for Specific Processes](#capture-traffic-for-specific-processes)

- [**Configure Kubernetes Pod Filters**](#configure-kubernetes-pod-filters)
  - [**K8s Pod Filter Examples**](#k8s-pod-filter-examples)
    - [Trace A Single Deployment In A Specific Namespace](#trace-a-single-deployment-in-a-specific-namespace)
    - [Ignore All Traffic Belonging To A Specific Namespace](#ignore-all-traffic-belonging-to-a-specific-namespace)
    - [Trace Multiple Deployments In A Specific Namespace](#trace-multiple-deployments-in-a-specific-namespace)
    - [Trace A Specific Deployment In A Namespace, And Trace All Other Namespaces](#trace-a-specific-deployment-in-a-namespace-and-trace-all-other-namespaces)
    - [Trace All Deployments and Statefulsets From Any Namespace](#trace-all-deployments-and-statefulsets-from-any-namespace)
    - [Ignore Traffic From K8s System Level Services](#ignore-traffic-from-k8s-system-level-services)
    
    
- [**Configure URL Filters**](#configure-url-filters)
  - [**URL Filter Examples**](#url-filter-examples)
    - [Ignore All `.js` API Endpoints](#ignore-all-js-api-endpoints)
    - [Ignore API Base Path `/static/`](#ignore-api-base-path-static)
    - [Ignore API Endpoints With Query Parameter `timeout`](#ignore-api-endpoints-with-query-parameter-timeout)
    - [Only Trace API Endpoints Containing `/users/`](#only-trace-api-endpoints-containing-users)
    - [Only Trace `GET/POST` API Endpoints](#only-trace-getpost-api-endpoints)
    - [Only Trace `payments.com:8888` APIs](#only-trace-paymentscom8888-apis)
    - [Only Trace `payments.com:8888/credit/` APIs Doing `GET`](#only-trace-paymentscom8888credit-apis-doing-get)
    - [Trace APIs on All Subdomains of `api.acme.com`](#trace-apis-on-all-subdomains-of-apiacmecom)

-------------------------------------------------------------

## Default Excluded Ports
The Sensor excludes capturing traffic from the below ports (TCP & UDP) by default.

If your API Traffic (HTTP) uses one of these ports, please see section below on how the port can be included for capture. 

| Standard Protocol | Port  |
| :-                | :-    |
| DNS               | 53    |
| etcd              | 2379-2380 |
| Kafka             | 9092-9093 |
| mongodb           | 27017-27019, 28017   |
| SQL Server        | 135, 4022, 1433-1434  |
| MySQL             | 3306, 33060-33062     |
| Postgress         | 5432-5433 |
| RabbitMQ          | 5671-5672, 15672-15675, 25672, 35672-35682, 61613-61614 |
| Redis             | 6379  |
| ZooKeeper         | 2181, 3888, 3888  |

<br/>

-------------------------------------------------------------

## Configure IP Filters
The below sections describe common filtering scenarios with examples. In all cases the examples show the relevant snippet of the configuration file. Adapt these examples to the [Helm Values config file](../../../static/artifacts/sensor/config-values.yml), if running on Kubernetes.

### IP Filter Examples

#### Exclude All Traffic

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Default policy is to drop all traffic
```

#### Exclude Specific Ports/Port Ranges

##### Exclude Specific Host Ports/Port Ranges
Host Port is the server listening port, where client/peer connections are accepted.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Default policy is to capture all traffic
  entries: # Specific 'entries' can override the default policy
    ### Host Ports ###
    # Host Port is the server listening port, where client connections are accepted
    - policy: drop
      host-ports: 53 # DNS
    - policy: drop
      host-ports: 2379-2380 # etcd
```

##### Exclude Specific Peer Ports/Port Ranges
Peer Port is a client port used in communication with the server listening port.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Default policy is to capture all traffic
  entries: # Specific 'entries' can override the default policy
### Peer Ports ###
    # Peer Port is the client port used in communication with the server listening port
    - policy: drop
      peer-ports: 9000
    - policy: drop
      peer-ports: 25000-29000 
```

#### Include Specific Ports/Port Ranges

##### Include Specific Host Ports/Port Ranges
Host Port is the server listening port, where client/peer connections are accepted.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    ### Host Ports ###
    # Host Port is the server listening port, where client connections are accepted
    - policy: accept
      host-ports: 9000
    - policy: accept
      host-ports: 23000-28000
```

##### Include Specific Peer Ports/Port Ranges
Peer Port is a client port used in communication with the server listening port.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
### Peer Ports ###
    # Peer Port is the client port used in communication with the server listening port
    - policy: accept
      peer-ports: 9000
    - policy: accept
      peer-ports: 25000-29000 
```

#### Exclude Specific IP Addresses

##### Exclude Specific HOST IP Addresses

Host implies the binding IP addresses of the Server servicing the API endpoints.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Accept all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 10.98.76.53 # Drop all traffic to/from 10.98.76.53
      policy: drop
    - host-network: 10.99.76.53 # Drop all traffic to/from 10.99.76.53
      policy: drop
```

##### Exclude Specific Peer IP Addresses

Peer implies the IP addresses of clients connecting to the Server/Host servicing the API endpoints.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Accept all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - peer-network: 10.98.76.53 # Drop all traffic to/from 10.98.76.53
      policy: drop
    - peer-network: 10.99.76.53 # Drop all traffic to/from 10.99.76.53
      policy: drop
```

#### Include Specific IP Addresses

##### Include Specific HOST IP Addresses

Host implies the binding IP addresses of the Server servicing the API endpoints.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 10.98.76.53 # Accept all traffic to/from 10.98.76.53
      policy: accept
    - host-network: 10.99.76.53 # Accept all traffic to/from 10.99.76.53
      policy: accept
```

##### Exclude Specific Peer IP Addresses

Peer implies the IP addresses of clients connecting to the Server/Host servicing the API endpoints.

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - peer-network: 10.98.76.53 # Drop all traffic to/from 10.98.76.53
      policy: accept
    - peer-network: 10.99.76.53 # Drop all traffic to/from 10.99.76.53
      policy: accept
```

#### Exclude IP Subnets
Entire classes of subnets can be excluded using either the CIDR or prefix notations.
The examples below are for `host-network` subnets. The same technique is applicable for `peer-network` subnets.

##### Exclude IP Subnets - CIDR Notation

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Accept all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 1.2.3.4/255.255.255.252 # Drop all from/to this host CIDR block
      policy: drop
```

##### Exclude IP Subnets - Prefix Notation

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Accept all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 1.2.3.4/30 # Drop all from/to this host subnet block
      policy: drop
```

#### Include IP Subnets
Entire classes of subnets can be included using either the CIDR or prefix notations.
The examples below are for `host-network` subnets. The same technique is applicable for `peer-network` subnets.

##### Include IP Subnets - CIDR Notation

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 1.2.3.4/255.255.255.252 # Accept all to/from this host CIDR block
      policy: accept
```

##### Include IP Subnets - Prefix Notation

```yaml
# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: drop # Drop all traffic except ones below
  entries: # Specific 'entries' can override the default policy
    - host-network: 1.2.3.4/30 # Accept all to/from this host subnet block
      policy: accept
```

#### Capture Traffic for Specific Processes
Traffic can be captured ONLY for specific processes, by specifying either their command name or PID.

##### Capture Traffic by Command Name
```yaml
# --------------------------------------------------------------------------------------------
# Process Filters: process command names/IDs to monitor & capture API traffic.
# --------------------------------------------------------------------------------------------
# Uncomment and modify appropriately to limit capture to specific process names or IDs.
# Both monitored-commands and monitored-pids support list of names & IDs respectively.
# NOTE: monitored-commands and monitored-pids settings are mutually exclusive

# Capture traffic from/to nginx & python3
monitored-commands:
  - nginx
  - python3

# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Default policy is to capture all traffic
```

##### Capture Traffic by PID
```yaml
# --------------------------------------------------------------------------------------------
# Process Filters: process command names/IDs to monitor & capture API traffic.
# --------------------------------------------------------------------------------------------
# Uncomment and modify appropriately to limit capture to specific process names or IDs.
# Both monitored-commands and monitored-pids support list of names & IDs respectively.
# NOTE: monitored-commands and monitored-pids settings are mutually exclusive

# Capture traffic from/to PIDs 123 & 45.
monitored-pids:
  - 123
  - 45

# --------------------------------------------------------------------------------------------
# IP Filters: IP/Port/Network address based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
# IP Filters enable granular capture of API traffic based on various criteria.
# Default values ignore traffic from standard ports that normally do not carry HTTP traffic.
# Refer to documentation on how these can be customized to suit your environment.
ip-filter-list:
  default-policy: accept # Default policy is to capture all traffic
```


## Configure Kubernetes Pod Filters
The sensor allows filtering of API traffic based on the Kubernetes Pod's metadata. Examples are including/excluding API traffic from a Pod belonging to specific `namespaces`, `deployments`, `statefulsets`, etc.

### K8s Pod Filter Configuration Section

K8s Pod filters are configured in the `k8s-pod-filter-list` section of the [Helm Values config file](../../../static/artifacts/sensor/config-values.yml) as shown below.

```yaml
sensor:
  config:
  # --------------------------------------------------------------------------------------------
    # Kubernetes Pod Filters: Kubernetes pod properties based granular filtering of API traffic.
    # --------------------------------------------------------------------------------------------
    # Pod Filters enable granular capture of API traffic based on Kubernetes Pod attributes.
    # Rules should ideally be in decreasing order of specificity.
    # The first rule to match a pod's properties will be used.
    # --------------------------------------------------------------------------------------------
    #
    k8s-pod-filter-list:
      default-policy: <trace|ignore>
      rules:
        - policy: <trace|ignore>
          namespace: <name or regex pattern>
          # Optional owner reference of the Pod
          owner-reference:
            kind: <Node|Deployment>
            name: <name or regex pattern>
  # --------------------------------------------------------------------------------------------
```

### K8s Pod Filter Examples
Below are common filtering scenarios with examples. In all cases the examples show the relevant snippet of the configuration file. Adapt these examples to the [Helm Values config file](../../../static/artifacts/sensor/config-values.yml).

#### Trace A Single Deployment In A Specific Namespace

Below example will only trace all API traffic belonging to `entity-service` Deployment in the `levoai` Namespace, and ignore all other API traffic in the K8s cluster.

```yaml
k8s-pod-filter-list:  
  default-policy: ignore
  rules:  
    - policy: trace
      namespace: levoai
      owner-reference:
        kind: Deployment
        name: entity-service

```

#### Ignore All Traffic Belonging To A Specific Namespace

Below example will trace all API traffic in a K8s cluster, except traffic belonging to Pods in the `levoai` namespace.

```yaml
k8s-pod-filter-list:  
  default-policy: trace
  rules:  
    - policy: ignore
      namespace: levoai
```

#### Trace Multiple Deployments In A Specific Namespace

Below example will only trace all API traffic belonging to `entity-service`, and `onboarding-service` Deployments in the `levoai` Namespace, and ignore all other API traffic in the K8s cluster.

```yaml
k8s-pod-filter-list:  
  default-policy: ignore
  rules:  
    - policy: trace
      namespace: levoai
      owner-reference:
        kind: Deployment
        name: (entity|onboarding)-service

```

#### Trace A Specific Deployment In A Namespace, And Trace All Other Namespaces

The below example does the following:
- Traces all API traffic in all namespaces, except traffic within the `crapi` namespace
- Trace traffic belonging to `crapi-identity` Deployment in the `crapi` namespace

```yaml
k8s-pod-filter-list:  
  default-policy: trace  
  rules:  
    - policy: trace  
      namespace: crapi  
      owner-reference:  
        kind: Deployment  
        name: crapi-identity  
    - policy: ignore  
      namespace: crapi
```

#### Trace All Deployments and Statefulsets From Any Namespace

```yaml
k8s-pod-filter-list:  
  default-policy: ignore
  rules:  
    - policy: trace
      owner-reference:
        kind: Deployment
        namespace: .*
    - policy: trace
      owner-reference:
        kind: StatefulSet
        name: .*
```

#### Ignore Traffic From K8s System Level Services

Below example ignores all API traffic from kube, istio and levoai namespaces. It also ignores pods created by the K8s Nodes. All other traffic is traced.

```yaml
k8s-pod-filter-list:  
  default-policy: trace
  rules:  
    - policy: ignore
      namespace: kube-.*
    - policy: ignore
      namespace: istio.*
    - policy: ignore
      namespace: levoai
    - policy: ignore
      namespace: .*
      owner-reference:
        kind: Node
        name: .*
```



## Configure URL Filters
The sensor allows filtering of API traffic based on the *API endpoint Method (operation)*, the *API Host* (Host Header), and the *API endpoint's URI*. The endpoint's URI can be a [(Perl format)](https://perldoc.perl.org/perlre) regex pattern.

Please ensure that any [regex metacharacters](https://perldoc.perl.org/perlre#Metacharacters) present in the URI string expression are properly escaped (for example `?`, etc.). Use an [online regex evaluator](https://regex101.com/) to test your regex pattern if necessary.

### URL Filter Configuration Section

URL filters are configured in the `url-filter` section of the config file as shown below.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  # 'default-url-action' specifies the default behavior which can be overridden by 'rules' below.
  # This is a mandatory attribute that needs to be specified in order to use URL filters.
  default-url-action: <trace|ignore>
  #
  # YAML array of one or more rules. Order of rules matters during evaluation
  rules:
    # 'action' is mandatory. At least one of 'methods', or 'request-uri', or 'host'
    # MUST be specified for each rule entry
    - action: <trace|ignore>
      #
      # YAML array list of one or more (API operations) methods: GET, POST, PUT, PATCH, DELETE
      # Example: [GET], or [GET, POST, PUT, DELETE]
      methods: <[GET, POST, PUT, PATCH, DELETE]>
      #
      # URI of the API endpoint. Can be a (Perl format) regex pattern. Example: /foo/bar, or /bar/*
      request-uri: <URI>
      #
      # Hostname of the API endpoint and optionally the port. Example: levo.ai:8888, or levo.ai
      host: <hostname[:port]>
      #
# --------------------------------------------------------------------------------------------
```

The `default-url-action` specifies the default behavior for filtering APIs, and is a **mandatory** attribute. Either all API endpoints are traced, or all are ignored. This default behavior can be overridden to granularly trace or ignore specific endpoints that match rules specified in the `rules` sub section. 

The `rules` sub section defines the override behavior using a YAML array list. Each entry of the array list is comprised of the following parameters:
- `action`: mandatory parameter that accepts either `trace` or `ignore` as values
- At least one, and optionally all of the below additional parameters:
  - `methods`: YAML array list of one or more (API operations) methods as values: GET, POST, PUT, PATCH, DELETE
  - `request-uri`: URI of the API endpoint as the value. Can be a (Perl format) regex pattern. Example: `/foo/bar`, or `/bar/*`
  - `host`: Hostname of the API endpoint and optionally the port as values. Can be a (Perl format) regex pattern. Example: `levo.ai:8888`, or `levo.ai`, or a regex such as `.*\.levo\.ai` to handle all subdomains of levo.ai

**Rule entries are evaluated in the order in which they were specified**. Further evaluation stops, as soon as a single rule entry matches.


### URL Filter Examples
Below are common filtering scenarios with examples. In all cases the examples show the relevant snippet of the configuration file. Adapt these examples to the [Helm Values config file](../../../static/artifacts/sensor/config-values.yml), if running on Kubernetes.

#### Ignore All `.js` API Endpoints
The below filter will ignore all API endpoints with URIs ending with `.js`.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: trace
  rules:
    - action: ignore
      request-uri: .*\.js # Regex pattern to ignore all API endpoints which end with '.js' 
# --------------------------------------------------------------------------------------------
```

#### Ignore API Base Path `/static/`
The below filter will ignore all API endpoints that have the base path `/static/`.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: trace
  rules:
    - action: ignore
      request-uri: /static/.*
# --------------------------------------------------------------------------------------------
```

#### Ignore API Endpoints With Query Parameter `timeout`
The below filter will ignore all endpoints that have the query parameter `timeout`. For example `/users/list?timeout=60`.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: trace
  rules:
    - action: ignore
      request-uri: .*\?.*timeout=.* # Notice '?' is escaped with '\?'
# --------------------------------------------------------------------------------------------
```

#### Only Trace API Endpoints Containing `/users/`
The below filter will ONLY trace all API endpoints that have `/users/` in the path.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: ignore # Ignore all API endpoints by default
  rules:
    - action: trace
      request-uri: .*/users/.*
# --------------------------------------------------------------------------------------------
```

#### Only Trace `GET/POST` API Endpoints
The below filter will ONLY trace all API endpoints that perform *GET or POST*.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: ignore # Ignore all API endpoints by default
  rules:
    - action: trace
      methods: [GET, POST]
# --------------------------------------------------------------------------------------------
```

#### Only Trace `payments.com:8888` APIs
The below filter will ONLY trace API endpoints belonging to API host *payments.com:8888*.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: ignore # Ignore all API endpoints by default
  rules:
    - action: trace
      host: payments.com:8888
# --------------------------------------------------------------------------------------------
```

#### Only Trace `payments.com:8888/credit/` APIs Doing `GET`
The below filter will ONLY trace API endpoints belonging to API host *payments.com:8888*, having */credit/* as the
base path, and performing `GET`.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: ignore # Ignore all API endpoints by default
  rules:
    - action: trace
      host: payments.com:8888
      methods: [GET]
      request-uri: /credit/.*
# --------------------------------------------------------------------------------------------
```

#### Trace APIs on All Subdomains of `api.acme.com`
The below filter will ONLY trace API endpoints belonging to all subdomains of API host *acme.com*. For example API endpoints belonging to *payments.api.acme.com*, and *orders.api.acme.com*, will be traced, but *catalog.acme.com* will be ignored.

The Host header is expressed as a Perl format regular expression.

```yaml
# --------------------------------------------------------------------------------------------
# URL Filters: API parameter based granular filtering of API traffic.
# --------------------------------------------------------------------------------------------
url-filter:
  default-url-action: ignore # Ignore all API endpoints by default
  rules:
    - action: trace
      host: .*\.api\.acme\.com # '.' has been escaped as we are using a regex
# --------------------------------------------------------------------------------------------
```


# Kubernetes Configuration

### Add Tolerations and Node Selectors

Tolerations and Node Selectors for the Sensor pods may be specified via helm values. For example:

```yaml
sensor:
  tolerations:
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: NoSchedule
    - key: "devops"
      operator: "Equal"
      value: "dedicated"
      effect: "NoSchedule"
  nodeSelector:
    kubernetes.io/hostname: "mavros"
```


---
sidebar_position: 4
---

# Sensor via APT Package

## Install on Debian based Linux via `apt`

### 1. Install `curl` and `gnupg`

```bash
sudo apt install gnupg

sudo apt install curl
```

### 2. Configure Linux host to access `Levo apt repo`

```bash
curl -fsSL https://us-apt.pkg.dev/doc/repo-signing-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/us-apt-repo-signing-key.gpg
```

```bash
echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/us-apt-repo-signing-key.gpg] \
 https://us-apt.pkg.dev/projects/levoai apt-levo main" \
| sudo tee -a /etc/apt/sources.list.d/artifact-registry.list > /dev/null
```

```bash
sudo apt update
```

### 3. Download/install Sensor artifacts

```bash
sudo apt install levo-ebpf-sensor=0.42.1
```

### 4. Start the Sensor
Please take a look at the [Running the Sensor as a Systemd Service](/install-traffic-capture-sensors/ebpf-sensor/sensor-systemd-service) section for further instructions.

------------------------------------------------------------------

## Sensor Lifecycle Management

### Configure Satellite Address (`host:port` information)

The Satellite address is configured in `/etc/levo/sensor/config.yaml`. The default `host:port` for Satellite is `localhost:4317`.

Edit `/etc/levo/sensor/config.yaml`, and set `satellite-url` (under Satellite Settings) to the desired `host:port` value.

```bash
...
# --------------------------------------------------------------------------------------------
# Satellite Settings:
# --------------------------------------------------------------------------------------------
# host:port for the collector service receiving the sensor's API traces.
# mention the scheme http/https if you decide not to use gRPC for sensor satellite communication
satellite-url: <set to desired host:port value>
# --------------------------------------------------------------------------------------------
...
```

### Configure sensor environment
The eBPF sensor environment is configured in `/etc/default/levo-ebpf-sensor`. The default env value is `staging`

Edit `/etc/default/levo-ebpf-sensor`, and set `LEVO_ENV` to the desired env value (eg. `prod`, `qa`)

```bash
# Environment Variables for levo-ebpf-sensor.service
MALLOC_CONF="background_thread:true,narenas:1,tcache:false,dirty_decay_ms:0,muzzy_decay_ms:0,abort_conf:true"
LEVO_ENV="staging"
```

**A Sensor *restart* is required for this to take effect.**


### Start Sensor
```bash
# Note: The default config file is located at: '/etc/levo/sensor/config.yaml'
sudo systemctl start levo-ebpf-sensor
```

### Get Sensor Status
```bash
sudo systemctl status levo-ebpf-sensor
```

### Stop Sensor
```bash
sudo systemctl stop levo-ebpf-sensor
```

### Check Sensor Logs
```bash
journalctl -u levo-ebpf-sensor.service -b -f --since "15min ago"

# If journalctl isn't providing logs, you can alternatively:
sudo cat syslog | grep 'levo-ebpf-sensor'
```

### Show Sensor Config
```bash
cat /etc/levo/sensor/config.yaml
```

### Uninstall Sensor
```bash
sudo apt remove --purge levo-ebpf-sensor
sudo apt clean
```

### Manage Sensor Configuration
Please refer to [Sensor Configuration](/install-traffic-capture-sensors/common-tasks/sensor-configuration.mdx), and [Applying Configuration Changes](/install-traffic-capture-sensors/common-tasks/sensor-configuration.mdx#running-on-linux-host).



---
sidebar_position: 3
---

# Sensor via Docker

## Install on Linux host via Docker

### Prerequisites
- Docker Engine version `18.03.0` and above
- Admin (or `sudo`) privileges on the Docker host

### 1. Install Sensor

> If you are installing the Satellite and Sensor on the ***same*** Linux host, please do ***NOT*** use `localhost` as the satellite-address below. Use `host.docker.internal`, or the Linux host's `IP address` or `domain name` instead. This is required as the Sensor runs inside a Docker container, and `localhost` resolves to the Sensor container's IP address, instead of the Linux host.

```bash
# Replace '<satellite-address>' with the values you noted down from the Satellite install
#
# Specify below the 'Application Name' chosen earlier. Do not quote the 'Application Name'
#
sudo docker run --restart unless-stopped \
  -v /sys/kernel/debug:/sys/kernel/debug -v /proc:/host/proc \
  --add-host host.docker.internal:host-gateway \
  --privileged --detach levoai/ebpf_sensor:0.40.0 \
  --host-proc-path /host/proc/ \
  --satellite-url <satellite-address> \
  --env <'application-environment'> \
  --default-service-name <'Application Name' chosen earlier>
```

#### NOTE:
The default address for the collector in Docker-based Sensor installations is `https://collector.levo.ai`.
This address assumes that Levo is hosting the Satellite for you, and you must also specify an organization ID when starting the sensor (with the `--organization-id` flag).
If you wish, you may also host the Satellite yourself and specify the address of the collector in the self-hosted Satellite to direct the Sensor's traffic to it.

### 2. Verify connectivity with Satellite
Execute the following command to check for connectivity health:

```bash
# Please specify the actual container name for levoai-sensor below
docker logs <levoai-sensor container name> | grep "Initial connection with Collector"
```
If connectivity is healthy, you should see output similar to below.

```bash
2022/06/13 21:15:40 729071	INFO [ebpf_sensor.cpp->main:120]	Initial connection with Collector was successful.
```

Please proceed to the next step, if there are no errors.

<br></br>
--------------------------------------------------------------

## Sensor Lifecycle Management

### Uninstall Sensor
```bash
# Get the container id of the Sensor
docker ps | grep "levoai/ebpf_sensor"

# Remove the Sensor
docker rm -f <container id from docker ps step above>
```

### Get Sensor Logs
```bash
# Get the container id of the Sensor
docker ps | grep "levoai/ebpf_sensor"

sudo docker logs <container id from docker ps step above>
```

### Upgrade Sensor
- Uninstall Sensor
- Pull new Sensor image
```bash
docker pull levoai/ebpf_sensor:latest
```
- Reinstall Sensor

### Manage Sensor Configuration
Please refer to [Sensor Configuration](/install-traffic-capture-sensors/common-tasks/sensor-configuration.mdx), and [Applying Configuration Changes](/install-traffic-capture-sensors/common-tasks/sensor-configuration.mdx#running-via-docker).



---
sidebar_position: 1
---

# Sensor on Kubernetes

## Install on Kubernetes

### Prerequisites
- Kubernetes version >= v1.18.0
- [Helm v3](https://helm.sh/docs/intro/install/) installed and working.
- The Kubernetes cluster API endpoint should be reachable from the machine you are running Helm.
- `kubectl` access to the cluster, with `cluster-admin` permissions.

### 1. Install levoai Helm repo
```bash
helm repo add levoai https://charts.levo.ai && helm repo update
```

### 2. Create `levoai` namespace & install Sensor
```bash
# Replace 'hostname|IP' & 'port' with the values you noted down from the Satellite install
# If Sensor is installed on same cluster as Satellite, use 'levoai-haproxy'
# If they are installed on different clusters, the haproxy service should be exposed so that it is
# reachable by the sensor. Use the exposed address as the value for satellite-url.
# Specify below the 'Application Name' chosen earlier and Organization ID (copy from levo platform).
#
helm upgrade levoai-sensor levoai/levoai-ebpf-sensor \
  --install \
  --namespace levoai \
  --create-namespace \
  --set sensor.config.default-service-name=<'Application Name' chosen earlier> \
  --set sensor.config.satellite-url=<hostname|IP:port> \
  --set sensor.config.organization-id=<your-org-id> \
  --set sensor.levoEnv=<'Application environment'>
```


### 3. Verify connectivity with Satellite

#### i. Check Sensor health

Check the health of the Sensor by executing the following:

```bash
kubectl -n levoai get pods | grep levoai-sensor
```                              
If the Sensor is healthy, you should see output similar to below.

```bash
levoai-sensor-747fb4aaa9-gv8g9   1/1     Running   0             1m8s
```

#### ii. Check connectivity

Execute the following command to check for connectivity health:

```bash
# Please specify the actual pod name for levoai-sensor below
kubectl -n levoai logs <levoai-sensor pod name> | grep "Initial connection with Collector"
```
If connectivity is healthy, you should see output similar to below.

```
2022/06/13 21:15:40 729071	INFO [ebpf_sensor.cpp->main:120]	Initial connection with Collector was successful.
```

**Please contact `support@levo.ai` if you notice health/connectivity related errors.**

#### NOTE:
The default address for the satellite url in helm installations is `levoai-haproxy`.
This address assumes that the Satellite is installed in the same cluster (and namespace) as the Sensor.
If they are installed on different clusters, the haproxy service should be exposed so that it is
reachable by the sensor. Use the exposed address as the value for satellite-url.
If you wish to, you may also request Levo to host the Satellite for you. In this case, you will need to set the
`satellite-url` to `https://collector.levo.ai` and specify an organization ID (`organization-id`) via helm values.

```shell
helm upgrade --set sensor.levoEnv=<your-application-environment> --set sensor.config.satellite-url=https://collector.levo.ai --set sensor.config.organization-id=<your-org-id> levoai-sensor levoai/levoai-ebpf-sensor -n levoai
```

Please proceed to the next step, if there are no errors.

<br></br>


---
sidebar_position: 6
---

# Sensor as a Systemd Service

## Running the Sensor as a Systemd Service {#running-sensor-systemd}

### 1. Configure Satellite Address
The Satellite (collector) address is configured in `/etc/levo/sensor/config.yaml`.

#### NOTE:
The default address for the collector in Systemd installations is `https://collector.levo.ai`.
This address assumes that Levo is hosting the Satellite for you, and you must also specify an organization ID (`organization-id`) via the config file.
If you wish, you may also host the Satellite yourself and specify the address of the collector in the self-hosted Satellite to direct the Sensor's traffic to it.


Edit `/etc/levo/sensor/config.yaml`, and set `satellite-url` (under Satellite Settings) to the address noted from the Satellite install.

```yaml
...
# --------------------------------------------------------------------------------------------
# Satellite Settings:
# --------------------------------------------------------------------------------------------

# Levo Organization ID. This must be specified when the collector is hosted by Levo.
# organization-id: ""

# host:port for the collector service receiving the Sensor's API traces.
satellite-url: <Use the default (https://collector.levo.ai) or set to a custom address>
...
```
**Note**: If you change the Satellite address later, you have to restart the Sensor, since it's not a hot property.

### 2. Configure Application Name
The `Application Name` is configured in `/etc/levo/sensor/config.yaml`.

Edit `/etc/levo/sensor/config.yaml`, and set `default-service-name` to the `Application Name` chosen earlier.

```yaml
# --------------------------------------------------------------------------------------------
# Default Application Name:
#
# Auto discovered API endpoints and their OpenAPI specifications are show in the API Catalog
# grouped under this application name. The application name helps segregate and group API
# endpoints from different environments.
# --------------------------------------------------------------------------------------------
#
default-service-name: <'Application Name' chosen earlier>
# --------------------------------------------------------------------------------------------
```

### Configure sensor environment
The eBPF sensor environment is configured in `/etc/default/levo-ebpf-sensor`. The default env value is `staging`

Edit `/etc/default/levo-ebpf-sensor`, and set `LEVO_ENV` to the desired env value (eg. `prod`, `qa`)

```bash
# Environment Variables for levo-ebpf-sensor.service
MALLOC_CONF="background_thread:true,narenas:1,tcache:false,dirty_decay_ms:0,muzzy_decay_ms:0,abort_conf:true"
LEVO_ENV="staging"
```

**Note**: If you change the `Application Name` later, you have to restart the Sensor, since it's not a hot property.


### 3. Start the Sensor
```bash
sudo systemctl start levo-ebpf-sensor
```

### 4. Verify connectivity with Satellite
```bash
sudo journalctl -u levo-ebpf-sensor.service -b -f

# If 'journalctl' isn't tailing logs, use syslog:
sudo cat /var/log/syslog | grep 'levo-ebpf-sensor'
```

#### Connection Success
If connectivity is healthy, you should see output similar to below.

```bash
2022/06/13 21:15:40 729071	INFO [ebpf_sensor.cpp->main:120]	Initial connection with Collector was successful.
```

#### Connection Failures
If the Sensor is unable to connect with the Satellite, you will notice log entries similar to the one below. Please contact `support@levo.ai` for assistance.

```
Initial connection with Collector failed. However, the sensor will keep attempting to send future traces.

[OTLP TRACE GRPC Exporter] Export() failed: failed to connect to all addresses
```

Please proceed to the next step, if there are no errors.


### 5. Sensor's resource limits
By default, sensor is restricted to use up to 50% of CPU and 2GB memory.

If you ever need to change these limits, you need to modify `CPUQuota` and `MemoryMax` in the below systemd config file under `[Service]` section:

#### 1. Open the config file `/usr/lib/systemd/system/levo-ebpf-sensor.service` and modify `CPUQuota` and `MemoryMax`

```
sudo vi /usr/lib/systemd/system/levo-ebpf-sensor.service
```
For example,

If you want to limit sensor's CPU usage to 0.75 of a core, then set `CPUQuota=75%`. You can set `CPUQuota=200%` to go upto two full cores of CPU.

If you want to limit sensor's memory usage to 1GB, then set `MemoryMax=1G`

#### 2. Reload the config

```
systemctl daemon-reload
```

#### 3. Restart the sensor

```
sudo systemctl restart levo-ebpf-sensor
```


---
sidebar_position: 5
---

# Sensor via YUM Package

## Install on RPM based Linux Distributions via `yum` {#sensor-yum-install}

### 1. Configure the package manager

Configure `yum` to access Levo's RPM packages using the following command:

```shell
sudo tee -a /etc/yum.repos.d/levo.repo << EOF
[levo]
name=Levo.ai
baseurl=https://us-yum.pkg.dev/projects/levoai/yum-levo
enabled=1
repo_gpgcheck=0
gpgcheck=0
EOF
```

### 2. Install the eBPF Sensor

Install the eBPF Sensor from Levo's RPM repository.

1. Update the list of available packages:
  ```shell
  sudo yum makecache
  ```

1. Install the package in your repository.
  ```shell
  sudo yum install levo-ebpf-sensor-0.42.1
  ```

Enter `y` when prompted.

### 3. Start the Sensor
Please take a look at the [Running the Sensor as a Systemd Service](/install-traffic-capture-sensors/ebpf-sensor/sensor-systemd-service) section for further instructions.




# Install PCAP Sensor

## Prerequisites
- Refer [pcap-filter-guide](https://www.tcpdump.org/manpages/pcap-filter.7.html) to apply filters.

> **_NOTE:_**  You need to have the satellite installed to configure the sensor to point to it. If you haven't done it already, head over to [Install Satellite ](/install-satellite)
Make sure the satellite is able to listen on port `9999`
Edit Inbound Rules to accept port `9999` in case the satellite is running on an AWS instance.

## Follow instructions for your platform

 - [Install on Fargate](/install-traffic-capture-sensors/pcap-sensor/sensor-fargate)
 - [Install via Docker](/install-traffic-capture-sensors/pcap-sensor/sensor-docker)
 - [Install on Kuberenetes](/install-traffic-capture-sensors/pcap-sensor/sensor-kubernetes)





---
sidebar_position: 1
---

# Sensor via Docker

## Install via Docker

### Prerequisites
-   Docker Engine version  `18.03.0`  and above
-   Admin (or  `sudo`) privileges on the Docker host

```bash
sudo docker run --net=host --rm -it levoai/pcap-sensor:0.1.1 \
./bin/init apidump \
--satellite-url "your satellite url (http(s)://hostname|IP:port)" \
--levo-env "your application environment (staging, production etc.)" \
--levoai-org-id "your levo org id"
```
Specify additional flags in the command
```bash
--trace-export-interval	"trace export interval in seconds (default 10)"
--rate-limit "number of traces per minute"
--filter "pcap filter string, eg. port 8080 and (not port 8081)"
--host-allow "host allow regex"
--path-allow "path allow regex"
--host-exclusions "host exclude regex"
--path-exclusions "path exclude regex"
```



---
sidebar_position: 3
---

# Sensor on Fargate

## Prerequisites
- AWS profile access key and secret access key saved at path  ~/.aws/credentials file
- The profile should have all the required permissions as listed [here](#aws-permissions)

## Install Sensor on Fargate

The pcap Sensor can be installed as a sidecar on an existing AWS task by adding to its task definition via the AWS Console.

The steps to add the sensor to your task are as follows

- Go to Task Definitions
- Select the required task definition
- Click on `Create revision with JSON`
- Add the given JSON object under ContainerDefinitions
- Replace the values for satellite-url, levo-env and levoai-org-id in entrypoint.
- Replace the values for Environment and LogConfiguration as per your requirement.
- Set the cpu limit as number of CPU Units (*Note: 1 core = 1024 CPU Units*)
- Set the memory limit in `Mib` (*Note: memory should not exceed the Task memory limit*)

```json
{
    "name": "levo-pcap-sensor",
    "image": "levoai/pcap-sensor:0.1.1",
    "cpu": 512,
    "memory": 512,
    "portMappings": [],
    "essential": false,
    "entryPoint": [
        "./bin/init",
        "apidump",
        "--satellite-url",
        "< INSERT SATELLITE URL (http(s)://hostname|IP:port) >",
        "--levo-env",
        "<INSERT APPLICATION ENVIRONMENT (staging, production etc.)>",
        "--levoai-org-id",
        "< INSERT LEVO ORG ID >",
        "--rate-limit",
        "<INSERT NUMBER OF TRACES PER MINUTE>"
    ],
    "environment": [
        {
            "name": "LEVO_AWS_REGION",
            "value": "< INSERT AWS REGION (us-west-2) >"
        }
    ],
    "mountPoints": [],
    "volumesFrom": [],
    "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
            "awslogs-group": "< INSERT LOGS IDENTIFIER (/ecs/your-application-pcap) >",
            "awslogs-create-group": "true",
            "awslogs-region": "< INSERT AWS REGION (us-west-2) >",
            "awslogs-stream-prefix": "ecs-pcap"
        }
    }
}
```

Specify additional flags in the entrypoint
```bash
--trace-export-interval     # default 10s
--rate-limit                # number of traces per minute
--filter                    # eg. port 8080 and (not port 8081)
--host-allow                # regex for allowed hosts
--path-allow                # regex for allowed paths
--host-exclusions           # regex for excluded hosts
--path-exclusions           # regex for excluded paths
```

<a id="aws-permissions"></a>

### AWS Permissions needed

Add the **AmazonECS_FullAccess** policy to get access to all the necessary permissions.

| Action                      | Resource                                               | Purpose                                                                                      |
|-----------------------------|--------------------------------------------------------|----------------------------------------------------------------------------------------------|
| ec2:DescribeRegions         | *                                                      | Find the list of AWS regions you have enabled. (If not present, defaults to a precompiled list.) |
| ecs:ListClusters            | *                                                      | Find the available ECS clusters.                                                             |
| ecs:DescribeClusters        | , or restricted to account like `arn:aws:ecs:::cluster/*` | Look up the names of the available ECS clusters.                                              |
| ecs:ListTaskDefinitionFamilies | *                                                  | Find the available task definitions.                                                         |
| ecs:DescribeTaskDefinition  | *                                                      | Read the existing task definition in order to copy it.                                        |
| ecs:RegisterTaskDefinition  | *                                                      | Write a new version of the task definition.                                                  |
| ecs:ListServices            | *                                                      | Find the available services.                                                                 |
| ecs:DescribeServices        | *, or restricted to your account, or restricted to the cluster you selected | Identify which services are using the task definition you selected.                 |
| ecs:UpdateService           | *, or restricted to your account, or restricted to the cluster you selected | Update and restart the service using the new task definition.                             |
| ecs:TagResource             | *, or restricted to your account, or restricted to the cluster you selected | Mark the service as having been updated by Levoai.



---
sidebar_position: 2
---

# Sensor on Kubernetes

## Install on Kubernetes as daemonset

### Prerequisites
-   Kubernetes version >= v1.18.0
-   [Helm v3](https://helm.sh/docs/intro/install/)  installed and working.
-   The Kubernetes cluster API endpoint should be reachable from the machine you are running Helm.
-   `kubectl`  access to the cluster, with  `cluster-admin`  permissions.

### 1. Install levoai helm repo
```
helm repo add levoai https://charts.levo.ai && helm repo update
```

### 2. Create levoai namespace and install pcap-sensor

```bash
# Replace 'hostname|IP' & 'port' with the values you noted down from the Satellite install
# If Sensor is installed on same cluster as Satellite, use 'http://levoai-satellite:9999'
# Specify below the 'Application Name' chosen earlier.
#
helm upgrade levoai-pcap-sensor levoai/levoai-pcap-sensor \
  --install \
  --namespace levoai \
  --create-namespace \
  --set sensor.config.levoaiOrgId="your Levo Org ID" \
  --set sensor.config.satelliteUrl="http(s)://hostname|IP:port"
  --set sensor.confg.levoEnv="your application environment (staging, production etc.)"
```

Set additional configs
```bash
sensor.config.traceExportInterval="trace export interval in seconds (default 10)"
sensor.config.rateLimit="rate limit number in traces/min (default 1000)"
sensor.config.fitler="pcap filter string, eg. port 8080 and (not port 8081)"
sensor.config.hostAllow="host allow regex"
sensor.config.pathAllow="path allow regex"
sensor.config.hostExclusions="host exclusion regex"
sensor.config.pathExclusions="path exclusion regex"
```



---
sidebar_position: 6
---

# Common Tasks
- [Generating CLI Authorization Keys](#generating-cli-authorization-keys)
- [Accessing Organization IDs](#accessing-organization-ids)

-----------------------------------
## Generating CLI Authorization Keys
The Levo CLI is packaged within CI/CD plugins that are embedded in quality gates, that run security/resilience tests. 

The CLI uses an authorization key to access Levo.ai. Follow instructions below to generate a key.

- [Login](https://app.levo.ai/login) to Levo.ai
- Click on your user profile
- Click on `User Settings`
- Click on `Keys` on the left navigation panel
- Click on `Get CLI Authorization Key`
- Now copy & save your authorization key, to be used in the CI/CD plugin of your choice

-----------------------------------
## Accessing Organization IDs
Levo allows signed-in users to belong to more than one *organization*. Each organization has a unique ID. Below are instructions on fetching the ID for a specific organization.

![Fetch ORG ID](../assets/levo-org-id.png)

- [Login](https://app.levo.ai/login) to Levo.ai
- Click on your user profile
- Click on `User Settings`
- Click on `Organizations` on the left navigation panel
- Now copy & save the ID for the Organization of your preference
- This ID will be used within 3rd party integrations like CI/CD plugins, etc.

---
sidebar_position: 1
keywords: [CI/CD Integrations, API Integrations, Continuous Security Testing]
---

# Integrations

Levo allows you to embed API security/resilience testing into development workflows by integrating with with your preferred third-party development tools.

Below are details on various supported integrations.

- [JIRA](/integrations/jira)
- [Splunk](/integrations/splunk)
- [Slack](/integrations/slack)
- [Okta](/integrations/okta)
- [Webhooks](/integrations/webhooks)


---
sidebar_position: 1
---

# Jira

## Atlassian JIRA Integration

This integration allows JIRA tickets to be created/viewed directly from Test Run failures reported by Levo. Below are links to common tasks.

- [Add JIRA Integration](#add-jira-integration)
- [Creating JIRA Tickets From Vulnerability Page](#creating-jira-tickets-from-vulnerability-page)
- [Assign / Unassign JIRA Tickets From Vulnerability Page](#assign--unassign-jira-tickets-from-vulnerability-page)

### Add JIRA Integration

1. Prerequisites
    - Ensure you have a JIRA account, and note down the URL for the JIRA service.
    - Create an API integration token in your Atlassian account as shown below.
      ![](../assets/Integrations/JIRA/Atlassian-Account-API-Tokens.png)
      ![](../assets/Integrations/JIRA/Atlassian-Create-API-Token-1.png)
      ![](../assets/Integrations/JIRA/Atlassian-Create-API-Token-2.png)
    - Copy the API Token
      ![](../assets/Integrations/JIRA/Atlassian-Create-API-Token-3.png)
    - Identify the JIRA `Project` that will be the recipient  for the tickets created from Levo, and note down the project's `Key` name.
      ![](../assets/Integrations/JIRA/JIRA-Project-Name-Key.png)

2. Enable JIRA Integration
    - In the Levo SaaS console, navigate to the Integrations screen as shown below and click on `Jira` tile.
      ![](../assets/Integrations/Integrations-Screen.png)
    - Configure the JIRA integration following the steps below. Specify the `Project Key` rather than the `Project Name` in the screens below.
      ![](../assets/Integrations/JIRA/JIRA-integration-Add.png)
    - Save the settings to enable the integration
      ![](../assets/Integrations/JIRA/JIRA-Integrations-Enabled.png)

   Congratulations! You have successfully enabled the JIRA integration. Below are steps to a) create JIRA tickets from failed test runs, and b) view linked JIRA tickets from failed test cases.


### Creating JIRA Tickets From Vulnerability Page
Follow the below steps to create a JIRA ticket for a specific Vulnerability reported from a Test Run.

- Navigate to the Vulnerabilities page.
  ![](../assets/Integrations/JIRA/JIRA-Integration-Vulnerabilities-Page.png)
- Navigate to the specific Vulnerability, and click on the `Create Ticket` icon.
  ![](../assets/Integrations/JIRA/JIRA-Integration-Create-JIRA-Ticket-1.png)
- Complete the dialog appropriately to create a JIRA ticket
  ![](../assets/Integrations/JIRA/JIRA-Integration-Create-JIRA-Ticket-2.png)
- Optionally verify if the ticket was successfully created in JIRA. Clik on `Jira Ticket` link to open the ticket in a new browser tab.
  ![](../assets/Integrations/JIRA/JIRA-Integration-Created-JIRA-Ticket.png)

### Assign / Unassign JIRA Tickets From Vulnerability Page
Vulnerabilities that are linked with a JIRA ticket, will have a User Icon as shown below. Clicking on the icon will open the dialog, select user to assign/unassign user to a ticket.

![](../assets/Integrations/JIRA/JIRA-Integration-Assign-JIRA-Ticket.png)



---
sidebar_position: 4
---

# Okta

## Configure Okta Integration using SAML

Follow these steps to configure the Okta Integration for your Levo organization. This will allow you to use Okta to login to the platform.

1. Navigate to Levo console IAM settings section and click on "Configure Okta" button.
2. Copy **ACS Url** and **Entity ID** to be used during the Okta app creation.
![](../assets/Integrations/Okta/levo-okta-config-acs-entity.png)
3. Navigate to the application creation screen in your Okta admin console.
4. Add the Descope app from the Okta Integration Marketplace.
5. When you first add the integration, set the name as **Levo** and click Done:
![](../assets/Integrations/Okta/add-descope-app.png)
6. Under Sign On > Advanced Sign-on Settings use the values we got in step 2:
![](../assets/Integrations/Okta/acs-url-and-entity-id.png)
7. Once you've added the app, expand the attributes field in the SAML section and add the following mapping:
![](../assets/Integrations/Okta/levo-okta-attribute-mapping.png)
8. Under Assignments in the same section, add the relevant User and Group assignments to your new application.
9. Go to Sign on methods > SAML 2.0 > Metadata details, to locate and copy your Okta Metadata URL.
10. And as a last step in the Okta app creation edit the logo of the application and replace it with the [Levo logo](../assets/Integrations/Okta/levo-logo.png) so you can identify it in your Okta dashboard.
11. Go back to Levo console and fill in the details to connect your Okta app.
    - **Connection Name**: AN identifier for the connection.
    - **Domain**: Email domain of your organization users.
    - **Okta Metadata Url**: The Metadata URL you copied from Okta.


After that, you should be able to use this custom app to login to Levo using Okta.

---
sidebar_position: 3
---

# Slack

### Add Slack Integration

1. Prerequisites
    - Sign in to your Slack and navigate to the channel where you want to receive notifications.
    - Click on the channel name, then select "Integrations" > "Add an app".
    - Search for "Incoming WebHooks" and install it.
    - Select the channel for posting messages and click "Add Incoming WebHooks integration".
    - Copy the Webhook URL provided.

2. Enable Slack Integration
    - In the Levo SaaS console, navigate to the Integrations screen as shown below and click on `Slack` tile.
      ![](../assets/Integrations/Integrations-Screen.png)
    - Configure the Slack integration following the steps below.
      - Select the event types for Changelog Notifications and Vulnerability Notifications that you wish to receive.
        - Changelog Event Types: `New Application`, `New Endpoint`, `New Sensitive Type`.
        - Vulnerability Notification Types: `Vulnerability Created`, `Vulnerability Reopened`, `Vulnerability Closed`.
      - Paste the Webhook URL copied from Slack.
          ![](../assets/Integrations/Slack/Slack-Integration-Add.png)
    - After configuring your preferences, save to activate the Slack integration.
      ![](../assets/Integrations/Slack/Slack-Integrations-Enabled.png)



---
sidebar_position: 2
---

# Splunk

### Add Splunk Integration

1. Prerequisites
    - Sign in to your Splunk where you like to receive notifications.
    - Copy the `Webhook URL` and `HEC Token`.

2. Enable Splunk Integration
    - In the Levo SaaS console, navigate to the Integrations screen as shown below and click on `Splunk` tile.
      ![](../assets/Integrations/Integrations-Screen.png)
    - Configure the Splunk integration following the steps below.
        - Select the event types for Changelog Notifications and Vulnerability Notifications that you wish to receive.
            - Changelog Event Types: `New Application`, `New Endpoint`, `New Sensitive Type`.
            - Vulnerability Notification Types: `Vulnerability Created`, `Vulnerability Reopened`, `Vulnerability Closed`.
        - Paste the Webhook URL and HEC Token copied from Splunk.
          ![](../assets/Integrations/Splunk/Splunk-Integration-Add.png)
    - After configuring your preferences, save to activate the Splunk integration.
      ![](../assets/Integrations/Splunk/Splunk-Integrations-Enabled.png)



---
sidebar_position: 5
---

# Custom Webhooks

### Add Custom Webhook Integration

1. Prerequisites
    - Make sure you have the necessary webhook related information where you like to receive notifications.
    - Copy the `Webhook URL` and `API Key`.

2. Enable Splunk Integration
    - In the Levo SaaS console, navigate to the Integrations screen as shown below and click on `Webhooks` tile.
      ![](../assets/Integrations/Integrations-Screen.png)
    - Configure the Webhooks integration following the steps below.
        - Select the event types for Changelog Notifications and Vulnerability Notifications that you wish to receive.
            - Changelog Event Types: `New Application`, `New Endpoint`, `New Sensitive Type`.
            - Vulnerability Notification Types: `Vulnerability Created`, `Vulnerability Reopened`, `Vulnerability Closed`.
        - Paste the Webhook URL and API Key copied earlier.
          ![](../assets/Integrations/Webhooks/Webhooks-Integration-Add.png)
    - After configuring your preferences, save to activate the Webhook integration.
      ![](../assets/Integrations/Webhooks/Webhooks-Integrations-Enabled.png)


---
sidebar_position: 5
keywords: [API Security, ZAP, OWASP, Linux, macOS, Windows, API Observability]
---

# Quickstart with Burp

The Levo.ai add-on for Burp Plugin allows building OpenAPI specs with the traffic sent or proxied via Burp Suite.

You can install the Levo.ai Burp Integration Plugin from the BApp Store: https://portswigger.net/bappstore/e1772ac14930453b98d5bff8c4f8b0cd.

1. Set Levo satellite's URL

   ![image](https://github.com/levoai/docs/assets/105229925/fe8c1967-e655-4a8e-a278-755bebe6bf28)

2. Set org id
   
   ![image](https://github.com/levoai/docs/assets/105229925/4bf66e25-20dd-4daa-b8aa-83394cd9c73b)
   
   You can copy Organization Id from "User Settings" page from Levo Dashboard top right section.

3. Enable sending traffic to Levo

   ![image](https://github.com/levoai/docs/assets/105229925/b5f60459-3d1c-4c48-af2c-c94b1390823c)




---
sidebar_position: 3
keywords: [API Security, ZAP, OWASP, Linux, macOS, Windows, API Observability, Kubernetes]
---

# Quickstart on Kubernetes

This quickstart guide will help you install the LevoAI eBPF Sensor on a Kubernetes cluster.

### Prerequisites
- Kubernetes version >= `v1.18.0`
- [Helm v3](https://helm.sh/docs/intro/install/) installed and working.
- The Kubernetes cluster API endpoint should be reachable from the machine you are running Helm.
- `kubectl` access to the cluster, with `cluster-admin` permissions.
- At least 4 CPUs
- At least 8 GB RAM

## Copy `Authorization Key` from Levo.ai

The Satellite uses an authorization key to access Levo.ai.

- [Login](https://app.levo.ai/login) to Levo.ai.
- Click on your user profile.
- Click on `User Settings`
- Click on `Keys` on the left navigation panel
- Click on `Get Satellite Authorization Key`

Copy your authorization key. This key is required in subsequent steps below.

### Add Helm Charts Repository

```bash
helm repo add levoai https://charts.levo.ai && helm repo update
```

### Add LevoAI Auth Key

```bash
export LEVOAI_AUTH_KEY=<'Authorization Key' copied earlier>
```

### Install Satellite

```bash
helm upgrade --install -n levoai --create-namespace \
  --set global.levoai_config_override.onprem-api.refresh-token=$LEVOAI_AUTH_KEY \
  levoai-satellite levoai/levoai-satellite 
```

### Check satellite connectivity
Execute the following to check for connectivity health:

```bash
# Please specify the actual pod name for levoai-tagger below
kubectl -n levoai logs <levoai-tagger pod name> | grep "Ready to process; waiting for messages."
```
If connectivity is healthy, you will see output similar to below.

```bash
{"level": "info", "time": "2022-06-07 08:07:22,439", "line": "rabbitmq_client.py:155", "version": "fc628b50354bf94e544eef46751d44945a2c55bc", "module": "/opt/levoai/e7s/src/python/levoai_e7s/satellite/rabbitmq_client.py", "message": "Ready to process; waiting for messages."}
```

### Install eBPF Sensor

```bash
# Replace 'hostname|IP' & 'port' with the values you noted down from the Satellite install
# If Sensor is installed on same cluster as Satellite, use 'levoai-collector.levoai:4317'
# Specify below the 'Application Name' chosen earlier.
#
helm upgrade levoai-sensor levoai/levoai-ebpf-sensor \
  --install \
  --namespace levoai \
  --create-namespace \
  --set sensor.config.default-service-name=<'Application Name' chosen earlier> \
  --set sensor.config.satellite-url=<hostname|IP:port>
  --set sensor.config.env=<'Application environment'>
```

### Check sensor health

```bash
# Please specify the actual pod name for levoai-sensor below
kubectl -n levoai logs <levoai-sensor pod name> | grep "Initial connection with Collector"
```
If connectivity is healthy, you should see output similar to below.

```
2022/06/13 21:15:40 729071	INFO [ebpf_sensor.cpp->main:120]	Initial connection with Collector was successful.
```

**Please contact `support@levo.ai` if you notice health/connectivity related errors.**


---
sidebar_position: 2
keywords: [API Security, ZAP, OWASP, Linux, macOS, Windows, API Observability]
---

# Quickstart on Mac / Laptop

### Prerequisites
- Docker Engine version `18.03.0` and above

### Copy `Authorization Key` from Levo.ai

The Levo-all uses an authorization key to access Levo.ai.

- [Login](https://app.levo.ai/login) to Levo.ai.
- Click on your user profile.
- Click on `User Settings`
- Click on `Keys` on the left navigation panel
- Click on `Get Satellite Authorization Key`

Copy your authorization key. This key is required in subsequent steps below.


### Install Levo-all (Sensor, Satellite and Log Parser)

The Sensor-Satellite setup can be run with the following docker command -

```bash
docker run -e LEVOAI_AUTH_KEY=<your-auth-key> \
  -e LEVOAI_ORG_ID=<your-org-id> \
  --net=host \
  -v ./logs:/mnt/levo/logs
  levoai/levo-all
```

## Required Environment Variables

- **LEVOAI_AUTH_KEY**
    - *Description:* The Satellite CLI authorization key from app.levo.ai
    - *Default:* ""

- **LEVOAI_ORG_ID**
    - *Description:* Organization ID for your specific organization in your app.
    - *Default:* ""

### Note
- For more information on the environment variables, refer to the [Environment Variables](/install-traffic-capture-sensors/sensor-on-macos#required-environment-variables) section.
- For more information on log parser, refer to the [Log Parser](/install-traffic-capture-sensors/sensor-on-macos#log-parser) section.


**Please contact `support@levo.ai` if you notice health/connectivity related errors.**


---
sidebar_position: 4
keywords: [API Security, ZAP, OWASP, Linux, macOS, Windows, API Observability]
---

# Quickstart with Minikube

Run the following command to find out which driver your minikube installation is using:

```shell
minikube profile list
```

```
|----------|-----------|---------|--------------|------|---------|---------|-------|--------|
| Profile  | VM Driver | Runtime |      IP      | Port | Version | Status  | Nodes | Active |
|----------|-----------|---------|--------------|------|---------|---------|-------|--------|
| minikube | docker    | docker  | 192.168.49.2 | 8443 | v1.27.3 | Running |     1 | *      |
|----------|-----------|---------|--------------|------|---------|---------|-------|--------|
```

The second column in the output, `VM Driver`, should list the minikube driver of your existing minikube profile.

If you want to test the eBPF Sensor in minikube, we recommend using minikube with a VM driver (e.g. kvm2 or virtualbox). Or if you are already using a VM, you may run minikube on bare metal (with the "none" driver).

You can find the full list of minikube drivers [in the minikube docs](https://minikube.sigs.k8s.io/docs/drivers/).

Based on your minikube driver, follow the instructions below:


## Bare-metal or VM-based driver
Follow the [standard Kubernetes installation instructions](/install-traffic-capture-sensors/ebpf-sensor/sensor-kubernetes).


## Docker driver
Since the eBPF Sensor needs access to the `/proc` folder on the host, there are additional steps to ensure that the directory is mounted correctly inside the Sensor container for running it in minikube with the Docker driver.

First, run:

```shell
minikube mount /proc:/ggproc
```

Then, in a new terminal window, run:

```shell
helm repo add levoai https://charts.levo.ai && helm repo update
helm pull levoai/levoai-ebpf-sensor --untar
cd levoai-ebpf-sensor/
sed -i "s/path: \/proc/path: \/ggproc/" templates/deployment.yaml
helm upgrade --install levoai-sensor . -n levoai
```


---
sidebar_position: 7
keywords: [API Security, eBPF, macOS, Windows, API Observability]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Quickstart with MITM proxy

Quickstart instructions for evaluating *API Observability* on Laptops/Desktops running **Mac OSX** or **Windows**.

![Levo Sensor Package for OSX/Windows](../assets/api-observability-laptops.svg)

Since Mac OSX and Windows do not support [eBPF](https://ebpf.io), Levo provides a Sensor package (Docker based install), to enable quick evaluation on these platforms. This Sensor package gets visibility into your API traffic, by **[reverse proxying](https://www.cloudflare.com/learning/cdn/glossary/reverse-proxy/)** traffic between your *API Client* and *API Server*.

**Your estimated completion time is *10 minutes*.**

## 1. Prerequisites
<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <ul>
      <li> Docker Engine version `18.03.0` and above </li>
      <li> Admin (or `sudo`) privileges on the Docker host </li>
      <li> <a href="https://levo.ai/levo-signup/">Forever Free Account on Levo.ai</a> </li>
      <li> Command line terminal with Bash or Bash compatible shell </li>
    </ul>
  </TabItem>
  <TabItem value="win" label="Windows">
    <ul>
      <li> Docker Engine version `18.03.0` and above </li>
      <li> Admin privileges on the Docker host </li>
      <li> <a href="https://levo.ai/levo-signup/">Forever Free Account on Levo.ai</a> </li>
      <li> Docker containers MUST be allowed to connect to the internet. Please check Firewall settings </li>
      <li> PowerShell terminal </li>
    </ul>
  </TabItem>
</Tabs>



## 2. Setup Test *API Service*

API Observability auto discovers APIs and generates OpenAPI specifications for all API endpoints, by observing API traffic between your *API Client* and *API Server*.

If you do not have a test *API Service*/*Application*, you can use the [sample application](/guides/demo-application) provided by Levo.

- a. Note down the base URL for your test *API Server*/*Service*.
> For example, if you are running the sample application (crAPI) on your laptop, the base URL would be `http://localhost:8888`. If your local test *API Server* uses HTTPs the base URL for example, would be `https://localhost/`.

  > Since the Sensor package runs in a container, addresses like `localhost`, `127.0.0.1`, etc., that refer to the Docker host, must be translated to ones, that can be resolved correctly to point to the Docker host inside the container. Please specify `host.docker.internal` instead of `localhost` or `127.0.0.1` in the base URL.

  > In essence, if your base URL is `http://localhost:<port>` or `http://127.0.0.1:<port>`, you will need to specify `http://host.docker.internal:<port>` instead below.

- b. Export your *API Server*/*Service* URL in your terminal.
<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        export SERVICE_ADDRESS=&lt;http://host:port/base-path&gt;
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        $env:SERVICE_ADDRESS="&lt;http://host:port/base-path&gt;"
      </code>
    </pre>
  </TabItem>
</Tabs>



## 3. Copy `Authorization Key` from Levo.ai
The Sensor package uses an authorization key to access Levo.ai. Follow instructions below to copy & export the key.
- [Login](https://app.levo.ai/login) to Levo.ai.
- Click on your user profile.
- Click on `User Settings`
- Click on `Keys` on the left navigation panel
- Click on `Get Satellite Authorization Key`
- Now copy your authorization key.
- Export the copied `Authorization Key` in your terminal.

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        export LEVOAI_AUTH_KEY=&lt;'Authorization Key' copied above&gt;
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        $env:LEVOAI_AUTH_KEY="&lt;'Authorization Key' copied above&gt;"
      </code>
    </pre>
  </TabItem>
</Tabs>



## 4. Pick an `Application Name`
Auto discovered API endpoints and their OpenAPI specifications are show in the [API Catalog](/guides/security-testing/concepts/api-catalog/api-catalog.md), grouped under an application name. The application name helps segregate and group API endpoints from different API servers, similar to how file folders work in an operating system.

- a. Pick a descriptive name which will be used in the subsequent step below. For example: `my-test-api-server`.
- b. Export the `Application Name` in your terminal.

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        export LEVOAI_SERVICE_NAME=&lt;'Application Name' chosen above&gt;
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        $env:LEVOAI_SERVICE_NAME="&lt;'Application Name' chosen above&gt;"
      </code>
    </pre>
  </TabItem>
</Tabs>


## 5. Download - Docker Compose file

Execute the following in your terminal:

import BrowserOnly from '@docusaurus/BrowserOnly';

export function CurlScript(props) {
  var curlCmd = "curl";
  if (props.curlCmd) {
    curlCmd = props.curlCmd;
  }
  return (
    <BrowserOnly fallback={<div>Loading...</div>}>
      {() => (
        <pre>
          <code>
              {curlCmd} -s -o proxy-docker-compose.yml {window.location.protocol + '//' + window.location.host + '/artifacts/satellite/proxy-docker-compose.yml'}
          </code>
        </pre>
      )}
    </BrowserOnly>
  );
}

export function DownloadLink() {
  return (
    <BrowserOnly fallback={<div>Loading...</div>}>
      {() => (
        <a href={window.location.protocol + '//' + window.location.host + '/artifacts/satellite/proxy-docker-compose.yml'}> here </a>
      )}
    </BrowserOnly>
  );
}

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <CurlScript/>
  </TabItem>
  <TabItem value="win" label="Windows">
    <CurlScript curlCmd="curl.exe"/>
  </TabItem>
</Tabs>

If prefer to download the Docker Compose file via your browser, you can download it <DownloadLink/>.



## 6. Install Sensor Package via Docker Compose
Execute the following in your terminal (where you previously downloaded the Docker Compose file):

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        docker compose -f proxy-docker-compose.yml pull &amp;&amp; docker compose -f proxy-docker-compose.yml up -d
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        docker compose -f .\proxy-docker-compose.yml pull
      </code>
    </pre>
    <pre>
      <code>
        docker compose -f .\proxy-docker-compose.yml up -d  
      </code>
    </pre>
  </TabItem>
</Tabs>



## 7. Verify Connectivity with Levo.ai

The Sensor package contains both the (proxy based) Sensor and Satellite. Follow steps below to check the Satellite health and connectivity to Levo.ai.

#### a. Check Satellite Health

The Satellite is comprised of four sub components 1) levoai-collector, 2) levoai-rabbitmq, 3)levoai-satellite, and 4) levoai-tagger.

Wait couple of minutes after the install, and check the health of the components by executing the following:

```bash
docker ps -f name=levoai
```

If the Satellite is healthy, you should see output similar to below.

```bash
CONTAINER ID   IMAGE                        COMMAND                  CREATED          STATUS                    PORTS                                                                                                         NAMES
5a54d8efe672   levoai/proxy:latest          "docker-entrypoint.s…"   50 seconds ago   Up 37 seconds              0.0.0.0:8081->8081/tcp, 0.0.0.0:9080->8080/tcp                                                                              levoai-proxy
8767c62db6cb   levoai/satellite:latest      "python -OO /opt/lev…"   50 seconds ago   Up 37 seconds                                                                                                                           levoai-tagger
dcb187e00ff2   levoai/satellite:latest      "gunicorn --capture-…"   50 seconds ago   Up 37 seconds             0.0.0.0:9999->9999/tcp                                                                                        levoai-satellite
169ceecf0263   rabbitmq:3.10.5-management   "docker-entrypoint.s…"   50 seconds ago   Up 49 seconds (healthy)   4369/tcp, 5671/tcp, 0.0.0.0:5672->5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672->15672/tcp   levoai-rabbitmq
```

#### b. Check Connectivity
Execute the following to check for connectivity health:

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        docker logs levoai-tagger 2>&1 | grep "Ready to process; waiting for messages." 
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        docker logs levoai-tagger 2>&1 | sls "Ready to process; waiting for messages." 
      </code>
    </pre>
  </TabItem>
</Tabs>

<br/>

If connectivity is **healthy**, you will see output similar to below:

```json
{"level": "info", "time": "2022-06-07 08:07:22,439",
"line": "rabbitmq_client.py:155", "version": "fc628b50354bf94e544eef46751d44945a2c55bc", 
"module": "/opt/levoai/e7s/src/python/levoai_e7s/satellite/rabbitmq_client.py", 
"message": "Ready to process; waiting for messages."}
```

**Please contact `support@levo.ai` if you notice health/connectivity related errors.**



## 8. Generate Application Traffic

The Sensor picks up API traffic that is HTTP\1.x based. There has to be some consistent load on your API endpoints for them to be auto discovered and documented.

### a. Point Your *API Client* to the Sensor

The Sensor acts as a **[reverse proxy](https://www.cloudflare.com/learning/cdn/glossary/reverse-proxy/)** for your *API Server*. You will need to point your *API Client* to the Sensor. The Sensor will proxy the traffic to your test *API Server*/*Service*.

The Sensor listens on [http://127.0.0.1:9080](http://127.0.0.1:9080). Please point your API Client (Web Browser, [Postman](https://www.postman.com/), [curl](https://curl.se/), etc.) to this address (instead of the *API Server's* address).

> If your *API Server* uses HTTP/s (TLS), the Sensor will use HTTP/s when proxying traffic to it. However your *API Client* will need to use **HTTP** when talking to the Sensor.

> If you are using `/etc/hosts` (or equivalent in Windows) to resolve the IP address of your *API Server*, please edit the appropriate `/etc/hosts` entry to point to `127.0.0.1` (IP address of the Sensor).

### b. Generate Traffic

Please ensure you exercise your API endpoints several times using using your *API Client*. Use a load generator to generate consistent traffic, if necessary.

### c. Verify API Traffic Capture
Check the logs of Satellite's `Tagger` sub-component.

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        docker logs levoai-tagger 2>&1 | grep "Consuming the span" 
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        docker logs levoai-tagger 2>&1 | sls "Consuming the span" 
      </code>
    </pre>
  </TabItem>
</Tabs>

If API Traffic is correctly being processed, you will see a lot of log entries containing the term `Consuming the span`.



## 9. View Auto-discovered OpenAPI Specifications
The [API Catalog](/guides/security-testing/concepts/api-catalog/api-catalog.md) in Levo.ai should be auto populated in a matter of minutes (after your API endpoints are being exercised consistently).

The API Catalog will contain your auto discovered API endpoints and their OpenAPI schemas, all grouped under the `Application Name` you chose earlier.

**Congratulations! You have successfully auto discovered and auto documented API endpoints in your application.**
<br/>

---------------------------------
## Common Tasks

### Shutdown Sensor
Execute the following in the directory where you downloaded the Docker Compose file:
```bash
docker compose -f proxy-docker-compose.yml down
```

### Change Sensor Listen Port
The Sensor by default listens on TCP port 9080 (interface address 127.0.0.1). If this conflicts with a port being used by another application, you can change it by following the instructions below.

- [Shutdown](quickstart-mitm.md#shutdown-sensor) the Sensor (if running)
- Export your desired port in your terminal
<Tabs groupId="operating-systems">
  <TabItem value="mac" label="Mac OSX">
    <pre>
      <code>
        export LEVOAI_PROXY_PORT=&lt;Your desired port number&gt;
      </code>
    </pre>
  </TabItem>
  <TabItem value="win" label="Windows">
    <pre>
      <code>
        $env:LEVOAI_PROXY_PORT="&lt;Your desired port number&gt;"
      </code>
    </pre>
  </TabItem>
</Tabs>
- [Start](./quickstart-mitm.md#6-install-sensor-package-via-docker-compose) the Sensor



---
sidebar_position: 6
keywords: [API Security, ZAP, OWASP, Linux, macOS, Windows, API Observability]
---

# Quickstart with OWASP ZAP

The Levo.ai add-on for ZAP allows building OpenAPI specs with the traffic sent or proxied via ZAP.

This guide assumes that you have [signed up for a Levo account](https://app.levo.ai/signup) and have [installed a recent version of ZAP](https://www.zaproxy.org/download/) (> 2.12.0).

Here are the steps you need to follow to start building OpenAPI specs with Levo and ZAP:
1. The OpenAPI spec is built by sending anonymized API traces to Levo. You may run the *Satellite* (a set of services which receives and processes the traces) locally using docker or minikube, or on AWS with an AMI provided by Levo.

   [Click here for instructions on installing the satellite](/install-satellite).

   Please ensure that ZAP is able to reach the satellite at the configured listening port (the default is `9999`).

2. Launch ZAP and install the Levo.ai add-on from the [ZAP Marketplace](https://www.zaproxy.org/addons/). You may need to restart ZAP after the add-on is installed.
3. If the add-on is successfully installed, you should see a new button in the main toolbar.
   ![Screenshot of the Levo.ai button in ZAP's main toolbar](../assets/zap-levo-button-toolbar.png)

   Clicking on it will toggle sending traffic to Levo's satellite.
4. Navigate to Tools &rarr; Options &rarr; Levo.ai in ZAP and enter the URL pointing to the satellite (e.g. `http://localhost:9999`).

   ![Screenshot of the Levo.ai Options Panel in ZAP](../assets/zap-levo-options.png)
5. Ensure that the Levo button is enabled in the toolbar, and you are good to go! Start browsing your website using ZAP and you should start seeing auto-discovered applications in your Levo dashboard in a few minutes.


---
sidebar_position: 1
---

# Quickstart

Evaluate Levo's API Observability in Action with your favourite tools.

- [Quickstart on Mac](quickstart-mac.md)
- [Quickstart on Windows](quickstart-kubernetes.md)
- [Quickstart with Minikube](quickstart-minikube.md)
- [Quickstart with Burp](quickstart-burp-plugin.md)
- [Quickstart with OWASP ZAP](quickstart-zap-addon.md)
- [Quickstart with MITM proxy in Docker](quickstart-mitm.md)

> If you are looking for comprehensive install instructions (for all supported platforms), please refer to the [Install Guide](../guides/install-guide/install-guide.md).


---
sidebar_position: 0
---

# Running Tests from Catalog

Levo provides you with the ability to run a variety of tests on your API endpoints using the Run Tests feature.

### Navigate to the `Applications` tab and choose an Application you want to run tests against.

![](../assets/testruns-step-1.png)

<br></br>

### Click on the `Run Tests` button on the bottom right side of the screen. You can choose to
- `Run On Cloud`: The tests will be run on Levo's platform, i.e., the requests to the target server are made by Levo. This means that the application must be exposed via a publicly reachable domain or IP address.
- `Run OnPrem`: The tests will run on your premise. Head to the **[testrunners](testrunner.md)** page to know how to install **Testrunners**.

![](../assets/testruns-step-2.png)

<br></br>

### Select Runnable Endpoints on the next screen.

![](../assets/testruns-step-3.png)

>Note: You can configure non-runnable endpoints by manually entering sample values for mandatory parameters.

<br></br>

### Click on Next and select the categories of test you want to run from and choose from a wide variety of Tests like BOLA, SQLI, CORS, Fuzzing, etc.

![](../assets/testruns-step-4.png)

<br></br>

### Enter a Target URL to run tests against, e.g. `http://crapi.levo.ai` and click on `Run Tests` to start the tests' execution.

![](../assets/testruns-step-5.png)


---
sidebar_position: 2
---

# GitHub Action
Levo's security/contract tests can be embedded in quality gates via [GitHub Actions](https://docs.github.com/en/actions).

Below are examples of embedding Levo's autogenerated tests in GitHub CI/CD via pre-built actions. You have two choices.
- [Execute Test Plans](#execute-test-plans-via-actions)
- [Execute Standalone Contract Tests](#execute-standalone-schema-conformance-tests-aka-contract-tests-via-actions)


### Execute Test Plans Via Actions

#### Prerequisites
- Forever Free Account on Levo.ai
- A runnable Levo [Test Plan](/guides/security-testing/concepts/test-plans)

#### Action Configuration

The pre-built action for executing `Test Plans` requires the following configuration settings:

- `authorization-key` : Specify your CLI authorization key here. Refer to [Generating CLI Authorization Keys](/integrations/common-tasks.md#generating-cli-authorization-keys) for instructions on fetching your key

- `organization-id` : Specify your *Organization ID* here. Refer to [Accessing Organization IDs](/integrations/common-tasks.md#accessing-organization-ids) for instructions on fetching your ID

- `target` : The base URL of the Application/API under test

- `plan` : Specify the LRN of your Levo Test Plan (from the Levo console) here. The LRN uniquely identifies the Test Plan to execute

  ![LRN](../assets/test-plan-lrn.png)

- `base64_env` : This is an **OPTIONAL** setting.

  If you are using an [environment file](/guides/security-testing/test-your-app/test-app-security/data-driven/configure-env-yml) to define authentication details, you add the contents of the file here in BASE64 encoded format.

- `report` : This is an **OPTIONAL** setting.

  This setting controls the reporting of test results to the Levo Cloud. If you do not want to send test results to the Levo Cloud, set this to `false`. The default value is `true`.

- `cli_extra_args` : This is an **OPTIONAL** setting.

  Use this setting to pass extra CLI arguments like headers or the verbosity level. Please use `\\\˝` to escape quotes.

  E.g. `cli_extra_args: "-H \\\"Authorization: Bearer 1234\\\" --verbosity INFO"`

Here is a sample *Test Plan Action* with its configuration:

```YAML
- uses: levoai/actions/test-plan@v1-beta
  with:
    # Authorization key required to execute the Levo CLI. Please refer to https://app.levo.ai/settings/keys to get your authorization key.
    authorization-key: <'Specify your CLI authorization key here'>

    # The ID of your organization in Levo dashboard. Please refer to https://app.levo.ai/settings/organization to get your organization id.
    organization-id: <'Specify your organization ID here'>

    # The base URL of the Application/API under test.
    target: <'Specify the target base URL here'>

    # Test plan LRN. You can get this value from the test plan section in the Levo SaaS console.
    plan: <'Specify your Test Plan's LRN here'>

    # [OPTIONAL] Base64 encoded environment file content.
    base64_env: <'The contents of your environment file as a BASE64 encoded string here'>

    # [OPTIONAL] If you do not want to report the result of this execution to the Levo cloud, set this value to false. Default: true.
    report: <true|false>

    # [OPTIONAL] Use this option to pass extra CLI arguments like headers or verbosity.
    # Please use \\\˝ to escape quotes.
    # E.g. cli_extra_args: "-H \\\"Authorization: Bearer 1234\\\" --verbosity INFO"
    cli_extra_args: <"Specify any extra arguments here">
```

#### Job Outputs
This pre-built *Action* produces the below [Outputs](https://docs.github.com/en/actions/using-jobs/defining-outputs-for-jobs), which can be referenced by downstream Actions/Jobs.

```YAML
outputs:
  success:
    description: '# of successful test cases'
  failed:
    description: '# of failed test cases'
  skipped:
    description: '# of skipped test cases'
```


### Execute Standalone Schema Conformance Tests (aka Contract Tests) Via Actions

#### Prerequisites
- Forever Free Account on Levo.ai

#### Action Configuration

The pre-built action for executing standalone `Schema Conformance Tests` requires the following configuration settings:

- `authorization-key` : Specify your CLI authorization key here. Refer to [Generating CLI Authorization Keys](/integrations/common-tasks.md#generating-cli-authorization-keys) for instructions on fetching your key

- `organization-id` : Specify your *Organization ID* here. Refer to [Accessing Organization IDs](/integrations/common-tasks.md#accessing-organization-ids) for instructions on fetching your ID

- `schema` : The URL or file path of the (under test) API's OpenAPI schema (YAML or JSON format)

- `target` : The base URL of the Application/API under test

- `report` : This is an **OPTIONAL** setting.

  This setting controls the reporting of test results to the Levo Cloud. If you do not want to send test results to the Levo Cloud, set this to `false`. The default value is `true`.

- `cli_extra_args` : This is an **OPTIONAL** setting.

  Use this setting to pass extra CLI arguments like headers or the verbosity level. Please use `\\\˝` to escape quotes.

  E.g. `cli_extra_args: "-H \\\"Authorization: Bearer 1234\\\" --verbosity INFO"`

Here is a sample *Schema Conformance Test Action* with its configuration:

```YAML
- uses: levoai/actions/schema-conformance@v1-beta
  with:
    # Authorization key required to execute the Levo CLI. Please refer to https://app.levo.ai/settings/keys to get your authorization key.
    authorization-key: <'Specify your CLI authorization key here'>

    # The ID of your organization in the Levo dashboard. Please refer to https://app.levo.ai/settings/organization to get your organization id.
    organization-id: <'Specify your organization ID here'>

    # The URL or file path of the API's OpenAPI schema.
    schema: '<URL of schema|File path of schema>'

    # The base URL of the Application/API under test.
    target: '<Specify the target base URL here>'

    # [OPTIONAL] If you do not want to report the result of this execution to the Levo cloud, set this value to false. Default: true.
    report: <true|false>

    # [OPTIONAL] Use this option to pass extra CLI arguments like headers or verbosity.
    # Please use \\\˝ to escape quotes.
    # E.g. cli_extra_args: "-H \\\"Authorization: Bearer 1234\\\" --verbosity INFO"
    cli_extra_args: <"Specify any extra arguments here">
```

#### Job Outputs
This pre-built *Action* produces the below [Outputs](https://docs.github.com/en/actions/using-jobs/defining-outputs-for-jobs), which can be referenced by downstream Actions/Jobs.

```YAML
outputs:
  success:
    description: '# of successful test cases'
  failed:
    description: '# of failed test cases'
```


---
sidebar_position: 3
---

# Jenkins Plugin

Levo's security/contract tests can be embedded in Jenkins quality gates via Levo's [Jenkins plugin](https://plugins.jenkins.io/levo/).

### Prerequisites
- Forever Free Account on Levo.ai
- A runnable Levo [Test Plan](/guides/security-testing/concepts/test-plans/test-plans.md)
- A `Levo CLI Authorization Key`. Refer to instructions [here](/integrations/common-tasks.md#generating-cli-authorization-keys)

### Installation
Below are the installation options:

- [Using the GUI](https://www.jenkins.io/doc/book/managing/plugins/#from-the-web-ui): From your Jenkins dashboard navigate to `Manage Jenkins > Manage Plugins` and select the `Available` tab. Locate the plugin by searching for levo, and install it

- Using the [CLI tool](https://github.com/jenkinsci/plugin-installation-manager-tool):
    ```bash
    jenkins-plugin-cli --plugins levo:33.vc34b_8f81dc9a
    ```

- Using [direct upload](https://www.jenkins.io/doc/book/managing/plugins/#advanced-installation). Download one of the [releases](https://plugins.jenkins.io/levo/#releases) and upload it to your Jenkins instance

### Running Levo Test Plans Via Freestyle Projects (Jobs)
Follow the steps below to create a build job, that executes a Levo Test Plan against your build target.

1. Create a `Freestyle project` and name it appropriately

2. Optionally configure the `General`, `Build Triggers`, and `Build Environment` sections based on your preferences

3. Add `Levo Test Plan` build step to `Build Steps`

   ![Jenkins Build Step](../assets/jenkins-build-step.png)

4. Configure the build step as shown below:

   ![Levo Build Step Config](../assets/jenkins-levo-test-plan-build-step.png)

   i. `Test Plan`

   Copy the LRN of your Levo Test Plan (from the Levo console), and paste it in the Test Plan section. The LRN uniquely identifies the Test Plan to execute.

   ![LRN](../assets/test-plan-lrn.png)

   ii. `Target`

   Specify the API target that needs to be tested here. This is usually the base URL of your API.

   iii. `Extra CLI Arguments` (optional)

   Please refer to the [CLI Command Reference](/security-testing/test-laptop/levo-cli-command-reference.md). Specify any optional arguments based on your preferences here.

   iv. `Generate JUnit Reports`

   If you would to generate build results (Test Plan execution results) in standard [JUnit format](https://www.ibm.com/docs/en/developer-for-zos/14.1.0?topic=formats-junit-xml-format), check the box titled `Generate JUnit Reports`.

   v. `Levo Credentials`

   You will need to specify the *Levo CLI Authorization Key* here. The Jenkins [Credentials Provider Plugin](https://plugins.jenkins.io/credentials/) is utilized to securely store the API key.

   ![Jenkins Credentials](../assets/add-jenkins-cli-auth-key.png)

    - Click on the "Add" button next to the credentials dropdown
    - Select your domain
    - Select "Levo CLI Credentials" for Kind
    - Select your `Scope` based on your preferences
    - Enter your *Organization ID* in the `Organization Id` text box. Refer to [Accessing Organization IDs](/integrations/common-tasks.md#accessing-organization-ids) for instructions on fetching your ID
    - Enter your CLI authorization key in the `CLI Authorization Key` textbox. Refer to [Generating CLI Authorization Keys](/integrations/common-tasks.md#generating-cli-authorization-keys) for instructions on fetching your key
    - Click `Add` to save the credentials
    - Finally select the credential you just added

   vi. `Environment Secret Text`

   If you are using an [environment file](/guides/security-testing/test-your-app/test-app-security/data-driven/configure-env-yml) to define authentication details, you add those details as a secret file here.

   ![Environment File for Jenkins](../assets/add-env-file-to-jenkins-secret.png)

    - Click on the "Add" button next to the *Environment Secret Text* dropdown
    - Select your domain
    - Select "Secret file" for Kind
    - Select your `Scope` based on your preferences
    - Import your `environment.yml` file using the file chooser dialog
    - Click `Add` to save the environment.yml as a secret file
    - Now select the secret file you just added

5. Optionally configure `Post-build Actions`

6. `Save/Apply` your `Freestyle Project` configuration. You are done!




---
sidebar_position: 1
---

# Test Runner

Levo provides you with the ability to run security tests on your Application endpoints.

With Levo you can run security tests
- on Cloud
- on Premises


To run security tests we need three things
- A target service URL which should be reachable
- Valid configuration for authenticated endpoints
- Valid API endpoint parameters


If the target service is publicly reachable, tests can be run directly from Levo Cloud

But if you want to test some internal services which are not publicly reachable, you can use the **testrunner**.

The testrunner can be installed in your premise.

Once you start security tests from the UI, the testrunner will pull those tests and execute them in your premise.
This way if you want to test internal APIs, you can install our testrunner service.
<br></br>

## Installation

You can install the testrunner
- [via helm in Kubernetes environment](#install-testrunner-via-helm-on-kubernetes)
- [via docker](#install-testrunner-via-docker)

### Prerequisites
- You will need an authorization token and the organization-id for which you want to run security tests
- Either helm or docker installed based on the installation process.
<br></br>

### Install testrunner via helm on Kubernetes

To get the authorization token and organization-id, follow instructions [here](#get-authorization-token-and-orgnaization-id)


- Add Levo Helm repo

```bash
helm repo add levoai https://levoai.github.io/helm-charts/
```

- Run following command to install testrunner helm chart

```bash
helm install \
--set key="auth-key" \
--set orgId="organization id" \
--set levoBaseUrl="https://api.levo.ai" \
testrunner levoai/testrunner
```

:::info

Depending on the region your apps are in, you may need to set a different Levo base URL.

For example, if the testrunner will be used with `app.india-1.levo.ai`, use the following alias:

```bash
helm install \
--set key="auth-key" \
--set orgId="organization id" \
--set levoBaseUrl="https://api.india-1.levo.ai" \
testrunner levoai/testrunner
```
:::

<br></br>

### Install testrunner via Docker

To get the authorization token and organization-id, follow instructions [here](#get-authorization-token-and-orgnaization-id)

If you have docker running on your machine, you can start the testrunner with a simple `docker run` command

```bash
mkdir -p $HOME/.config/configstore
 
alias levo='docker run --rm \
    --add-host=host.docker.internal:`ip route|awk '\''/docker0/ { print $9 }'\''` \
    --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e LOCAL_USER_ID=$(id -u) \
    -e LOCAL_GROUP_ID=$(id -g) \
    -e LEVO_BASE_URL=https://api.levo.ai \
    -e TERM=xterm-256color \
    -ti levoai/levo:stable'

levo start --key "auth-key" --organization "orgId"
```
:::info

Depending on the region your apps are in, you may need to set a different Levo base URL.

For example, if the testrunner will be used with `app.india-1.levo.ai`, use the following alias:

```bash
alias levo='docker run --rm \
    --add-host=host.docker.internal:`ip route|awk '\''/docker0/ { print $9 }'\''` \
    --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e LOCAL_USER_ID=$(id -u) \
    -e LOCAL_GROUP_ID=$(id -g) \
    -e LEVO_BASE_URL=https://api.india-1.levo.ai \
    -e TERM=xterm-256color \
    -ti levoai/levo:stable'
```

:::
<br></br>

### Get Authorization token and Orgnaization ID

[Login](https://app.levo.ai/login) to  Levo.ai

To get the authorization token
- Click on User Settings
- Click on Keys on the left navigation panel
- Click on Get CLI Authorization Key

To get the Organization ID
- Click on User Settings
- Click on Organizations on the left navigation panel
- Click on Copy for whichever organization you want to run tests for

:::info
If you are an India Customer <br></br>
[India Login](https://app.india-1.levo.ai/login) for  Levo.ai
:::







---
sidebar_position: 5
---

# Levo CLI Command Reference

## help
Show help message for the CLI,

`levo --help`

## version
Show the current version of the CLI.

`levo --version`

## login
`levo login [options] <arguments>`

```
Authenticate the CLI with Levo's SaaS portal.

Options:
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
                                  OPTIONAL Accept all of the Python's log
                                  level values: CRITICAL, ERROR, WARNING,
                                  INFO, DEBUG, and NOTSET (all case
                                  insensitive).
  -k, --key TEXT                  Specify an authorization key to login with.
                                  Go to https://app.dev.levo.ai/settings/keys
                                  to get your authorization key.
  -o, --organization TEXT         OPTIONAL Specify the id of the organization
                                  you want to work with.
  -h, --help                      Show this message and exit.
```

The login command might ask you for a `CLI Authorization Key`, that is used to authenticate the CLI with Levo.ai. This key can be retrieved from [User Profile-->User Settings-->Keys](https://app.dev.levo.ai/settings/keys).

You will need an account on [Levo.ai](https://levo.ai/levo-signup/) to retrieve the key.

The login command stores authentication tokens in the `$HOME/.config/configstore/levo.json` file (on the Docker host). This file is only accessible by the user who owns the $HOME directory. Treat this file as do with any secrets.

## logout
`levo logout [options]`

```
Removes the local login config file.

Options:
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
                                  OPTIONAL Accept all of the Python's log
                                  level values: CRITICAL, ERROR, WARNING,
                                  INFO, DEBUG, and NOTSET (all case
                                  insensitive).
  -h, --help                      Show this message and exit.
```

The logout command removes the `$HOME/.config/configstore/levo.json` file (on the Docker Host). This file contains authentication tokens, and other local state persisted by the CLI.

## test-conformance
`levo test-conformance [options] <arguments>`

```
Perform schema conformance tests against API endpoints specified in the target-url.

Options:
  --schema TEXT                   --schema must specify a valid URL or file
                                  path (accessible from the CLI container)
                                  that points to an Open API / Swagger
                                  specification.  [required]
  --target-url TEXT               --target-url must specify a valid URL
                                  pointing to a live host that implements the
                                  endpoints specified by --schema.  [required]
  --disable-reporting-to-saas     Do not send test reports to Levo's SaaS
                                  portal.
  -H, --header TEXT               Custom header that will be used in all
                                  requests to the target server. Example: -H
                                  "Authorization: Bearer 123" .
  --show-errors-tracebacks        Show full tracebacks for internal errors.
  --ignore-ssl-verify TEXT        Controls whether the test run verifies the
                                  server's SSL certificate.
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
                                  OPTIONAL Accept all of the Python's log
                                  level values: CRITICAL, ERROR, WARNING,
                                  INFO, DEBUG, and NOTSET (all case
                                  insensitive).
  --export-junit-xml FILENAME     Export test results as JUnit XML
  -h, --help                      Show this message and exit.
```

> Levo CLI runs as a Docker container and by default mounts the current working directory on the host file system as read/write. If specifying a schema file as an argument, please provide a path that is accessible by the CLI container.

> Do not use `127.0.0.1` or `localhost` as arguments of the `--target-url`, as these will not resolve correctly within the CLI container. Please use `host.docker.internal` instead.

##### Usage Examples
`levo test-conformance --target-url http://host.docker.internal:9000/ --schema ./malschema.json`

`levo test-conformance --target-url http://host.docker.internal:9000/ --schema http://host.docker.internal:9000/api/openapi.json`

## test

`levo test [options] <arguments>`

```
Execute a test plan against the specified target-url.

Options:
  --target-url TEXT               --target-url must specify a valid URL
                                  pointing to a live host that implements the
                                  endpoints that are present in the test plan.
                                  [required]
  --disable-reporting-to-saas     Do not send test reports to Levo's SaaS
                                  portal.
  --test-plan TEXT                --test-plan must specify a valid Levo
                                  Resource Name (LRN) or a path to a Levo Test
                                  Plan folder (accessible from the CLI
                                  container).  [required]
  -H, --header TEXT               Custom header that will be used in all
                                  requests to the target server. Example: -H
                                  "Authorization: Bearer 123" .
  --show-errors-tracebacks        Show full tracebacks for internal errors.
  --env-file TEXT                 Path to YAML file with environment
                                  definitions (AuthN/AuthZ info, etc.). This
                                  file must be accessible from the CLI
                                  container.
  --ignore-ssl-verify TEXT        Controls whether the test run verifies the
                                  server's SSL certificate.
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
  -d, --suite-execution-delay INTEGER
                                  Adds a delay between test suite execution
  --request-timeout INTEGER       Timeout for the http request made to the API
  --export-junit-xml FILENAME     Export test results as JUnit XML
  -h, --help                      Show this message and exit.
```

> Levo CLI runs as a Docker container and by default mounts the current working directory on the host file system as read/write. If specifying a `Test Plan` folder as an argument, please provide a path that is accessible by the CLI container.

> Do not use `127.0.0.1` or `localhost` as arguments of the `--target-url`, as these will not resolve correctly within the CLI container. Please use `host.docker.internal` instead.

> Authentication credentials and user role information might be required by some `Test Plans` for proper execution. This is to be provided using the `--env-file` option. Please refer to details on [Authentication/Authorization][env-yaml].

##### Usage Examples
- Using a local test plan folder
`levo test --target-url host.docker.internal:8888 --test-plan ./my-test-plan-folder --env-file ./environment.yml`

- using a LRN (Levo Resource Name) for a test plan located in Levo SaaS
`levo test --target-url host.docker.internal:8888 --test-plan demo:app/Demo_crAPI:tp/Demo_crAPI --env-file ./environment.yml`

Here `demo:app/Demo_crAPI:tp/Demo_crAPI` is the LRN for a test plan located in Levo SaaS.


## test-plan

Test Plan management sub commands.

### run
This is an alias of the `levo test` command.

`levo test-plan run [options] <arguments>`

```
Run a test plan against the specified target-url.

Options:
  --target-url TEXT               --target-url must specify a valid URL
                                  pointing to a live host that implements the
                                  endpoints that are present in the test plan.
                                  [required]
  --disable-reporting-to-saas     Do not send test reports to Levo's SaaS
                                  portal.
  --test-plan TEXT                --test-plan must specify a valid Levo
                                  Resource Name (LRN) or a path to a Levo Test
                                  Plan folder (accessible from the CLI
                                  container).  [required]
  -H, --header TEXT               Custom header that will be used in all
                                  requests to the target server. Example: -H
                                  "Authorization: Bearer 123" .
  --show-errors-tracebacks        Show full tracebacks for internal errors.
  --env-file TEXT                 Path to YAML file with environment
                                  definitions (AuthN/AuthZ info, etc.). This
                                  file must be accessible from the CLI
                                  container.
  --ignore-ssl-verify TEXT        Controls whether the test run verifies the
                                  server's SSL certificate.
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
  -d, --suite-execution-delay INTEGER
                                  Adds a delay between test suite execution
  --request-timeout INTEGER       Timeout for the http request made to the API
  --export-junit-xml FILENAME     Export test results as JUnit XML
  -h, --help                      Show this message and exit.
```

> This command is a functional equivalent of the `levo test` command. Please see constraints and examples outlined for that command.

### export-env

The environment file is used to specify authentication credentials, and optional role(s)
information (for authorization tests). Please refer to [Authentication/Authorization][env-yaml].

`levo test-plan export-env [OPTIONS] <arguments>`

```
Export the environment file of a test plan from Levo SaaS to the local file system.

Options:
  --lrn TEXT                      The LRN of the test plan, whose environment
                                  file you want to export.  [required]
  --local-dir TEXT                Path to a local directory where the
                                  environment file is to be exported. The
                                  local directory must be accessible from the
                                  CLI container. If not specified, the test
                                  plan is exported to the current working
                                  directory.
  -v, --verbosity [NOTSET|DEBUG|INFO|WARNING|ERROR|CRITICAL]
                                  Accept all of the Python's log level values:
                                  CRITICAL, ERROR, WARNING, INFO, DEBUG, and
                                  NOTSET (all case insensitive).
  -h, --help                      Show this message and exit.
```

> Levo CLI runs as a Docker container and by default mounts the current working directory on the host file system as read/write.

##### Usage Examples
`levo test-plan export-env --lrn "acme-gizmo-org:ws/buchi:app/Demo_crAPI:tp/Demo_crAPI" --local-dir ./`

## Additional Notes

### Usage with a proxy

#### Option 1: Copy proxy CA certificate

The CLI container does not have access to the host's CA certificates. If you are using a proxy with a self-signed certificate, you can copy the CA certificate to `$HOME/.config/configstore/ca-cert.pem` on the host. This directory is mounted as a volume in the CLI container in the alias. The CLI will read this file if it exists and load it into the container's CA certificate store.

#### Option 2: Use the `--ignore-ssl-verify` option

You can use the `--ignore-ssl-verify` flag with the `levo` command to disable SSL verification for **all** requests made by the CLI, for example:

```shell
levo --ignore-ssl-verify test --target-url https://crapi.levo.ai --app-lrn your-app
```

The usage of this option is discouraged unless absolutely necessary.

:::tip
Adding the `--ignore-ssl-verify` flag after the `test` subcommand, e.g. `levo test --ignore-ssl-verify`, will cause SSL verification to be ignored only for the requests sent to the target server.
:::

[env-yaml]: /guides/security-testing/concepts/test-plans/env-yml.md


---
sidebar_position: 4
---

# Upgrading Levo CLI

Levo CLI is shipped as a Docker image. There are versioned Levo CLI images, and also tagged images with tags `latest` & `stable`. While you can pick the specific version of the image you want, it is recommend that you use the `stable` image.

Follow instructions below for your platform. 

> Note: if you update the `levo` alias, please remember to persist it in the shell's profile.

### Mac OS

*   To get the latest stable image type the following in a terminal:

```bash
docker pull levoai/levo:stable
```

*   To select a specific version of the image and update the alias (where x.x.x is the version):

```bash
docker pull levoai/levo:<x.x.x>

alias levo='docker run --rm -v $HOME/.config/configstore:/home/levo/.config/configstore:rw -v $HOME/.aws:/home/levo/.aws -v $PWD:/home/levo/work:rw -e TERM=xterm-256color -ti levoai/levo:<x.x.x>'
```

### Linux

*   To get the latest stable image type the following in a terminal:

```bash
docker pull levoai/levo:stable
```

*   To select a specific version of the image and update the alias (where x.x.x is the version):

```bash
docker pull levoai/levo:<x.x.x>

alias levo='docker run --rm --add-host=host.docker.internal:`ip route|awk '\''/docker0/ { print $9 }'\''` -v $HOME/.config/configstore:/home/levo/.config/configstore:rw -v $HOME/.aws:/home/levo/.aws -v $PWD:/home/levo/work:rw -e TERM=xterm-256color -ti levoai/levo:<x.x.x>'
```

### Windows

*   To get the latest stable image type the following in a terminal:

```plain
docker pull levoai/levo:stable
```

*   To select a specific version of the image and update the alias (where x.x.x is the version):

```plain
docker pull levoai/levo:<x.x.x>

Function Launch_Levo {docker run --rm -v ${HOME}/.config/configstore:/home/levo/.config/configstore:rw -v ${pwd}:/home/levo/work:rw -e TERM=xterm-256color -ti levoai/levo:<x.x.x> $args}
```

---
sidebar_position: 0
---

# Levo CLI (aka Test Runner)

![](../../assets/cli-test-runner.svg)

The CLI is the component that executes the autogenerated Test Plans. The CLI can be run on a developer's laptop or integrated into CI/CD environments.

The CLI is packaged as a Docker container, and is available for Mac OS, Windows, and Linux.

[Install Levo CLI for Mac OS][cli-mac]

[Install Levo CLI for Linux][cli-linux]

[Install Levo CLI for Windows][cli-win]

[Levo CLI Command Reference][cli-reference]


[cli-mac]: /security-testing/test-laptop/test-mac-os
[cli-linux]: /security-testing/test-laptop/test-linux
[cli-win]: /security-testing/test-laptop/test-windows
[cli-reference]: /security-testing/test-laptop/levo-cli-command-reference

---
sidebar_position: 2
---

# Test on Linux

### Prerequisites

*   Use of Levo CLI requires Docker (min version: 18.03.0)
*   Linux version that supports Docker
*   Ensure that you are able to launch and use Docker containers, and network connectivity works
*   Bash or Bash compatible shell
*   `ip` command installed (if missing see notes below)

### Instructions to Setup Levo CLI

*   Open a terminal (bash) window and type the following commands to setup an alias:

```bash
mkdir -p $HOME/.config/configstore
 
alias levo='docker run --rm \
    --add-host=host.docker.internal:`ip route|awk '\''/docker0/ { print $9 }'\''` \
    --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e LOCAL_USER_ID=$(id -u) \
    -e LOCAL_GROUP_ID=$(id -g) \
    -e TERM=xterm-256color \
    -ti levoai/levo:stable'
```

:::info

Depending on the region your apps are in, you may need to set a different Levo base URL for the satellite.

For example, if the CLI will be used with `app.india-1.levo.ai`, use the following alias:

```bash
alias levo='docker run --rm \
    --add-host=host.docker.internal:`ip route|awk '\''/docker0/ { print $9 }'\''` \
    --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e LOCAL_USER_ID=$(id -u) \
    -e LOCAL_GROUP_ID=$(id -g) \
    -e LEVO_BASE_URL=https://api.india-1.levo.ai \
    -e TERM=xterm-256color \
    -ti levoai/levo:stable'
```

:::

*   Now signup and create an account on [Levo.ai](https://Levo.ai) via the CLI:

```bash
levo login
```

### Notes

> Use of sudo with Docker may be required for your installation. Please refer to: [Run *docker* as non-root user](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user)

> The CLI container mounts your current working directory as R/W. This directory is used to read schema files, and export test plans etc.

> Please note that the alias is only available in the current terminal session. If you want to persist this across sessions, you need to persist this in the shell's profile (.bashrc, etc.). Please refer to the shell documentation.

> **ip** command can be installed as shown below:  
    - Debian: `sudo apt install iproute2`  
    - Fedora/CentOS: `sudo yum -y install iproute`  
    - Arch: `sudo pacman -S iproute2`

### [Upgrade Instructions][cli-upgrade]

[cli-upgrade]: levo-cli-upgrade-instructions.md#linux


---
sidebar_position: 1
---

# Test on Mac OS

### Prerequisites

*   Use of Levo CLI requires Docker (min version: 18.03.0)
*   OSX version that supports Docker
*   Ensure that you are able to launch and use Docker containers, and network connectivity works

### Instructions to Setup Levo CLI

* Open a terminal (zsh) window and type the following commands to setup an alias:

```bash
alias levo='docker run --rm \
    -v $HOME/.config/configstore:/home/levo/.config/configstore:rw \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e TERM=xterm-256color \
    -ti levoai/levo:stable'
```

:::info

Depending on the region your apps are in, you may need to set a different Levo base URL for the satellite.

For example, if the CLI will be used with `app.india-1.levo.ai`, use the following alias:

```bash
alias levo='docker run --rm \
    -v $HOME/.config/configstore:/home/levo/.config/configstore:rw \
    -v $HOME/.aws:/home/levo/.aws \
    -v $PWD:/home/levo/work:rw \
    -e TERM=xterm-256color \
    -e LEVO_BASE_URL=https://api.india-1.levo.ai \
    -ti levoai/levo:stable'
```

:::

* Now signup and create an account on [Levo.ai](https://Levo.ai) via the CLI:

```bash
levo login
```

### Notes

> The CLI container mounts your current working directory as R/W. This directory is used to read schema files, and export test plans etc.

> Please note that the alias is only available in the current terminal session. If you want to persist this across sessions, you need to persist this in the shell's profile (.bashrc, .zshrc, etc.). Please refer to the shell documentation.

### [Upgrade Instructions][cli-upgrade]

[cli-upgrade]: levo-cli-upgrade-instructions.md#mac-os




---
sidebar_position: 3
---

# Test on Windows

### Prerequisites

*   Windows 10 OS that supports Docker
*   Use of Levo CLI requires Docker for Windows (min version: 3.0.0)
*   Ensure that you are able to launch and use Docker containers, and network connectivity works
 
### Instructions to Setup Levo CLI

*   Open a powershell window and type the following commands to setup an alias:

```powershell
Function Launch_Levo {docker run --rm -v ${HOME}/.config/configstore:/home/levo/.config/configstore:rw -v ${pwd}:/home/levo/work:rw -e TERM=xterm-256color -ti levoai/levo:stable $args} 

Set-Alias -Name levo -Value Launch_Levo
```

:::info

Depending on the region your apps are in, you may need to set a different Levo base URL for the satellite.

For example, if the CLI will be used with `app.india-1.levo.ai`, use the following alias:

```powershell
Function Launch_Levo {docker run --rm -v ${HOME}/.config/configstore:/home/levo/.config/configstore:rw -v ${pwd}:/home/levo/work:rw -e TERM=xterm-256color -e LEVO_BASE_URL=https://api.india-1.levo.ai -ti levoai/levo:stable $args} 

Set-Alias -Name levo -Value Launch_Levo
```

:::

*   Now signup and create an account on [Levo.ai](http://Levo.ai) via the CLI:

```bash
levo login
```

### Notes

> The CLI container mounts your current working directory as R/W. This directory is used to read schema files, and export test plans etc.

> Please note that the alias is only available in the current powershell session. If you want to persist this across sessions, you need to persist this in the powershell profile. Please refer to the powershell documentation.


### [Upgrade Instructions][cli-upgrade]

[cli-upgrade]: levo-cli-upgrade-instructions.md#windows


---
sidebar_position: 0
---

# Security Vulnerability Guide

This section lists important vulnerabilities applicable to modern API driven applications.

### OWASP API Top 10

| Rank  | Vulnerability                               | CWE                                        |
| ----- | ------------------------------------------- | ---------------                            |
| A1    | [Broken Object Level Authorization][BOLA]   | [639][BOLA-CWE]                            |
| A2    | [Broken Authentication][BUA]                | [425][BUA-CWE], [287][BUA-CWE-2]           |
| A3    | [Excessive Data Exposure][EXPOSURE]         | [213][EXPOSURE-CWE]                        |
| A4    | [Lack of Resources and Rate Limits][RATES]  | [770][RATES-CWE]                           |
| A5    | [Broken Function Level Authorization][BFLA] | [1220][BFLA-CWE]                           |
| A6    | [Mass Assignment][MASS-ASSIGN]              | [915][MASS-ASSIGN-CWE]                     |
| A7    | [Security Misconfiguration][MISCONFIG]      | [1349][MISCONFIG-CWE]                      |
| A8    | [Injection][INJECTION]                      | [89][SQLi-CWE], [77][CMDi-CWE]             |
| A9    | [Improper Asset Management][ASSETS]         | [1059][ASSETS-CWE]                         |
| A10   | [Insufficient Logging & Monitoring][NOLOG]  | [778][NOLOG-CWE]                           |



### OWASP Web Top 10

| Rank  | Vulnerability                               | CWE                                        |
| ----- | ------------------------------------------- | ---------------                            |
| A10   | [Server Side Request Forgery][SSRF]         | [918][SSRF-CWE]                            |



### Miscellaneous

This section lists issues related to API security and resilience, but which cannot be purely categorized as security vulnerabilities.

| Issue                                                   | CWE                                                       |
| -----------------------------------------------------   | ----------------------------------------------------------|
| [API Schema Non Conformance][SC]                        | [1215][CWE-1215], [393][CWE-393]                          |
| [Unexpected 5XX Server Errors][SC-5XX]                  | [600][CWE-600]                                            |
| [Undocumented Response Codes][SC-CODES]                 | [394][CWE-394]                                            |
| [Inadequate Response Headers][SC-HDRS]                  | [838][CWE-838]                                            |
| [Incorrect Response Content Types][SC-CONT]             | [838][CWE-838]                                            |
| [Incorrect Response Body][SC-BODY]                      | [838][CWE-838]                                            |



### Baseline

*Baseline Security Controls* are a minimum set of foundational controls that APIs should implement. These are based on security best practices.

This section lists vulnerabilities arising due to the violation of these security controls. A number of these issues are applicable to [OWASP API A7][REF-OWASP-API-A7].


| Issue                                                   | CWE / Reference                                                 |
| -----------------------------------------------------   | ----------------------------------------------------------|
| [In Page Banner Information Leak][BL-IN_PAGE_BANNER_INFORMATION_LEAK] | [Testing for Error Codes][REF-ERROR-DISCLOSURE] |
| [Information Disclosure - Debug Error Messages][BL-DEBUG-MSGS]| [CWE-200][CWE-200]|
| [Information Disclosure - Sensitive Information in URL][BL-URL-PII]| [CWE-200][CWE-200]|
| [Information Disclosure - Sensitive Information in HTTP Referrer Header][BL-PII-REF-HDR]| [CWE-200][CWE-200]|
| [Application Error Disclosure][BL-APP-ERR-DISCLOSURE]| [CWE-200][CWE-200]|
| [X-Powered-By Information Leak][BL-SERVER_LEAKS_INFORMATION_VIA_X_POWERED_BY] | [CWE-200][CWE-200] |
| [Information Leak Via 'Server' HTTP Response Header][BL-SERVER-HDR]| [CWE-200][CWE-200]|
| [Private IP Disclosure In Response][BL-PRIV-IP-DISCLOSURE]| [CWE-200][CWE-200]|
| [PII Disclosure In Response][BL-PII-DISCLOSURE]| [CWE-359][CWE-359]|
| [Hash Disclosure In Response][BL-HASH-DISCLOSURE]| [CWE-200][CWE-200]|
| [Cross-Domain (CORS) Misconfiguration (Passive)][BL-CORS-PASSIVE]| [CWE-264][CWE-264]|
| [Sub Optimal Cache Control Directives][BL-RE_EXAMINE_CACHE_CONTROL_DIRECTIVES]| [CWE-525][CWE-525] |
| [Content Retrieved from Cache][BL-CACHE-RETRIEVE]| [CWE-525][CWE-525]|
| [Missing Strict-Transport-Security Header][BL-HSTS]| [Strict Transport Security Cheat Sheet][REF-HSTS]|
| [Missing Content-Type Header][BL-CONTENT-TYPE]| [CWE-345][CWE-345]|
| [Missing X-Content-Type-Options Header][BL-X-CONTENT-TYPE]| [CWE-693][CWE-693]|
| [Cookie Set Without HttpOnly Flag][BL-COOKIE-NO-HTTP-ONLY] | [CWE-1004][CWE-1004]|
| [Cookie Without Secure Flag][BL-COOKIE-NO-SECURE] | [CWE-614][CWE-614]|
| [Cookie Poisoning Via Query/Body Parameters][BL-COOKIE-POISON]| [CWE-20][CWE-20]|
| [Session ID in URL Via Rewrite][BL-SESS-ID-URL] | [CWE-200][CWE-200]|
| [Suboptimal Anti-clickjacking Headers][BL-ANTI-CLICKJACK]| [CWE-1021][CWE-1021]|
| [Open/Unrestricted URL Redirect Via URL Query Parameter][BL-OPEN-REDIRECT]| [CWE-601][CWE-601]|
| [Weak Authentication Method][BL-WEAK-AUTH]| [CWE-326][CWE-326]|
| [Java Serialization Detected][BL-JAVA-SERIALIZATION]| [CWE-502][CWE-502]|





[BOLA]: ./OWASP-API-10/A1-BOLA.md
[BOLA-CWE]: https://cwe.mitre.org/data/definitions/639.html

[BUA]: ./OWASP-API-10/A2-BUA.md
[BUA-CWE]: https://cwe.mitre.org/data/definitions/425.html
[BUA-CWE-2]: https://cwe.mitre.org/data/definitions/287.html

[EXPOSURE]: ./OWASP-API-10/A3-Excessive-Data-Exposure.md
[EXPOSURE-CWE]: https://cwe.mitre.org/data/definitions/213.html

[RATES]: ./OWASP-API-10/A4-Rate-Limits.md
[RATES-CWE]: https://cwe.mitre.org/data/definitions/770.html

[BFLA]: ./OWASP-API-10/A5-BFLA.md
[BFLA-CWE]: https://cwe.mitre.org/data/definitions/1220.html

[MASS-ASSIGN]: ./OWASP-API-10/A6-Mass-Assignment.md
[MASS-ASSIGN-CWE]: https://cwe.mitre.org/data/definitions/915.html

[MISCONFIG]: ./OWASP-API-10/A7-Security-Misconfiguration.md
[MISCONFIG-CWE]: https://cwe.mitre.org/data/definitions/1349.html

[SSRF]: ./OWASP-WEB-10/A10-SSRF.md
[SSRF-CWE]: https://cwe.mitre.org/data/definitions/918.html

[INJECTION]: ./OWASP-API-10/A8-Injection.md
[CMDi-CWE]: https://cwe.mitre.org/data/definitions/77.html
[SQLi-CWE]: https://cwe.mitre.org/data/definitions/89.html

[ASSETS]: ./OWASP-API-10/A9-Improper-Asset-Management.md
[ASSETS-CWE]: https://cwe.mitre.org/data/definitions/1059.html

[NOLOG]: ./OWASP-API-10/A10-Insufficient-Logging.md
[NOLOG-CWE]: https://cwe.mitre.org/data/definitions/778.html


[SC]: ./Miscellaneous/schema-conformance.md
[SC-CODES]: ./Miscellaneous/schema-conformance.md#status-code-conformance-test
[SC-HDRS]: ./Miscellaneous/schema-conformance.md#response-headers-schema-conformance-test
[SC-CONT]: ./Miscellaneous/schema-conformance.md#content-type-schema-conformance-test
[SC-BODY]: ./Miscellaneous/schema-conformance.md#response-schema-conformance-test
[SC-5XX]: ./Miscellaneous/schema-conformance.md#unexpected-server-error-schema-conformance-test


[CWE-20]: https://cwe.mitre.org/data/definitions/20.html
[CWE-200]: https://cwe.mitre.org/data/definitions/200.html
[CWE-264]: https://cwe.mitre.org/data/definitions/264.html
[CWE-326]: https://cwe.mitre.org/data/definitions/326.html
[CWE-345]: https://cwe.mitre.org/data/definitions/345.html
[CWE-359]: https://cwe.mitre.org/data/definitions/359.html
[CWE-393]: https://cwe.mitre.org/data/definitions/393.html
[CWE-394]: https://cwe.mitre.org/data/definitions/394.html
[CWE-502]: https://cwe.mitre.org/data/definitions/502.html
[CWE-525]: https://cwe.mitre.org/data/definitions/525.html
[CWE-600]: https://cwe.mitre.org/data/definitions/600.html
[CWE-601]: https://cwe.mitre.org/data/definitions/601.html
[CWE-614]: https://cwe.mitre.org/data/definitions/614.html
[CWE-693]: https://cwe.mitre.org/data/definitions/693.html
[CWE-838]: https://cwe.mitre.org/data/definitions/838.html
[CWE-1004]: https://cwe.mitre.org/data/definitions/1004.html
[CWE-1021]: https://cwe.mitre.org/data/definitions/1021.html
[CWE-1215]: https://cwe.mitre.org/data/definitions/1215.html
[CWE-1275]: https://cwe.mitre.org/data/definitions/1275.html


[BL-IN_PAGE_BANNER_INFORMATION_LEAK]: ./Baseline/in-page-banner-information-leak.md
[BL-SERVER_LEAKS_INFORMATION_VIA_X_POWERED_BY]: ./Baseline/server-leaks-information-via-x-powered-by-http-response-header-field-s.md
[BL-RE_EXAMINE_CACHE_CONTROL_DIRECTIVES]: ./Baseline/re-examine-cache-control-directives.md
[BL-HSTS]: ./Baseline/strict-transport-security-header.md
[BL-CONTENT-TYPE]: ./Baseline/content-type-header-missing.md
[BL-X-CONTENT-TYPE]: ./Baseline/x-content-type-options-header-missing.md
[BL-APP-ERR-DISCLOSURE]: ./Baseline/application-error-disclosure.md
[BL-COOKIE-NO-HTTP-ONLY]: ./Baseline/cookie-no-httponly-flag.md
[BL-COOKIE-NO-SECURE]: ./Baseline/cookie-without-secure-flag.md
[BL-COOKIE-POISON]: ./Baseline/cookie-poisoning.md
[BL-SESS-ID-URL]: ./Baseline/session-id-in-url-rewrite.md
[BL-DEBUG-MSGS]: ./Baseline/information-disclosure-debug-error-messages.md
[BL-URL-PII]: ./Baseline/information-disclosure-sensitive-information-in-url.md
[BL-PII-REF-HDR]: ./Baseline/information-disclosure-sensitive-information-in-http-referrer-header.md
[BL-PRIV-IP-DISCLOSURE]: ./Baseline/private-ip-disclosure.md
[BL-OPEN-REDIRECT]: ./Baseline/open-redirect.md
[BL-SERVER-HDR]: ./Baseline/http-server-response-header.md
[BL-CACHE-RETRIEVE]: ./Baseline/retrieved-from-cache.md
[BL-PII-DISCLOSURE]: ./Baseline/pii-disclosure.md
[BL-HASH-DISCLOSURE]: ./Baseline/hash-disclosure.md
[BL-CORS-PASSIVE]: ./Baseline/cross-domain-misconfiguration-passive.md
[BL-ANTI-CLICKJACK]: ./Baseline/anti-clickjacking-header.md
[BL-WEAK-AUTH]: ./Baseline/weak-authentication-method.md
[BL-JAVA-SERIALIZATION]: ./Baseline/java-serialization-object.md


[REF-OWASP-API-A7]: ./OWASP-API-10/A7-Security-Misconfiguration
[REF-ERROR-DISCLOSURE]: https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_for_Error_Code 
[REF-HSTS]: https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html


# Suboptimal Anti-clickjacking Headers
![Suboptimal Anti-clickjacking Headers](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returned a response with suboptimal anti-clickjacking headers.

The following distinct issues are covered under this category:

### 1. Missing Anti-clickjacking Header

#### Summary
The response does not include either a Content-Security-Policy header with ‘frame-ancestors’ directive or a X-Frame-Options header to protect against ‘ClickJacking’ attacks.

#### Solution
Modern Web browsers support the Content-Security-Policy and X-Frame-Options HTTP headers. Ensure one of them is set on all responses returned by your API. 

[OWASP](https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Headers_Cheat_Sheet.html#x-frame-options) recommends that API responses set the 'X-Frame-Options' header to 'DENY'.

### 2. Multiple X-Frame-Options Header Entries In Response

#### Summary
Multiple X-Frame-Options (XFO) headers were found in the response. A response with multiple XFO header entries may not be predictably processed by all user-agents.

#### Solution
Ensure only a single X-Frame-Options header is present in the response.

### 3. X-Frame-Options Setting Malformed

#### Summary
An X-Frame-Options header was present in the response but the value was not correctly set.

#### Solution
Ensure a valid setting is used on all responses returned by your API server. [OWASP](https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Headers_Cheat_Sheet.html#x-frame-options) recommends that API responses set the 'X-Frame-Options' header to 'DENY'.


## References
- [What is Clickjacking?](https://en.wikipedia.org/wiki/Clickjacking)
- [Testing for Clickjacking](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/11-Client-side_Testing/09-Testing_for_Clickjacking)
- [X-Frame-Options Header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options)
- [OWASP API TOP-10 A7](https://owasp.org/www-project-api-security/)  
- [CWE-1021](https://cwe.mitre.org/data/definitions/1021.html)


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for suboptimal/missing 'X-Frame-Options' headers.

### What is the solution?
Please refer to the solutions for the specific issues listed above: [Missing Anti-clickjacking Header](#1-missing-anti-clickjacking-header), [Multiple X-Frame-Options Header Entries In Response](#2-multiple-x-frame-options-header-entries-in-response), [X-Frame-Options Setting Malformed](#3-x-frame-options-setting-malformed).





# Application Error Disclosure
![Application Error Disclosure](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returns an error/warning message that may disclose sensitive information like the location of the (code) file that produced the unhandled exception. This information can be used to launch further attacks against the API.

For example, a `500 exception` response from the API/server looks like the example below.

```
HTTP/1.1 500 Internal Server Error
Date: Sat, 04 Nov 2006 15:26:48 GMT
Server: Python Flask
Content-Type: text/plain
...
INFO:root:General exception noted.
Traceback (most recent call last):
  File "C:\Test\test.py", line 8, in <module>
    myfunction()
NameError: name 'myfunction' is not defined
...
```

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
- [Testing for Improper Error Handling](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_For_Improper_Error_Handling)


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for information disclosure as shown in the example above.

### What is the solution?
Review the source code of this API endpoint. Implement custom error pages. Consider implementing a mechanism to provide a unique error reference/identifier to the API client, while logging the details on the API server side and not exposing them to the user.



# Missing 'Content-Type' Header
![Missing Content-Type Header](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returned a response without the Content-Type header being set.

API responses are typically of type 'application/json'. 

## References
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
- [Setting JSON Content Type In Spring MVC](https://www.baeldung.com/spring-mvc-set-json-content-type)
- [Web API Request/Response Data Formats](https://www.tutorialsteacher.com/webapi/request-response-data-formats-in-web-api)
- [CWE-345](https://cwe.mitre.org/data/definitions/345.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the missing Content-Type header.

### What is the solution?
Ensure each API endpoint is setting the specific and appropriate Content-Type value for the content being delivered.





# Cookie Set Without HttpOnly Flag
![Cookie Set Without HttpOnly Flag](../assets/baseline/baseline-vuln.svg)

## What is it?
A cookie has been set without the HttpOnly flag, which means that the cookie can be accessed by JavaScript.

If a malicious script can be run on this page then the cookie will be accessible and can be transmitted to another site. If this is a session cookie then session hijacking may be possible.

## References
- [CWE-1004](https://cwe.mitre.org/data/definitions/1004.html)
- [Testing for Cookies](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the 'Set-Cookie' header without the 'HttpOnly' flag.

### What is the solution?
Ensure that the HttpOnly flag is set for all cookies.





# Cookie Poisoning Via Query/Body Parameters
![Cookie Poisoning](../assets/baseline/baseline-vuln.svg)

## What is it?
Cookie Poisoning is a vulnerability caused when client provided parameters (query, and body parameters) are used by the API server to set cookie values.

For example, Bob is using an online shopping website, but is unable to afford the final checkout price of $100. Upon viewing all the cookies contained within his browser, Bob realizes that there is a cookie with a key named `checkout_price` which was being sent to the server for each transaction that was made.

He notices that the value of the `checkout_price` cookie is being set by a URL query parameter named `transaction_total`, in the `POST /transact?transaction_total={dollar_amount}` API call.

Bob decides to manipulate the `checkout_price` cookie, by calling the API with `POST /transact?transaction_total=-100`.
This results in his final checkout price of $0.00/.


## References
- [Cookie Poisoning](https://cs.brown.edu/courses/csci1660/wiki/attacks/Cookie-Poisoning/)
- [API A8 - Injection](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa8-injection.md)  
- [CWE-20](https://cwe.mitre.org/data/definitions/20.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints that allow cookie names/values to be controlled by user input, and when the **Baseline** security category is enabled in test plans.

### How does it work?
User input provided for HTTP query/body parameters are compared to the `Set-Coookie` values returned by the API endpoint. A potential vulnerability is raised, if either the cookie name or value matches the user supplied input, 

### What is the solution?
Do not allow user input to control cookie names and values.





# Cookie Without Secure Flag
![Cookie Without Secure Flag](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server is setting a cookie without the secure flag, which means that the cookie can be accessed via unencrypted connections.


## References
- [CWE-614](https://cwe.mitre.org/data/definitions/614.html)
- [Testing for Cookies](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the 'Set-Cookie' header without the 'Secure' flag.

### What is the solution?
Whenever a cookie contains sensitive information or is a session token, then it should always be passed using an encrypted channel. Ensure that the secure flag is set for cookies containing such sensitive information.





# Cross-Domain (CORS) Misconfiguration (Passive)
![Cross-Domain Misconfiguration (Passive)](../assets/baseline/baseline-vuln.svg)

## What is it?
The API is misconfigured with a sub optimal and/or overly permissive Cross-Origin Resource Sharing (CORS) policy.

Prior to HTML5, Web browsers enforced the Same Origin Policy which ensures that in order for JavaScript to access the contents of a Web page, both the JavaScript and the Web page must originate from the same domain. Without the Same Origin Policy, a malicious website could serve up JavaScript that loads sensitive information from other websites using a client's credentials, culls through it, and communicates it back to the attacker.

HTML5 makes it possible for JavaScript to access data across domains if a new HTTP header called `Access-Control-Allow-Origin` is defined. With this header, an API server defines which other domains are allowed to access its domain using cross-origin requests. 

A sub optimal and/or overly permissive CORS policy can can lead to spoofing, data theft, relay, and other attacks.

## References
- [Deep Dive Into CORS](https://ieftimov.com/posts/deep-dive-cors-history-how-it-works-best-practices/)
- [CORS Misconfiguration](https://0xn3va.gitbook.io/cheat-sheets/web-application/cors-misconfiguration)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md) 
- [CWE-264](https://cwe.mitre.org/data/definitions/264.html)


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the sub optimal configuration of CORS policy, based on the values of 'Access-Control-Allow-Origin', 'Access-Control-Allow-Credentials', and 'Access-Control-Allow-Methods' HTTP response headers.

### What is the solution?
Configure the 'Access-Control-Allow-Origin' HTTP header to a more restrictive set of domains, or remove all CORS headers entirely, to allow the web browser to enforce the Same Origin Policy (SOP) in a more restrictive manner. Follow best practices outlined [here](https://ieftimov.com/posts/deep-dive-cors-history-how-it-works-best-practices/#some-best-practices).





# Hash Disclosure In Response
![Hash Disclosure In Response](../assets/baseline/baseline-vuln.svg)

## What is it?
The response contains one or more hash values that could represent *secrets* and/or *passwords*.

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [Examples of Hashed Secrets](https://openwall.info/wiki/john/sample-hashes) 


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses from the API server are analyzed for the presence of common hash values (MD5 Crypt, SHA-256 Crypt, SHA-512, SHA-384, Mac OSX salted SHA-1, NTLM, BCrypt, Kerberos AFS DES, OpenBSD Blowfish, etc), that could potentially represent secrets and/or passwords.

### What is the solution?
Verify if hashes present in the response pertain to secrets. If secrets are being sent as hashes, ensure it is justified by a legitimate business requirement.





# Information Leak Via 'Server' HTTP Response Header
![Server Header Info Leak](../assets/baseline/baseline-vuln.svg)

## What is it?
The API/server is leaking information via the “Server” HTTP response headers. Access to such information may facilitate attackers identifying other frameworks/components your API is reliant upon and the vulnerabilities such components may be subject to.

Below is an example where the type of the API server, and the framework version is revealed by the 'Server' header.

```
HTTP/1.1 200 OK
Date: Thu, 12 Jun 2014 14:15:01 GMT
Server: Apache/2.2.21 (Win32) PHP/5.4.7
Content-Length:226
Connection: close
{
...
}
```

Revealing the type, version, and module information of the API server, enables attackers to try exploiting the server for known/unpatched vulnerabilities.

## References
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
- [Don't Reveal Too Much Information](https://www.troyhunt.com/shhh-dont-let-your-response-headers/)
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for information disclosure as shown in the example above.

### What is the solution?
Ensure that your API/server, load balancer, etc. is configured to suppress version info in 'Server' headers.





# In Page Banner Information Leak
![Page Banner Info Leak](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returned a version banner string in the response content. Such information leaks may allow attackers to further target specific issues impacting the product and version in use.

For example, a common 404 response from the API/server looks like the example below.

```
HTTP/1.1 404 Not Found
Date: Sat, 04 Nov 2006 15:26:48 GMT
Server: Apache/2.2.3 (Unix) mod_ssl/2.2.3 OpenSSL/0.9.7g
Content-Length: 310
Connection: close
Content-Type: text/html; charset=iso-8859-1
...
<title>404 Not Found</title>
...
<address>Apache/2.2.3 (Unix) mod_ssl/2.2.3 OpenSSL/0.9.7g at <host target> Port 80</address>
...
```

Revealing the type, version, and module information of the API server, enables attackers to try exploiting the server for known/unpatched vulnerabilities.

## References
[OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
[Testing for Error Handling]( https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for information disclosure as shown in the example above.

### What is the solution?
Configure the API server to prevent such information leaks. For example: Under Tomcat this is done via the 'server' directive and implementation of custom error pages. Under Apache this is done via the 'ServerSignature' and 'ServerTokens' directives.





# Information Disclosure - Debug Error Messages
![Debug Error Messages](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returns a response that contains standard error messages returned by platforms such as ASP.NET, and Web-servers such as IIS and Apache. 

Revealing standard error/debug information, allows attackers to deduce the type of the API server. This in turn enables attackers to try exploiting the server for known/unpatched vulnerabilities.

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [Testing for Improper Error Handling](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_For_Improper_Error_Handling)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the presence of standard error/debug messages that reveal the type of the API server.

### What is the solution?
Disable debugging messages before promoting to production.





# Information Disclosure - Sensitive Information in HTTP Referrer Header
![Information Disclosure - Referrer Header](../assets/baseline/baseline-vuln.svg)

## What is it?
The HTTP 'Referrer' header may have leaked a potentially sensitive parameter to another domain. This can violate PCI and most organizational compliance policies.  

Examples of sensitive information in the 'Referrer' header are parameters with keys like 'user', 'username', 'pass', 'password', 'pwd', 'token', 'ticket', 'session' 'jsessionid', 'sessionid', etc.

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Requests sent to the API server are analyzed for the presence of sensitive information in the 'Referrer' header.

### What is the solution?
Do not pass sensitive information in URIs that are utilized as a referrer.





# Information Disclosure - Sensitive Information in URL
![Information Disclosure - Sensitive Information in URL](../assets/baseline/baseline-vuln.svg)

## What is it?
The request to the API endpoint appeared to contain sensitive information leaked in the URL. This can violate PCI and most organizational compliance policies. 

Examples of sensitive information in URLs are query parameters with keys like 'user', 'username', 'pass', 'password', 'pwd', 'token', 'ticket', 'session' 'jsessionid', 'sessionid', etc.

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Requests sent to the API server are analyzed for the presence of sensitive information in the URL.

### What is the solution?
Do not pass sensitive information in URIs.





# Java Serialization Detected
![Java Serialization Detected](../assets/baseline/baseline-vuln.svg)

## What is it?
Java Serialization seems to be in use. If the serialized data is not correctly validated, an attacker can send a specially crafted object that leads to dangerous “Remote Code Execution”. A magic sequence identifying JSO has been detected (Base64: rO0AB, Raw: 0xac, 0xed, 0x00, 0x05).

## References
- [CWE-502](https://cwe.mitre.org/data/definitions/502.html)
- [Oracle Advisory On Deserialization](https://www.oracle.com/java/technologies/javase/seccodeguide.html#8)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
API requests and responses are analyzed for the presence of Java Serialization Objects (based on magic sequences that indicate the presence of JSOs).

### What is the solution?
Deserialization of untrusted data is inherently dangerous and should be avoided. APIs should always validate the serialized data thoroughly before consumption.





# Open/Unrestricted URL Redirect Via URL Query Parameter
![Open URL Redirect](../assets/baseline/baseline-vuln.svg)

## What is it?
An open redirect vulnerability occurs when an API endpoint allows a user to control a redirect or forward to another URL. If the API does not validate untrusted user input, an attacker could supply a URL that redirects an unsuspecting victim from a legitimate domain to an attacker’s phishing site.

Attackers exploit open redirects to add credibility to their phishing attacks. Most users see the legitimate, trusted domain, but do not notice the redirection to the phishing site.

Although this vulnerability doesn’t always directly impact the legitimate application, the company's reputation can be negatively impacted.

For example, `www.myapi.com/login?redirect_url=/profile` is an endpoint that uses a redirect query parameter to redirect the browser to the user's profile page, after a successful login.

Attacker could you use this capability to lure users to a phishing page that closely resembles the look & feel of `www.myapi.com`, and then manipulate the user to provide credentials etc., leading to a full account takeover.

## References
- [What is Open Redirect?](https://learn.snyk.io/lessons/open-redirect/javascript/)  
- [Testing for Client-side URL Redirect](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect)
- [CWE-601](https://cwe.mitre.org/data/definitions/601.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints that accept URLs as query parameters, and when the **Baseline** security category is enabled in test plans.

### How does it work?
A request is made to the API endpoint with a *bogus* URL in the query parameter, whose domain does not match the API's domain. If the API endpoint is deemed vulnerable to `Open Redirects`, if it returns a redirect response (301, 302, 307 HTTP response codes) directed to the bogus URL. 

### What is the solution?
To avoid the open redirect vulnerability, query parameters containing URLs must be validated (by the API endpoint) before sending 302 HTTP code (redirect) to the client. Implement safe redirect functionality that only redirects to relative URI's, or a list of trusted domains.





# PII Disclosure In Response
![PII Disclosure In Response](../assets/baseline/baseline-vuln.svg)

## What is it?
The response contains Personally Identifiable Information (PII), such as credit card numbers, social security numbers (SSN), and similar sensitive data.

## References
- [CWE-359](https://cwe.mitre.org/data/definitions/359.html)
- [OWASP Insecure Design](https://owasp.org/Top10/A04_2021-Insecure_Design/)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses from the API server are analyzed for the presence of sensitive information (PII).

### What is the solution?
Verify if PII present in the response is justified by a legitimate business requirement. Ensure that the amount of PII being disclosed in the response is limited to serve the specific use case of the API endpoint.





# Private IP Disclosure In Response
![Private IP Disclosure](../assets/baseline/baseline-vuln.svg)

## What is it?
A private IP (such as 10.x.x.x, 172.x.x.x, 192.168.x.x) or an Amazon EC2 private hostname (for example, ip-10-0-56-78) has been found in the HTTP response body. This information might be helpful for further attacks targeting internal systems.

## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [Internal IP Disclosure - Hacker News](https://thehackernews.com/2012/12/google-paypal-facebook-internal-ip.html)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses from the API server are analyzed for the presence of private IP information.

### What is the solution?
Verify if private IPs present in the response are justified by a legitimate business requirement. Remove unnecessary private IP information present in responses.





# Sub Optimal Cache Control Directives
![Sub Optimal Cache Control Directives](../assets/baseline/baseline-vuln.svg)

## What is it?
The cache-control header has not been set properly or is missing, allowing the browser and proxies to cache content. For static assets like css, js, or image files this might be intended, however, the resources should be reviewed to ensure that no sensitive content will be cached.

## References
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
- [Content Caching](https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html#web-content-caching)    
- [Cache Control Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control)  
- [CWE-525](https://cwe.mitre.org/data/definitions/525.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

## How does it work?
Responses sent by the API server are analyzed for sub optimal or missing cache control headers.

### What is the solution?
For secure content, ensure the cache-control HTTP header is set with 'no-cache, no-store, must-revalidate'. If an asset should be cached consider setting the directives 'public, max-age, immutable'.





# Content Retrieved from Cache
![Content Retrieved from Cache](../assets/baseline/baseline-vuln.svg)

## What is it?
The content was retrieved from a shared cache such as a CDN or Proxy Server, due the presence of HTTP response headers such as 'X-Cache', 'X-Cache-Lookup', 'Age', etc. 

If the response contains sensitive data (PII, PSI, PHI, etc.), this may result in sensitive information being leaked. In some cases, this may even result in a user gaining complete control of the session of another user, depending on the configuration of the caching components in use. 

## References
- [Testing for Browser Cache Weaknesses](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses)     
- [CWE-525](https://cwe.mitre.org/data/definitions/525.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

## How does it work?
Responses sent by the API server are analyzed for the presence of HTTP headers (e.g. 'X-Cache', 'X-Cache-Lookup', 'Age', etc.) that indicate that the response content in being served from a CDN or Proxy-Cache. 

### What is the solution?
Validate that the response does not contain sensitive data (PII, PSI, PHI, etc.). If it does, consider the use of the following HTTP response headers, to limit, or prevent the content being stored and retrieved from the cache by another user:
- Cache-Control: no-cache, no-store, must-revalidate, private
- Pragma: no-cache Expires: 0

The above configuration directs both HTTP 1.0 and HTTP 1.1 compliant caching servers to not store the response, and to not retrieve the response (without validation) from the cache, in response to a similar request.





# Information Leak Via 'X-Powered-By' HTTP Response Header
![X-Powered-By Info Leak](../assets/baseline/baseline-vuln.svg)

## What is it?
The API/server is leaking information via one or more “X-Powered-By” HTTP response headers. Access to such information may facilitate attackers identifying other frameworks/components your API is reliant upon and the vulnerabilities such components may be subject to.

Below is an example where the type of the API server, and the framework version is revealed by the 'X-Powered-By' header.

```
HTTP/1.1 200 OK
Date: Sat, 04 Nov 2006 15:26:48 GMT
Content-Length: 310
Content-Type: application/json
Server: Microsoft-IIS/7.5
X-Powered-By: ASP.NET; X-AspNet-Version=4.0.30319
{
...
}
```

Revealing the type, version, and module information of the API server, enables attackers to try exploiting the server for known/unpatched vulnerabilities.

## References
[OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
[Don't Reveal Too Much Information](https://www.troyhunt.com/shhh-dont-let-your-response-headers/)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for information disclosure as shown in the example above.

### What is the solution?
Ensure that your API/server, load balancer, etc. is configured to suppress 'X-Powered-By' headers.





# Session ID in URL (Via URL Rewrite)
![Session ID in URL Rewrite](../assets/baseline/baseline-vuln.svg)

## What is it?
Many users disable cookies as a security precaution in their browsers. In such cases, APIs that use cookies as the authentication mechanism, resort to embedding the session ID as a query parameter in the URL.

This is done by rewriting the original API URL with a new URL that has the session ID as a query parameter.

This is insecure as URLs can be cached, logged, and are generally visible in the browser. So any URL that has a secret (session ID) is likely to leak the secret, and lead to account takeover, etc.


## References
- [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
- [Testing for Exposed Session Variables](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for redirects to rewritten URLs that have session IDs embedded as query parameters.

### What is the solution?
Use bearer token based authentication for APIs. Alternatively use cookies instead of session IDs in the URL. 





# Missing Strict-Transport-Security Header
![Missing HSTS](../assets/baseline/baseline-vuln.svg)

## What is it?
HTTP Strict Transport Security (HSTS) is a web security policy mechanism whereby a API/server declares that complying user agents (such as a web browser) are to interact with it using only secure HTTPS connections (i.e. HTTP layered over TLS/SSL).

HSTS is an IETF standards track protocol and is specified in [RFC 6797](https://www.rfc-editor.org/rfc/rfc6797).

## References
[OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)  
[HSTS Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for missing HSTS header.

### What is the solution?
Ensure that your API/server, load balancer, etc. is configured to enforce Strict-Transport-Security.





# Weak Authentication Method
![Weak Authentication Method](../assets/baseline/baseline-vuln.svg)

## What is it?
The API is using HTTP basic or digest authentication over an unsecured (plain text) connection. The credentials can be read and then reused by someone with access to the network.

## References
- [Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md) 
- [CWE-326](https://cwe.mitre.org/data/definitions/326.html)


## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Requests sent for the API are analyzed for the presence of HTTP basic or digest authentication over plain text (non TLS) connections.

### What is the solution?
Protect the connection using HTTPS or use a stronger authentication mechanism such as `Bearer` authentication.





# Missing X-Content-Type-Options Header
![Missing X-Content-Type-Options Header](../assets/baseline/baseline-vuln.svg)

## What is it?
The API endpoint or server returned a response without the X-Content-Type-Options header being set correctly.

The Anti-MIME-Sniffing header X-Content-Type-Options was not set to ’nosniff’. This allows older versions of Internet Explorer and Chrome to perform MIME-sniffing on the response body, potentially causing the response body to be interpreted and displayed as a content type other than the declared content type. Current (early 2014) and legacy versions of Firefox will use the declared content type (if one is set), rather than performing MIME-sniffing.

## References
- [OWASP API TOP-10 A7](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa7-security-misconfiguration.md)
- [What does this header do?](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options)
- [OWASP Security Headers](https://owasp.org/www-community/Security_Headers)
- [CWE-693](https://cwe.mitre.org/data/definitions/693.html)

## Test case FAQs
### When is this test case applicable?
This is applicable for all API endpoints when the **Baseline** security category is enabled in test plans.

### How does it work?
Responses sent by the API server are analyzed for the missing or incorrectly set X-Content-Type-Options header.

### What is the solution?
Ensure that the API server sets the Content-Type header appropriately, and that it sets the X-Content-Type-Options header to 'nosniff' for all responses. If possible, ensure that the end user uses a standards-compliant and modern web browser that does not perform MIME-sniffing at all, or that can be directed by the API server to not perform MIME-sniffing.




---
sidebar_position: 2
---

# API Schema / Contract Non-Conformance
![Schema Conformance](../assets/Miscellaneous/schema-conformance.svg)

## What is it?
API endpoints have a defined schema (aka contract), that is often described in [**OpenAPI Specification**][1] format. The contract allows clients of the API endpoint to interact with it, without knowledge of the underlying implementation. Schema / Contract conformance testing ensures that said contract matches the actual implementation of the API endpoint. [Contract testing][contract-driven-testing] is a critical tool to detect breaking changes before they are deployed to production!

## References
[API Contract Testing](https://docs.pact.io/)  
[API Schema Validation](https://github.com/schemathesis/schemathesis/blob/master/README.rst)  
[Contract Driven Testing][contract-driven-testing]

## How does it work?
The API endpoints are exercised by sending specially crafted (fuzzed) payloads that violate the defined schema on purpose. If the API implementation is robust, the API will reject the request or gracefully fail.

For example, when dealing with string fields, if the defined maximum string length is 50 chars, the crafted payload could have a string length that exceeds 50 chars. If an integer field specifies positive ranges, the crafted payload could have negative values to test for proper input validation.

These tests will work on both authenticated and unauthenticated API endpoints.

## Test case FAQs
### What are the type of schema conformance tests?

#### Status Code Conformance Test
    This test checks to see if the API implementation returns any undocumented response status codes.

Please refer to [CWE-394: Unexpected Status Code or Return Value][CWE-394], for additional information.

#### Response Headers Schema Conformance Test
    This test checks to see if the API implementation returns all the `required` response headers documented in the schema.

Please refer to [CWE-838: Inappropriate Encoding for Output Context][CWE-838], for additional information.

#### Content Type Schema Conformance Test
    This test checks to see if the API implementation returns the appropriate `content types` documented in the schema.

Please refer to [CWE-838: Inappropriate Encoding for Output Context][CWE-838], for additional information.

#### Response Schema Conformance Test
    This test checks to see if the response body returned by API implementation conforms to the JSON structure documented in the schema.

Please refer to [CWE-838: Inappropriate Encoding for Output Context][CWE-838], for additional information.

#### Unexpected Server Error Schema Conformance Test
    This test checks to see if `5XX Server Error` response codes are returned by the API implementation. `5XX` errors are unexpected errors.

Please refer to [CWE-600: Uncaught Exception in Servlet][CWE:600], for additional information.


### What is the solution?
* Document all expected response codes in the API schema.
* Only document all the `required` headers in the response section of the schema.
* Document all expected `content-type` that is returned in the response section of the schema.
* Document (in the schema) all expected JSON structures that are returned by the API implementation in the response body.
* In case of `Unexpected Server Error`, the test case summary will indicate the specified `input parameter` value/ranges that caused the error. Use this hint to fix the implementation such that it either rejects the request or fails gracefully.

[1]: https://swagger.io/specification/
[contract-driven-testing]: https://www.ibm.com/garage/method/practices/code/contract-driven-testing/

[CWE-1215]: https://cwe.mitre.org/data/definitions/1215.html
[CWE:600]: https://cwe.mitre.org/data/definitions/600.html
[CWE-394]: https://cwe.mitre.org/data/definitions/394.html
[CWE-838]: https://cwe.mitre.org/data/definitions/838.html


---
sidebar_position: 1
---

# API A1 - Broken Object Level Authorization
![BOLA](../assets/API-Top-10/A1-BOLA.svg)

## What is it?
Attackers substitute the ID of their own resource in the API call with an ID of a resource belonging to another user. The lack of proper authorization checks allows attackers to access the specified resource.
This attack is also known as Horizontal Authorization Bypass, and [IDOR][IDOR-HO] (Insecure Direct Object Reference).

In the above example Troy (who is an authenticated user) is able to access Scott's receipt! This is a serious vulnerability, that is a result of improper authorization checks at the `GET /receipts/{receipt_id}` API endpoint.

## References
[OWASP API TOP-10 A1](https://owasp.org/www-project-api-security/)  
[BOLA / IDOR in API Security Encyclopedia](https://apisecurity.io/encyclopedia/content/owasp/api1-broken-object-level-authorization)

## Test case FAQs
### When is this test case applicable?
* Only for API endpoints that require authentication.
* API endpoints that take one or more object/resource IDs as an input via query or path params.
* Requires the use of fixtures to provide valid object/resource IDs, that the test case can access using two different users who have the same privileges.
* Currently only for non state changing operations like `GET`. Coverage for state changing operations (POST, PUT, DELETE, etc.) will follow soon.

### How does it work?
1. Expects authentication credentials of two different users, `victim` and `attacker`, to be configured via the environment file.
2. Expects all other endpoint params (query or path params) to be configured via fixtures.
3. Sends a request using victim's credentials, and stores the response.
4. Sends the exact request from the previous step, but with the `attacker's` credentials. 
5. The two responses from the above two requests are compared
6. If the **comparison is a match**, this is raised as an BOLA/IDOR vulnerability

### What is the solution?
* Implement granular authorization checks, that tests for proper ownership of the requested resource(s) by the user making the request.
* Authorize every request made by the user.
* Do not rely on resource IDs that the client sends. Use IDs stored in the session object instead.
* Use random resource IDs that cannot be guessed ([UUIDs](https://en.wikipedia.org/wiki/Universally_unique_identifier)).

## False positives
The test case will generate a false positive, if the endpoint requires authentication and is designed to serve same object/resource for two different users. 

This could happen with with endpoints that server blog posts etc. In such cases you can disable the test case from executing, in the test plan.


[IDOR-HO]: https://www.hackerone.com/company-news/rise-idor


---
sidebar_position: 10
---

# API A10 - Insufficient Logging & Monitoring
![POOR-LOGGING](../assets/API-Top-10/A10-Insufficient-Logging-Monitoring.svg)

## What is it?
Observability into who is using the API and how they are using it is the foundation of any security program.

API observability provides audit and forensics capabilities among other benefits, like performance/SLA monitoring.

Lack of logging with sufficient detail, severely impairs securing APIs.

## What are specific examples?
The access keys of an administrative API were leaked on a public repository. The repository owner was notified by email about the potential leak, but took more than 48 hours to act upon the incident.

Due to insufficient logging, the company was not able to assess what data was potentially accessed by specific malicious actors.

## References
[OWASP API TOP-10 A10](https://owasp.org/www-project-api-security/)  
[Logging - Cheat Sheet](https://github.com/OWASP/ASVS/blob/master/4.0/en/0x15-V7-Error-Logging.md)


## What is the solution?
Use Levo's no-code, and zero-config eBPF sensor, to automatically enable deep logging for all APIs and services. 

Levo captures the full request/response of APIs, without having to install SDKs, or sidecar proxies.


---
sidebar_position: 2
---

# API A2 - Broken Authentication
![BOLA](../assets/API-Top-10/A2-BUA.svg)

## What is it?
Authentication mechanisms are often implemented incorrectly, allowing attackers to compromise authentication tokens, or to exploit implementation flaws to assume other user’s identities.

Compromising a system’s ability to identify the client/user, compromises API security overall.

## What are specific examples?
 - Weak authentication that does not follow industry best practices.
 - Weak API keys that are not rotated.
 - Passwords that are weak, plain text, encrypted but poorly hashed, shared, or default passwords.
 - Authentication susceptible to brute force attacks and credential stuffing.
 - Credentials and keys included in URLs.
 - Lack of access token validation (including JWT validation).
 - Unsigned or weakly signed non-expiring JWTs.
 - Unprotected APIs that are considered “internal”.

## References
[OWASP API TOP-10 A2](https://owasp.org/www-project-api-security/)  
[Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)

## Test case FAQs

### When is this test case applicable?
* Only for API endpoints that require authentication.

### How does it work?
The endpoint is subjected to a battery of authentication related tests, that probe for common weaknesses.


### What is the solution?
- Maintain a clear inventory of your API endpoints.
- Clearly itemize APIs that require authentication and those that don't.
- Use industry standard libraries for authentication, token generation, and password storage. Do not build your own.
- Use multi-factor authentication (MFA).
- Use short-lived access tokens.
- Use stricter rate-limiting for authentication, and implement lockout policies and weak password checks.
- Continuously validate that your authentication mechanisms are working in pre-production and production.





---
sidebar_position: 3
---

# API A3 - Excessive Data Exposure
![DATA-EXPOSURE](../assets/API-Top-10/A3-Excessive-Data-Exposure.svg)

## What is it?
An API is only supposed to return the required data to the front-end clients. Sometimes developers will make a mistake or implement HTTP parameter auto-binding that results in all data being returned to the client. 

This results in excessive data exposure that can be easily mined and exploited by attackers.

## What are specific examples?
    
- Scenario 1

    A mobile team uses the /api/articles/{articleId}/comments/{commentId} endpoint in the articles view to render comments metadata.

    Sniffing the mobile application traffic, an attacker finds out that other sensitive data related to comment’s author is also returned.
    
    The endpoint implementation uses a generic toJSON() method on the User model, which contains PII, to serialize the object.

- Scenario 2
    
    An IOT-based surveillance system allows administrators to create users with different permissions.
    
    An admin created a user account for a new security guard that should only have access to specific buildings on the site. 
    
    Once the security guard uses his mobile app, an API call is triggered to: /api/sites/111/cameras in order to receive data about the available cameras and show them on the dashboard.
    
    The response contains a list with details about cameras in the following format: {"id":"xxx","live_access_token":"xxxx-bbbbb","building_id":"yyy"}. 
    
    While the client GUI shows only cameras which the security guard should have access to, the actual API response contains a full list of all the cameras in the site.

## References
[OWASP API TOP-10 A3](https://owasp.org/www-project-api-security/)  
[Secure Coding Handbook](https://vladtoie.gitbook.io/secure-coding/api/excessive-data-exposure)

## Test case FAQs

### When is this test case applicable?
* Applicable to all API endpoints that return JSON data.

### How does it work?
- The response returned from the endpoint is screened for classified/sensitive data using trained machine learning model.
- The density of sensitive data (PII/PSI) present in the response is computed, and the response is assigned an appropriate risk level.

### What is the solution?
- Never rely on the client-side to filter sensitive data; this should be done at the API level.
- Cherry-pick the specific properties of the response you want to return. Avoid using generic methods such as to_json() and to_string().
- Classify sensitive and personally identifiable information (PII) that your application works with. Review all API endpoints that return such information to see if these responses pose a security issue.
- Implement a schema-based response validation mechanism as an extra layer of security. As part of this mechanism define and enforce data returned by all API methods, including errors.




---
sidebar_position: 4
---

# API A4 - Lack of Resources and Rate Limits
![RATE-LIMITS](../assets/API-Top-10/A4-Rate-Limits.svg)

## What is it?
APIs need to restrict the size and/or the number of resources that can be requested by the client/user.

Lack of such controls lead to Denial of Service (DoS), degraded performance, and authentication flaws like brute force.

## What are specific examples?
 - Attackers overload the API by sending more requests than it can handle, causing degraded performance or complete Denial of Service.
 - The size of the requests or the size/value of certain fields in them, leads to degraded performance or complete Denial of Service. For example, API endpoints that accept an unrestricted page size, as a query parameter.
 - “Zip bombs”, archive files that have been designed so that unpacking them takes excessive amount of resources and overloads the API.

## References
[OWASP API TOP-10 A4](https://owasp.org/www-project-api-security/)  
[Rate Limiting - Best Practices](https://cloud.google.com/architecture/rate-limiting-strategies-techniques)

## Test case FAQs

### When is this test case applicable?
* Applicable to all API endpoints.

### How does it work?
- The endpoint is accessed at increasingly high frequencies to test for the absence of rate limit controls.
- Based on the structure of the endpoint, certain strategic fields (e.g. page key, limit key, etc.) are set to large values, attempting to cause degraded performance or complete Denial of Service.


### What is the solution?
- Define proper rate limiting for all endpoints by using industry standard frameworks.
- Limit payload sizes.
- Limit maximum values for strategic query fields like `page size`, `limit`, etc.
- Tailor the rate limiting to be match what API methods, clients, or addresses need or should be allowed to get.
- Add checks on compression ratios.
- Define limits for container resources.





---
sidebar_position: 5
---

# API A5 - Broken Function Level Authorization
![BFLA](../assets/API-Top-10/A5-BFLA.svg)

## What is it?
Authorization is the process where requests to access a particular resource should be granted or denied. Authorization determines which functionality and data the logged in user (or Principal) may access.

Vertical access control mechanisms restrict access to sensitive functions based on the types of users.

With vertical access controls, different types of users have access to different application functions. For example, an administrator might be able to modify or delete any user's account, while an ordinary user has no access to these actions.

`Broken Function Level Authorization` is a manifestation of suboptimal vertical access control rules.

## References
[OWASP API TOP-10 A5](https://owasp.org/www-project-api-security/)

[Vertical Authorization Abuse][vertical-priv-abuse]


## Test case FAQs

### When is this test case applicable?
Only for API endpoints that require authentication, and which have either a) role definitions, or b) [OIDC scope][scopes] definitions (scopes defined in JWT).

### How does it work?

#### Prerequisites
- Roles or scope sets are defined as part of the API catalog, via either [OIDC scope][scopes] definitions in the OpenAPI specification, or via the environment file.
- If using roles, the environment file should specify the which roles are allowed to access each API endpoint defined in the catalog
- For every role or scope set defined, authentication details for a corresponding user must be provided, via the environment file.
- Optional definition of fixtures that describe specific resources that belong to each user. Definition of these fixtures improves the coverage level of tests (deeper test coverage achieved with fixture data).
- Optional definition of other input parameters for the API endpoint, to be configured via fixtures (deeper test coverage achieved with fixture data).

#### Test sequence for roles
1. Each allowed role for an API endpoint gets a dedicated test case.
2. The API endpoint is first accessed with a user belonging to the allowed role. If this access fails, the test case execution is aborted as a failure.
3. For each disallowed role for the API endpoint under test, a user belonging to the disallowed role is used to access the API endpoint. If the any of the access attempts succeed, the test case results in a failure.
If none of the access attempts succeed, the test case results in a pass.

#### Test sequence for scopes
Scope based testing is coming soon.

### Success/Failure indications
The test case relies on the API endpoint's response status code to determine success or failure of the access attempt. Usually `403 Forbidden` or `401 Unauthorized` indicates access failure.
But in some cases the API might choose to return `404 Not Found` or other codes to indicate failure.

If the endpoint returns failure codes other than `403` or `401`, it might be hard to identify a real failure from a resource not found issue. For example, when the endpoint returns `404 Not Found`,
we cannot differentiate if this is due to lack of authorization or if the requested resource is actually not found.

If fixture definitions that clearly define valid resources (that belong to the users provided in the environment file), were provided, the test case can clearly distinguish between the condition mentioned
above.

### What is the solution?
- Deny all access by default.
- Only allow operations to users belonging to the appropriate role(s) or possessing the appropriate scope(s).


[vertical-priv-abuse]: https://en.wikipedia.org/wiki/Privilege_escalation#Vertical
[scopes]: https://openid.net/specs/openid-connect-basic-1_0.html#Scopes

---
sidebar_position: 6
---

# API A6 - Mass Assignment
![MASS-ASSIGN](../assets/API-Top-10/A6-Mass-Assignment.svg)

## What is it?
Modern software frameworks allow developers to automatically bind API request parameters into application code's variables or objects to reduce development effort.

Attackers can sometimes use this methodology to add new parameters that the developer never intended.

This can cause the unintended creation of new variables/objects and/or the modification of existing variables/objects in the application code.

The outcome of the above actions could be unintended privilege escalation or abuse of the underlying business logic of the API, which profits the attacker. 

This is called a `Mass Assignment` vulnerability.

### Alternative Names
Depending on the language/framework in question, this vulnerability can have several alternative names:

- Mass Assignment: Ruby on Rails, NodeJS.
- Autobinding: Spring MVC, ASP NET MVC.
- Object injection: PHP.

## What are specific examples?
In the diagram above, the attacker sends the same discount code multiple times as a JSON array, leading to a 100% discount, and paying $0 for his purchases.

This was clearly not the intent of the API developer. 

## References
[OWASP API TOP-10 A6](https://owasp.org/www-project-api-security/)  
[Mass Assignment - Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Mass_Assignment_Cheat_Sheet.html)

## Test case FAQs

### When is this test case applicable?
* Applicable to all API endpoints that accept query and/or body parameters.

### How does it work?
- For query and body parameters expected in the API endpoint's request, additional (extraneous) parameters are added iteratively, before making the request.
- Primitive, array, and dictionary JSON elements are subject to this treatment.
- If the API endpoint is robust, it should reject these malicious requests outright.
- Vulnerable API endpoints will serve a normal successful response, or a variant of the normal successful response, or fail in unexpected ways (exceptions, etc.)

### What is the solution?
- Do not automatically bind all incoming parameter data to internal variables/objects.
- Based on the business context of the API endpoint, explicitly define what incoming parameters should be automatically bound.
- If certain internal variables/objects of the API endpoint are readonly, annotate them as readonly in the framework's auto bind.
- Precisely define the schemas, types, and patterns you will accept in requests at design time and enforce them at runtime.





---
sidebar_position: 7
---

# API A7 - Security Misconfiguration
![MISCONFIG](../assets/API-Top-10/A7-Security-Misconfiguration.svg)

## What is it?
- Overly permissive access control settings in well know server frameworks.
- The latest security patches are missing, or the systems are out of date.
- Unnecessary features are enabled (e.g., HTTP methods).
- Transport Layer Security (TLS) is missing.
- Security directives are not sent to clients (e.g. common security headers).
- A Cross-Origin Resource Sharing (CORS) policy is missing or improperly set.
- Error messages include stack traces, or other sensitive information is exposed.

## References
[OWASP API TOP-10 A7](https://owasp.org/www-project-api-security/)  


## Test case FAQs

### When is this test case applicable?
* Applicable to all API endpoints.

### How does it work?
The test case does active probing for common API misconfigurations similar to a how a code linter checks for common flaws.

### What is the solution?
- Ensure all APIs are only accessible via TLS.
- Disable API operations (HTTP methods) that are not required to satisfy business functionality.
- Configure CORS headers in a secure manner.
- Make appropriate use of all recommended security headers.
- Do not expose stack traces in error messages. Customize error messages to prevent information leaking via the use of default error messages.
- Do not use default settings and admin credentials for popular server frameworks.
- Regularly patch/update all software components.
- Adopt a tool that provides continuous security validation on your APIs.





---
sidebar_position: 8
---

# API A8 - Injection
![A8](../assets/API-Top-10/A8-Injection.svg)

## What is it?
Attackers construct API calls that include SQL, NoSQL, OS, or other commands, that the API or the backend behind it blindly executes. Essentially this vulnerability arises from passing unsanitized user input directly to database queries or OS command interpreters.

## What are the common types of injection for APIs?
- [SQL Injection][SQLi]
- [NoSQL Injection][NoSQLi]
- [OS Command Injection][CMDi]

## References
- [OWASP API TOP-10 A8](https://owasp.org/www-project-api-security/)
- [Command Injection - CWE 77](https://cwe.mitre.org/data/definitions/77.html)
- [SQL Injection - CWE 89](https://cwe.mitre.org/data/definitions/89.html)
- [NoSQL Injection - CAPEC 676](https://capec.mitre.org/data/definitions/676.html)


## Test case FAQs

### When is this test case applicable?
Applies to all API endpoints that consume user supplied input

### How does it work?
The input parameter(s) within the API endpoint, are injected with malicious data (injection strings). The malicious data tries to trick the API's backend query interpreter, to execute unauthorized commands, which cause leakage of sensitive data, or even a complete denial of service.

### What is the solution?
- Strictly define all API input data, such as schemas, types, and string patterns, and enforce them at runtime.
- Validate, filter, and sanitize all incoming data.
- Define, limit, and enforce API outputs to prevent data leaks.


[SQLi]: https://docs.microsoft.com/en-us/sql/relational-databases/security/sql-injection?view=sql-server-ver15
[NoSQLi]: https://nullsweep.com/a-nosql-injection-primer-with-mongo/
[CMDi]: https://owasp.org/www-community/attacks/Command_Injection

---
sidebar_position: 9
---

# API A9 - Improper Asset Management
![ASSET-MGMT](../assets/API-Top-10/A9-Improper-Asset-Management.svg)

## What is it?
Attackers find non-production, and/or older versions of the API (for example, staging, testing, beta, or earlier versions) that are not as well protected as the production API, and use those to launch their attacks.

## What are specific examples?
    
In the diagram above v2 of `/api/v2/admin/userlist` only allows properly authenticated `admins` to access the API endpoint.

The `v1` version does not check if the user calling the API endpoint is actually an `admin`, allowing any user to retrieve details on all users in the application.

This is a serious privilege escalation vulnerability as details of all users including sensitive data about them is exposed.

## References
[OWASP API TOP-10 A9](https://owasp.org/www-project-api-security/)  
[Improper Asset Management - Cheat Sheet](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa9-improper-assets-management.md)

## Test case FAQs

### When is this test case applicable?
* Applicable to all API endpoints.

### How does it work?
- For the API endpoint under test, multiple version routes (/v1/, /v2/), are automatically probed and accessed without the proper authentication credentials. The test case will raise appropriate alerts if these routes respond positively.

- Similarly the presence of an admin route (/admin/) is probed, and accessed without the proper authentication credentials. Appropriate alerts are raised, if the route responds positively.

- Route word lists are all used to probe for the presence of commonly used administrative routes. Appropriate alerts are raised, if the route responds positively.

### What is the solution?
- Keep an up-to-date inventory all API hosts.
- Limit access to API endpoints that should not be public.
- Limit access to production data, and segregate access to production and non-production data.
- Properly retire old versions of APIs or backport security fixes to them.
- Implement strict authentication, redirects, and CORS checks for all API endpoints.



# Web A10 - Server Side Request Forgery
![SSRF](../assets/Web-Top-10/A10-SSRF.svg)

## What is it?
Server-side request forgery (also known as SSRF) is a security vulnerability that allows an attacker to induce the server-side application to make HTTP requests to an arbitrary domain of the attacker's choosing.

In a typical SSRF attack, the attacker might cause the server to make a connection to internal-only services within the organization's infrastructure. In other cases, they may be able to force the server to connect to arbitrary external systems, potentially leaking sensitive data such as authorization credentials.

## References
[MITRE CWE-918](https://cwe.mitre.org/data/definitions/918.html)  
[OWASP Top 10 - A10](https://owasp.org/Top10/A10_2021-Server-Side_Request_Forgery_%28SSRF%29/)   
[OWASP - SSRF Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html)

## Test case FAQs
### When is this test case applicable?
* API endpoints that take client-supplied input specifying URLs, files, or other API endpoints


### How does it work?
1. The parameter(s) within the API endpoint, which take URLs (or files, or other API endpoints) as input, are injected with malicious data. The malicious data is typically a URL, that references an internal resource that should not be exposed externally (e.g. AWS instance meta data).
2. If the API endpoint returns the internal resource, the API is deemed vulnerable to SSRF.

### What is the solution?
* Sanitize all client-supplied input by creating a list of trusted URLs (lists of hosts or a regex). Use a whitelist approach to limit what URLs (or files, or other API endpoints) can be specified as inputs.
* Restrict supported protocols in your web application. Disable any unused URL schemas. For example ftp://, dict://, file://, gopher://, etc.
* With microservice architectures, communication between all internal services should be authenticated.
* AWS: IMDSv2 is an additional defense mechanism for AWS that mitigates some instances of SSRF if you are using a cloud environment. Migrate to IMDSv2 and disable old IMDSv1. Check out the AWS [documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html) for more details.

---
sidebar_position: 1
---

# Web A6 - Vulnerable and Outdated Components

A software component is part of an application that extends the functionality of the application, such as a module, or software package. Component-based vulnerabilities occur when a software component is unsupported, out of date, or vulnerable to a known exploit.

You may inadvertently use vulnerable software components in production environments, posing a threat to the API's of the application. For example, an organization may download and use a software component, such as Log4J, and fail to regularly update or patch the component as flaws are discovered.

Since many software components run with the same privileges as the application itself, any vulnerabilities or flaws in the component can result in a threat to the APIs comprising the application.

Using components with known vulnerabilities makes your APIs susceptible to attacks that target any part of the application stack. For example, the following attack types are a few that may target known component vulnerabilities:

- Code injection
- Command injection
- Remote Code Execution

Below are known, critical vulnerabilities applicable to API based applications:

| Vulnerability                               | CWE                                        |
| ------------------------------------------- | ---------------                            |
| [Log4J - Remote Code Execution][LOG4J-RCE]   | [117][CWE-117]                            |

[LOG4J-RCE]: ./A6-Log4J-RCE.md
[CWE-117]: https://cwe.mitre.org/data/definitions/117.html

# Web A6 - Log4J Remote Code Execution
![LOG4J](../../assets/Web-Top-10/A6/A6-Log4J-RCE.svg)

## What is it?
This vulnerability arises due to high level reasons listed [here][WEB-A6].

Log4J is a widely used java based logging library. It has a known vulnerability that allows an attacker to download malicious code into the Log4J component, which leads to remote code execution.

The exact steps of this attack is described in the diagram above.

## References
[CWE-117: Improper Output Neutralization for Logs](https://cwe.mitre.org/data/definitions/117.html)

[Log4J Security Vulnerbilities](https://logging.apache.org/log4j/2.x/security.html)

## Test case FAQs
### When is this test case applicable?
Applies to all API endpoints that consume user supplied input.


### How does it work?
The input parameter(s) within the API endpoint, are injected with malicious strings (Log4J injection strings. See diagram above).

This malicious string refers to a remote server controlled by Levo. This remote server is called the `remote responder`.

If this malicious string is logged via a vulnerable Log4J library, the library is tricked into contacting the remote responder controlled by Levo. 

Levo's remote responder provides confirmation that the attack launched by the test case was successful.

### What is the solution?
* Upgrade Log4j2 to version 2.15.0 or newer. 

* In previous releases (>2.10) this behavior can be mitigated by setting the system property "log4j2.formatMsgNoLookups" to "true", or by removing the JndiLookup class from the classpath (example: zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class).

* Whitelist outbound traffic from your services to only legitimate destinations (URLs).


[WEB-A6]: ./A6-index.md

